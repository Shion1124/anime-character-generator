{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1edacd",
   "metadata": {},
   "source": [
    "# ğŸ¨ anime-character-generator v1.5 (LoRA Edition)\n",
    "## Stable Diffusion v1.5 + LoRA Fine-tuning\n",
    "\n",
    "**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.5 (LoRAå®Ÿè£…ç‰ˆãƒ»ãƒ–ãƒ­ã‚°ç¯„å›²å†…)  \n",
    "**èª¬æ˜**: Stable Diffusion v1.5 ã«LoRAã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨  \n",
    "**ã‚¬ã‚¤ãƒ‰**: [Day3-4 ãƒ–ãƒ­ã‚°è¨˜äº‹](https://shion.blog/)  \n",
    "**ã‚³ãƒ¼ãƒ‰**: [train_lora.py](../train_lora.py)\n",
    "\n",
    "Stable Diffusion v1.5 ã‚’ **ã‚¢ãƒ‹ãƒ¡ãƒ»ç‰¹å®šã‚¹ã‚¿ã‚¤ãƒ«å°‚ç‰¹åŒ–** ã«é©ç”¨ã•ã›ã‚‹ãŸã‚ã€LoRA ã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ Google Colab (T4 GPU) ã§å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ãƒ–ãƒ­ã‚°è¨˜äº‹ Day3-4 ã®å¾ŒåŠéƒ¨ã€ŒLoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè£…ã€ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f8a47",
   "metadata": {},
   "source": [
    "## ğŸ“Œ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ã¤ã„ã¦\n",
    "\n",
    "**ãƒ–ãƒ­ã‚°è¨˜äº‹ã¨ã®å¯¾å¿œ:**\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ Day3-4 ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€ŒPhase 3: å®Ÿè£…ã‹ã‚‰æœ¬ç•ªåŒ–ã¸ã€ã§ç´¹ä»‹ã•ã‚ŒãŸ `train_lora.py` ã‚’ã€å®Ÿéš›ã« **Google Colab ã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã®å®Ÿè·µã‚¬ã‚¤ãƒ‰**ã§ã™ã€‚\n",
    "\n",
    "**å®Ÿè£…ç¯„å›²:**\n",
    "- âœ… Stable Diffusion v1.5 ã«LoRA ã®è¿½åŠ å­¦ç¿’\n",
    "- âœ… Google Colab T4 GPU ã§ã®å®Ÿè¡Œï¼ˆç„¡æ–™æ å¯¾å¿œï¼‰\n",
    "- âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜æ©Ÿèƒ½ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­å¯¾å¿œï¼‰\n",
    "- âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°ä¿å­˜\n",
    "\n",
    "**å­¦ç¿’æ™‚é–“ç›®å®‰ï¼ˆColab T4ï¼‰:**\n",
    "- 1 epoch â‰ˆ 30-40åˆ†\n",
    "- 10 epoch â‰ˆ 5-7æ™‚é–“\n",
    "- 20 epoch â‰ˆ 10-12æ™‚é–“ï¼ˆæ¨å¥¨ã¯åˆ†å‰²å®Ÿè¡Œï¼‰\n",
    "\n",
    "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Œäº†å¾Œã€ç”Ÿæˆã•ã‚ŒãŸLoRAé‡ã¿ã¯ Google Drive ã«ä¿å­˜ã•ã‚Œã€ãƒ­ãƒ¼ã‚«ãƒ«ã® `character_generator_v1_lora.py` ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde6cb9",
   "metadata": {},
   "source": [
    "## Step 1: ç’°å¢ƒç¢ºèªãƒ»GPU ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ã®ç¢ºèª\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a3648",
   "metadata": {},
   "source": [
    "## Step 2: ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpeftä¸è¦ - ç´”ç²‹PyTorch LoRAã‚’ä½¿ç”¨ï¼‰\n",
    "!pip install -q diffusers transformers pillow torch tqdm safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa666c",
   "metadata": {},
   "source": [
    "## Step 3: Google Drive ã«ãƒã‚¦ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Google Drive ã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
    "drive.mount('/content/drive')\n",
    "print(\"âœ… Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a13c1",
   "metadata": {},
   "source": [
    "## Step 4: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™\n",
    "\n",
    "**äº‹å‰æº–å‚™ (ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œå‰):**\n",
    "1. ãƒ­ãƒ¼ã‚«ãƒ«ã§ `python scripts/download_danbooru.py --limit 60` ã‚’å®Ÿè¡Œ\n",
    "2. ç”Ÿæˆã•ã‚ŒãŸ `training_data/` ãƒ•ã‚©ãƒ«ãƒ€ã‚’ Google Drive ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "3. ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d51897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Google Drive ã‹ã‚‰ training_data ã‚’ã‚³ãƒ”ãƒ¼\n",
    "drive_path = Path(\"/content/drive/MyDrive/training_data\")\n",
    "local_path = Path(\"/content/training_data\")\n",
    "\n",
    "if drive_path.exists():\n",
    "    print(f\"âœ… Found: {drive_path}\")\n",
    "    # ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ (é€Ÿåº¦å‘ä¸Š)\n",
    "    if not local_path.exists():\n",
    "        os.symlink(drive_path, local_path)\n",
    "        print(f\"âœ… Symlink created: {local_path}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ\n",
    "    import json\n",
    "    metadata_file = drive_path / \"metadata.json\"\n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"ğŸ“Š Dataset: {len(metadata.get('training_data', []))} images\")\n",
    "else:\n",
    "    print(f\"âŒ Not found: {drive_path}\")\n",
    "    print(\"\\nPlease upload training_data/ to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efa079",
   "metadata": {},
   "source": [
    "## Step 5: train_lora.py ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "GitHub ã‹ã‚‰æœ€æ–°ã® train_lora.py ã‚’å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“¥ Step 5: train_lora.py ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "train_script = Path(\"/content/train_lora.py\")\n",
    "\n",
    "# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆå†å®Ÿè¡Œæ™‚ã«å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒæ®‹ã‚‰ãªã„ã‚ˆã†ï¼‰\n",
    "if \"train_lora\" in sys.modules:\n",
    "    del sys.modules[\"train_lora\"]\n",
    "\n",
    "# GitHub ã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "url = \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/master/train_lora.py\"\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {url[:60]}...\")\n",
    "    urllib.request.urlretrieve(url, train_script)\n",
    "    print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {train_script}\")\n",
    "    print(f\"ğŸ“¦ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}\")\n",
    "    print(f\"\\nğŸ”„ ä»£æ›¿æ–¹æ³•: git clone ã‚’è©¦è¡Œ...\")\n",
    "    import subprocess, shutil\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"git\", \"clone\", \"--depth\", \"1\",\n",
    "            \"https://github.com/Shion1124/anime-character-generator.git\",\n",
    "            \"/tmp/anime-gen\"\n",
    "        ], timeout=30)\n",
    "        shutil.copy(\"/tmp/anime-gen/train_lora.py\", train_script)\n",
    "        print(f\"âœ… git clone ã‹ã‚‰ã‚³ãƒ”ãƒ¼å®Œäº†\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ å¤±æ•—: {e2}\")\n",
    "        raise\n",
    "\n",
    "sys.path.insert(0, \"/content\")\n",
    "print(f\"âœ… Python ãƒ‘ã‚¹æ›´æ–°å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abb8fe",
   "metadata": {},
   "source": [
    "### Step 5.5: (ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã®ã¿å®Ÿè¡Œ)\n",
    "\n",
    "ä¸Šã® Step 5 ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¤±æ•—ã—ãŸå ´åˆã®ã¿ã€ä»¥ä¸‹ã«é€²ã‚“ã§ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.5: ã‚‚ã— Step 5 ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—ã—ãŸå ´åˆ\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "train_script = Path(\"/content/train_lora.py\")\n",
    "\n",
    "if train_script.exists() and train_script.stat().st_size > 10000:\n",
    "    print(f\"âœ… train_lora.py ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"ğŸ“¥ git clone ã‚’è©¦è¡Œä¸­...\")\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"git\", \"clone\", \"--depth\", \"1\",\n",
    "            \"https://github.com/Shion1124/anime-character-generator.git\",\n",
    "            \"/tmp/anime-gen\"\n",
    "        ], timeout=60, capture_output=True)\n",
    "        shutil.copy(\"/tmp/anime-gen/train_lora.py\", train_script)\n",
    "        print(f\"âœ… å–å¾—å®Œäº†: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å¤±æ•—: {e}\")\n",
    "        print(\"ğŸ”§ æ‰‹å‹•å¯¾å¿œ: Google Drive ã‹ã‚‰ train_lora.py ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9975f",
   "metadata": {},
   "source": [
    "### Step 5.6: (ãã‚Œã§ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã®ã¿å®Ÿè¡Œ)\n",
    "\n",
    "Step 5 ã¨ 5.5 ã§ã®å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã®ã¿å®Ÿè¡Œã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.6: æœ€çµ‚æ‰‹æ®µ - urllib ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "import urllib.request\n",
    "import ssl\n",
    "from pathlib import Path\n",
    "\n",
    "train_script = Path(\"/content/train_lora.py\")\n",
    "\n",
    "if train_script.exists() and train_script.stat().st_size > 10000:\n",
    "    print(f\"âœ… train_lora.py ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™\")\n",
    "else:\n",
    "    print(\"ğŸ“¥ urllib ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©¦è¡Œ...\")\n",
    "    \n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "    \n",
    "    url = \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/master/train_lora.py\"\n",
    "    \n",
    "    try:\n",
    "        request = urllib.request.Request(url)\n",
    "        request.add_header('User-Agent', 'Mozilla/5.0')\n",
    "        \n",
    "        with urllib.request.urlopen(request, context=ssl_context, timeout=30) as response:\n",
    "            content = response.read().decode('utf-8')\n",
    "        \n",
    "        with open(train_script, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ã™ã¹ã¦ã®å–å¾—æ–¹æ³•ãŒå¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
    "        print(\"ğŸ“ Google Drive ã‹ã‚‰æ‰‹å‹•ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a21a9a",
   "metadata": {},
   "source": [
    "## Step 6: LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "\n",
    "**LoRA (Low-Rank Adaptation) ã«ã¤ã„ã¦ï¼š**\n",
    "- Stable Diffusion v1.5 ã® UNet ã«ç–‘ä¼¼çš„ãªã€Œã‚¢ãƒ‹ãƒ¡ç‰¹åŒ–ã€é‡ã¿ã‚’è¿½åŠ å­¦ç¿’\n",
    "- å…ƒã®ãƒ¢ãƒ‡ãƒ«ã¯ãã®ã¾ã¾ï¼ˆè¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ ~4MB ã®ã¿ï¼‰\n",
    "- å­¦ç¿’ã« 20 ã‚¹ãƒ†ãƒƒãƒ— Ã— ç”»åƒæ•°ã§æ¨è«–ï¼ˆ3-5ç§’/ç”»åƒï¼‰\n",
    "\n",
    "**æ¨å¥¨è¨­å®šï¼ˆColab T4ï¼‰:**\n",
    "- ã‚¨ãƒãƒƒã‚¯: 10-20\n",
    "- ãƒãƒƒãƒã‚µã‚¤ã‚º: 2\n",
    "- å­¦ç¿’æ™‚é–“: 5-12æ™‚é–“ï¼ˆãƒ•ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰\n",
    "\n",
    "**é‡è¦:** Colab ã¯ 12 æ™‚é–“ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­ã•ã‚Œã‚‹ãŸã‚ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½ã§å¾©å¸°å¯èƒ½ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb324c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ¯ Step 6: LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-4\n",
    "LORA_RANK = 8\n",
    "LORA_ALPHA = 32.0\n",
    "OUTPUT_DIR = \"/content/lora_weights\"\n",
    "\n",
    "print(f\"\"\"\n",
    "âš™ï¸  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š:\n",
    "   ã‚¨ãƒãƒƒã‚¯æ•°: {EPOCHS}\n",
    "   ãƒãƒƒãƒã‚µã‚¤ã‚º: {BATCH_SIZE}\n",
    "   å­¦ç¿’ç‡: {LEARNING_RATE}\n",
    "   LoRA ãƒ©ãƒ³ã‚¯: {LORA_RANK}\n",
    "   LoRA ã‚¢ãƒ«ãƒ•ã‚¡: {LORA_ALPHA}\n",
    "   æ¨å®šæ™‚é–“: ç´„ {EPOCHS * 30 // 60} æ™‚é–“ (Colab T4)\n",
    "\"\"\")\n",
    "\n",
    "# GPUç¢ºèª\n",
    "if torch.cuda.is_available():\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"ğŸ“Š GPU: {torch.cuda.get_device_name(0)} ({total_mem:.1f} GB)\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª\n",
    "training_data_dir = Path(\"/content/training_data\")\n",
    "total_images = len(list(training_data_dir.rglob(\"*.png\"))) \\\n",
    "             + len(list(training_data_dir.rglob(\"*.jpg\"))) \\\n",
    "             + len(list(training_data_dir.rglob(\"*.jpeg\")))\n",
    "\n",
    "print(f\"ğŸ“Š ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”»åƒæ•°: {total_images}\")\n",
    "\n",
    "if total_images == 0:\n",
    "    print(\"âŒ ERROR: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(\"   Step 4 ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã—ã¦ãã ã•ã„\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# train_lora.py ã‹ã‚‰ LoRATrainer ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "sys.path.insert(0, \"/content\")\n",
    "\n",
    "try:\n",
    "    from train_lora import LoRATrainer\n",
    "    print(\"âœ… train_lora ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\\n\")\n",
    "\n",
    "    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–\n",
    "    # __init__ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: model_name, device, lora_rank, lora_alpha\n",
    "    print(\"ğŸš€ LoRA ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–ä¸­...\")\n",
    "    trainer = LoRATrainer(\n",
    "        model_name=\"runwayml/stable-diffusion-v1-5\",\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        lora_rank=LORA_RANK,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "    )\n",
    "\n",
    "    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹\n",
    "    # train() ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: data_dir, output_dir, epochs, batch_size, learning_rate\n",
    "    print(f\"\\nğŸš€ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ ({EPOCHS} epoch Ã— {total_images} images)...\\n\")\n",
    "\n",
    "    training_log = trainer.train(\n",
    "        data_dir=\"/content/training_data\",\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼\")\n",
    "    print(f\"ğŸ“ å‡ºåŠ›: {OUTPUT_DIR}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    print(\"   Step 5 ã‚’å®Ÿè¡Œã—ã¦ train_lora.py ã‚’å–å¾—ã—ã¦ãã ã•ã„\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a21c5c",
   "metadata": {},
   "source": [
    "## Step 7: å­¦ç¿’çµæœã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"/content/lora_weights\")\n",
    "print(\"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "print()\n",
    "\n",
    "for file in sorted(output_dir.glob(\"*\")):\n",
    "    if file.is_file():\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {file.name:40s} {size_mb:>8.2f} MB\")\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°ç¢ºèª\n",
    "log_file = output_dir / \"training_log.json\"\n",
    "if log_file.exists():\n",
    "    with open(log_file) as f:\n",
    "        log = json.load(f)\n",
    "    \n",
    "    print(f\"\\nâœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†!\")\n",
    "    print(f\"   æå¤±: {log['losses'][-1]['loss'] if log.get('losses') else 'N/A':.6f}\")\n",
    "    print(f\"   å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  training_log.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc79c7",
   "metadata": {},
   "source": [
    "## Step 7: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc4431",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4545af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "lora_dir = Path(\"/content/lora_weights\")\n",
    "print(\"ğŸ“ Output files:\")\n",
    "print()\n",
    "\n",
    "for file in sorted(lora_dir.glob(\"*\")):\n",
    "    if file.is_file():\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {file.name:40s} {size_mb:>8.2f} MB\")\n",
    "\n",
    "# ãƒ¡ã‚¤ãƒ³ã® LoRA é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "lora_model = lora_dir / \"anime-impressionist-lora.safetensors\"\n",
    "if lora_model.exists():\n",
    "    size_mb = lora_model.stat().st_size / (1024 * 1024)\n",
    "    print(f\"\\nâœ… Main LoRA weights: {lora_model.name} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d7328",
   "metadata": {},
   "source": [
    "## Step 9: Google Drive ã«çµæœã‚’ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f330d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°çµæœã‚’ Google Drive ã«ä¿å­˜\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "lora_weights_dir = Path(\"/content/lora_weights\")\n",
    "drive_output_dir = Path(\"/content/drive/MyDrive/lora_weights\")\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "drive_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
    "for file in lora_weights_dir.glob(\"*\"):\n",
    "    if file.is_file():\n",
    "        destination = drive_output_dir / file.name\n",
    "        shutil.copy2(file, destination)\n",
    "        print(f\"âœ… ä¿å­˜: {file.name}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Google Drive ã«ä¿å­˜å®Œäº†: {drive_output_dir}\")\n",
    "print(f\"\\nå®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ã«ã¯:\")\n",
    "print(f\"  1. LoRAé‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\")\n",
    "print(f\"  2. ãƒ­ãƒ¼ã‚«ãƒ«ã§ character_generator_v1_lora.py ã§åˆ©ç”¨\")\n",
    "print(f\"  3. ã¾ãŸã¯ HuggingFace Hub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb12ff",
   "metadata": {},
   "source": [
    "## Step 10: æ¨è«–ãƒ†ã‚¹ãƒˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ LoRA ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA ã‚’ä½¿ç”¨ã—ãŸæ¨è«–ãƒ†ã‚¹ãƒˆ\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "print(\"â³ Loading model...\")\n",
    "\n",
    "# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# LoRA é‡ã¿ãƒ­ãƒ¼ãƒ‰\n",
    "try:\n",
    "    # PEFT ã‚’ä½¿ç”¨ã—ãŸ LoRA ãƒ­ãƒ¼ãƒ‰\n",
    "    from peft import PeftModel\n",
    "    # (LoRA ãƒ­ãƒ¼ãƒ‰å®Ÿè£…)\n",
    "    print(\"âœ… LoRA weights loaded\")\n",
    "except:\n",
    "    print(\"âš ï¸ LoRA loading requires additional setup\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "prompt = \"1girl, watercolor painting style, masterpiece, high quality, anime\"\n",
    "negative_prompt = \"low quality, nsfw\"\n",
    "\n",
    "print(f\"\\nğŸ¨ Generating: {prompt}...\")\n",
    "\n",
    "# ç”»åƒç”Ÿæˆ\n",
    "with torch.no_grad():\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=512,\n",
    "        width=512,\n",
    "        num_inference_steps=20,\n",
    "        guidance_scale=7.0\n",
    "    ).images[0]\n",
    "\n",
    "# çµæœè¡¨ç¤º\n",
    "image.save(\"/content/test_output.png\")\n",
    "print(\"âœ… Image saved: test_output.png\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20208be4",
   "metadata": {},
   "source": [
    "## âœ… å®Œäº†ï¼\n",
    "\n",
    "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**\n",
    "1. LoRA é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "2. ãƒ­ãƒ¼ã‚«ãƒ«ã§ `character_generator.py --use_lora=True` ã§æ¨è«–\n",
    "3. çµæœã‚’ç¢ºèª\n",
    "\n",
    "**å‚è€ƒ:**\n",
    "- [GitHub ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/Shion1124/anime-character-generator)\n",
    "- [HuggingFace ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/runwayml/stable-diffusion-v1-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5464a",
   "metadata": {},
   "source": [
    "## Step 11: HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ LoRA ã‚¢ãƒ€ãƒ—ã‚¿ã¨ **ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ (README.md)** ã‚’ HuggingFace Hub ã§å…¬é–‹ã—ã¾ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### Step 11.1: HuggingFace ãƒ­ã‚°ã‚¤ãƒ³\n",
    "\n",
    "HuggingFace ã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€**æ›¸ãè¾¼ã¿æ¨©é™ã®ã‚ã‚‹ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³** ãŒå¿…è¦ã§ã™ã€‚  \n",
    "ä»¥ä¸‹ã®æ‰‹é †ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "**ã‚¹ãƒ†ãƒƒãƒ—1: è¨­å®šç”»é¢ã‚’é–‹ã**\n",
    "1. [HuggingFace](https://huggingface.co/) ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™\n",
    "2. ç”»é¢å³ä¸Šã®è‡ªåˆ†ã®ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™\n",
    "3. ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®ä¸­ã‹ã‚‰ **ã€ŒSettingsã€** ã‚’é¸æŠã—ã¾ã™\n",
    "\n",
    "**ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒšãƒ¼ã‚¸ã¸**\n",
    "- å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«ã‚ã‚‹ **ã€ŒAccess Tokensã€** ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™\n",
    "\n",
    "**ã‚¹ãƒ†ãƒƒãƒ—3: æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½œæˆã™ã‚‹**\n",
    "1. **ã€Œ+ Create new tokenã€** ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™\n",
    "2. ä»¥ä¸‹ã®2é …ç›®ã‚’å…¥åŠ›ãƒ»é¸æŠã—ã¾ã™ï¼š\n",
    "   - **Token Name**: åˆ†ã‹ã‚Šã‚„ã™ã„åå‰ï¼ˆä¾‹: `anime-lora-upload`ï¼‰\n",
    "   - **Token type**: å¿…ãš **ã€ŒWriteã€** ã‚’é¸æŠï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«ã¯æ›¸ãè¾¼ã¿æ¨©é™ãŒå¿…è¦ï¼‰\n",
    "3. **ã€ŒCreate tokenã€** ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å®Œäº†\n",
    "\n",
    "**ã‚¹ãƒ†ãƒƒãƒ—4: ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä¿å­˜ã™ã‚‹**\n",
    "- ãƒˆãƒ¼ã‚¯ãƒ³æ¨ªã® **ã‚³ãƒ”ãƒ¼ã‚¢ã‚¤ã‚³ãƒ³** ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚³ãƒ”ãƒ¼ã—ã¾ã™\n",
    "- ãƒ¡ãƒ¢å¸³ãªã©ã«è²¼ã‚Šä»˜ã‘ã¦å®‰å…¨ã«ä¿ç®¡ã—ã¦ãã ã•ã„\n",
    "\n",
    "> âš ï¸ **é‡è¦ãªæ³¨æ„ç‚¹**  \n",
    "> ãƒˆãƒ¼ã‚¯ãƒ³ã¯ã€Œãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€ã¨åŒã˜ã§ã™ã€‚GitHub ãªã©ã«è²¼ã‚Šä»˜ã‘ã¦å…¬é–‹ã—ãªã„ã‚ˆã†ã€ååˆ†æ³¨æ„ã—ã¦ãã ã•ã„ã€‚  \n",
    "> æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚Œã‚‹ã®ã§ã€ãã“ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1041206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Step 11.1: HuggingFace ãƒ­ã‚°ã‚¤ãƒ³\n",
    "# -----------------------------\n",
    "# HuggingFace Hub ã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚\n",
    "# å®Ÿè¡Œã™ã‚‹ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚Œã‚‹ã®ã§ã€å–å¾—ã—ãŸ Write ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "login()           # Colab will prompt â€” ã“ã“ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è²¼ã‚Šä»˜ã‘ã‚‹\n",
    "api = HfApi()\n",
    "\n",
    "print(\"âœ… HuggingFace ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9fb0c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 11.2: å­¦ç¿’æˆæœç‰©ã®ç¢ºèªã¨ README.mdï¼ˆãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ï¼‰ã®ç”Ÿæˆ\n",
    "\n",
    "å­¦ç¿’å¾Œã€`/content/lora_weights/anime-lora-final/` ã«ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ï¼ˆæœ€ä½é™ï¼‰ï¼š\n",
    "\n",
    "| ãƒ•ã‚¡ã‚¤ãƒ« | èª¬æ˜ |\n",
    "|---------|------|\n",
    "| `adapter_config.json` | LoRA è¨­å®šï¼ˆãƒ©ãƒ³ã‚¯ãƒ»ã‚¢ãƒ«ãƒ•ã‚¡å€¤ãªã©ï¼‰ |\n",
    "| `adapter_model.safetensors` | LoRA é‡ã¿æœ¬ä½“ |\n",
    "| `training_log.json` | ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚° |\n",
    "\n",
    "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ã«ã€æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã§ **README.mdï¼ˆãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ï¼‰** ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "#### README.md ã®æ­£ã—ã„æ›¸ãæ–¹\n",
    "\n",
    "HuggingFace ã§ã¯ `README.md` = **ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰** ã§ã™ã€‚  \n",
    "ã€Œã“ã®LoRAã¯ä½•ã‚’å­¦ç¿’ã—ã€ã©ã†ä½¿ã„ã€ä½•ã«æ³¨æ„ã™ã¹ãã‹ã€ã‚’ ç¬¬ä¸‰è€…ãŒå†åˆ©ç”¨ã§ãã‚‹æ°´æº–ã§èª¬æ˜ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "**å¿…é ˆæ§‹æˆï¼ˆã“ã®é †ã§æ›¸ãã“ã¨ï¼‰ï¼š**\n",
    "\n",
    "**â‘  YAML ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆå¿…é ˆï¼‰**\n",
    "```yaml\n",
    "---\n",
    "base_model: runwayml/stable-diffusion-v1-5\n",
    "datasets:\n",
    "- danbooru\n",
    "language:\n",
    "- ja\n",
    "- en\n",
    "license: openrail\n",
    "library_name: peft\n",
    "pipeline_tag: text-to-image\n",
    "tags:\n",
    "- lora\n",
    "- stable-diffusion\n",
    "- anime\n",
    "---\n",
    "```\n",
    "YAML front matter ãŒãªã„ã¨ HuggingFace ã§ã€Œå£Šã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã€æ‰±ã„ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "**â‘¡ ãƒ¢ãƒ‡ãƒ«æ¦‚è¦ï¼ˆWhatï¼‰** â€” ã€ŒLoRA ã‚¢ãƒ€ãƒ—ã‚¿ã®ã¿ã€ã§ã‚ã‚‹ã“ã¨ã‚’æ˜è¨˜  \n",
    "**â‘¢ å­¦ç¿’ç›®çš„ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆWhyï¼‰** â€” ã©ã®ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å­¦ç¿’ã—ãŸã‹  \n",
    "**â‘£ å­¦ç¿’è¨­å®šï¼ˆHowï¼‰** â€” ãƒ©ãƒ³ã‚¯ãƒ»ã‚¢ãƒ«ãƒ•ã‚¡ãƒ»ã‚¨ãƒãƒƒã‚¯æ•°ãƒ»å­¦ç¿’ç‡  \n",
    "**â‘¤ ä½¿ç”¨æ–¹æ³•ï¼ˆHow to useï¼‰** â€” ã‚³ãƒ”ãƒšã§å‹•ãã‚³ãƒ¼ãƒ‰ä¾‹  \n",
    "**â‘¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ï¼ˆå¿…é ˆï¼‰** â€” Danbooru / OpenRAIL æº–æ‹ \n",
    "\n",
    "> âš ï¸ **èª²é¡Œ**  \n",
    "> ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ`title_line`ï¼‰ã¯å¿…ãšè‡ªåˆ†ã§è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚  \n",
    "> ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤‰æ›´ã—ãŸå ´åˆã¯ Sources & Terms æ¬„ã‚‚æ›´æ–°ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef552e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Step 11.2: README.mdï¼ˆãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ï¼‰ã‚’ç”Ÿæˆ\n",
    "# -----------------------------\n",
    "# å­¦ç¿’å®Œäº†å¾Œã«å®Ÿè¡Œã—ã€HuggingFace ã® README.mdï¼ˆãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ï¼‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
    "# å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚³ãƒ¼ãƒ‰ã®å¤‰æ•°ã‹ã‚‰è‡ªå‹•åŒæœŸã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_LORA_DIR = \"/content/lora_weights/anime-lora-final\"\n",
    "os.makedirs(OUT_LORA_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Step 6 å¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆæœªå®šç¾©ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰\n",
    "# ------------------------------------------------------------------\n",
    "def _s(x, default=\"\"):\n",
    "    try:\n",
    "        v = str(x)\n",
    "        return v if v.strip() else default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _fmt_lr(x) -> str:\n",
    "    try:\n",
    "        return f\"{float(x):.0e}\"\n",
    "    except Exception:\n",
    "        return _s(x, \"\")\n",
    "\n",
    "try:\n",
    "    _lora_rank  = int(LORA_RANK)\n",
    "    _lora_alpha = float(LORA_ALPHA)\n",
    "    _epochs     = int(EPOCHS)\n",
    "    _lr_str     = _fmt_lr(LEARNING_RATE)\n",
    "    _batch_size = int(BATCH_SIZE)\n",
    "except NameError:\n",
    "    print(\"âš ï¸  Step 6 ã®å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "    _lora_rank  = 8\n",
    "    _lora_alpha = 32.0\n",
    "    _epochs     = 10\n",
    "    _lr_str     = \"1e-4\"\n",
    "    _batch_size = 2\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°ã‹ã‚‰æœ€çµ‚æå¤±ã‚’å–å¾—\n",
    "_final_loss = \"N/A\"\n",
    "log_file = Path(\"/content/lora_weights/training_log.json\")\n",
    "if log_file.exists():\n",
    "    with open(log_file) as f:\n",
    "        log = json.load(f)\n",
    "    if log.get(\"losses\"):\n",
    "        _final_loss = f\"{log['losses'][-1]['loss']:.6f}\"\n",
    "        _epochs = len(log[\"losses\"])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# README ã®è¨­å®š\n",
    "# âš ï¸ MODEL_TITLE ã¯å¿…ãšè‡ªåˆ†ã§è¨˜å…¥ã™ã‚‹ã“ã¨\n",
    "# ------------------------------------------------------------------\n",
    "BASE_MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "HF_REPO_ID    = \"YOUR_USERNAME/anime-character-lora\"  # â† è‡ªåˆ†ã®ãƒªãƒã‚¸ãƒˆãƒªIDã«å¤‰æ›´\n",
    "PRIVATE       = False                                  # True ã§ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆå…¬é–‹\n",
    "\n",
    "# README.md ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå¿…ãšè‡ªåˆ†ã§è¨˜å…¥ã—ã¦ãã ã•ã„ï¼‰\n",
    "title_line    = \"anime-character-lora\"  # ä¾‹: my-anime-watercolor-lora\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# README.md æœ¬æ–‡ã®ç”Ÿæˆ\n",
    "# ------------------------------------------------------------------\n",
    "readme_md = f\"\"\"---\n",
    "base_model: {BASE_MODEL_ID}\n",
    "datasets:\n",
    "- danbooru\n",
    "language:\n",
    "- ja\n",
    "- en\n",
    "license: openrail\n",
    "library_name: peft\n",
    "pipeline_tag: text-to-image\n",
    "tags:\n",
    "- lora\n",
    "- stable-diffusion\n",
    "- anime\n",
    "- character-generation\n",
    "- fine-tuned\n",
    "---\n",
    "\n",
    "# {title_line}\n",
    "\n",
    "This repository provides a **LoRA adapter** fine-tuned from  \n",
    "**{BASE_MODEL_ID}** using **PyTorch LoRA (PEFT)**.\n",
    "\n",
    "This repository contains **LoRA adapter weights only**.  \n",
    "The base model must be loaded separately.\n",
    "\n",
    "## Training Objective\n",
    "\n",
    "This adapter is trained to improve **anime character generation quality**  \n",
    "across 5 artistic styles (impressionist, soft-focus, oil painting, sketch, pastel).\n",
    "\n",
    "The model learns style-specific features from Danbooru anime images,  \n",
    "applied to the UNet attention layers (`to_k`, `to_v`, `to_q`, `to_out.0`).\n",
    "\n",
    "## Example Output\n",
    "\n",
    "![Example generated image](examples/test_output.png)\n",
    "\n",
    "## Training Configuration\n",
    "\n",
    "- Base model: `{BASE_MODEL_ID}`\n",
    "- Method: LoRA (PEFT)\n",
    "- Target modules: `to_k`, `to_v`, `to_q`, `to_out.0` (Attention Linear layers only)\n",
    "- LoRA rank: {_lora_rank}\n",
    "- LoRA alpha: {_lora_alpha}\n",
    "- Learning rate: {_lr_str}\n",
    "- Batch size: {_batch_size}\n",
    "- Epochs: {_epochs}\n",
    "- Final loss: {_final_loss}\n",
    "- GPU: Colab T4 (16 GB VRAM)\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Danbooru anime images collected and classified into 5 styles:\n",
    "\n",
    "| Style | Images |\n",
    "|-------|--------|\n",
    "| impressionist_style | ~60 |\n",
    "| soft_focus_landscape | ~60 |\n",
    "| oil_painting_aesthetic | ~60 |\n",
    "| sketch_aesthetic | ~60 |\n",
    "| pastel_softness | ~60 |\n",
    "\n",
    "Total: ~300 images\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "base = \"{BASE_MODEL_ID}\"\n",
    "adapter = \"{HF_REPO_ID}\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(base, torch_dtype=torch.float16)\n",
    "pipe.unet = PeftModel.from_pretrained(pipe.unet, adapter, adapter_name=\"anime_lora\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(\n",
    "    prompt=\"1girl, anime character, watercolor style, masterpiece, high quality\",\n",
    "    negative_prompt=\"low quality, blurry, distorted, nsfw\",\n",
    "    num_inference_steps=20,\n",
    "    guidance_scale=7.5,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
    ").images[0]\n",
    "image.save(\"output.png\")\n",
    "```\n",
    "\n",
    "## Recommended Prompts\n",
    "\n",
    "**Anime character:**\n",
    "```\n",
    "1girl, anime character, detailed beautiful face, long hair,\n",
    "watercolor painting style, soft colors, bokeh background,\n",
    "masterpiece, best quality, high quality, intricate details\n",
    "```\n",
    "\n",
    "**Negative prompt:**\n",
    "```\n",
    "low quality, worst quality, blurry, distorted, watermark,\n",
    "error, nsfw, extra limbs, missing limbs, ugly, bad anatomy\n",
    "```\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| `num_inference_steps` | 20 |\n",
    "| `guidance_scale` | 7.5 |\n",
    "| `height / width` | 512 Ã— 512 |\n",
    "\n",
    "## Sources & Terms (IMPORTANT)\n",
    "\n",
    "Training data: Danbooru (https://danbooru.donmai.us/)\n",
    "\n",
    "Dataset License: CC0 (Public Domain). Images sourced from Danbooru under CC0 terms.  \n",
    "Compliance: Users must comply with the base model's original license terms (OpenRAIL-M).\n",
    "\n",
    "## License\n",
    "\n",
    "| Component | License |\n",
    "|-----------|---------|\n",
    "| Stable Diffusion v1.5 | OpenRAIL-M |\n",
    "| LoRA adapter (this repo) | Apache 2.0 |\n",
    "| Training data (Danbooru) | CC0 |\n",
    "\n",
    "## References\n",
    "\n",
    "1. Ho et al. (2020) - *Denoising Diffusion Probabilistic Models* - [arXiv:2006.11239](https://arxiv.org/abs/2006.11239)\n",
    "2. Rombach et al. (2022) - *High-Resolution Image Synthesis with Latent Diffusion Models* - [arXiv:2112.10752](https://arxiv.org/abs/2112.10752)\n",
    "3. Hu et al. (2021) - *LoRA: Low-Rank Adaptation of Large Language Models* - [arXiv:2106.09685](https://arxiv.org/abs/2106.09685)\n",
    "\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# README.md ã®æ›¸ãè¾¼ã¿\n",
    "# ------------------------------------------------------------------\n",
    "readme_path = os.path.join(OUT_LORA_DIR, \"README.md\")\n",
    "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_md)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# å‹•ä½œç¢ºèª\n",
    "# ------------------------------------------------------------------\n",
    "assert os.path.exists(readme_path), \"README.md was not written.\"\n",
    "assert readme_md.lstrip().startswith(\"---\\n\"), (\n",
    "    \"README.md must start with YAML front matter (---).\"\n",
    ")\n",
    "assert readme_md.count(\"\\n---\\n\") >= 1, (\n",
    "    \"YAML front matter must be closed with ---.\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… README.md ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {readme_path}\")\n",
    "print(f\"   ã‚µã‚¤ã‚º: {Path(readme_path).stat().st_size / 1024:.1f} KB\")\n",
    "print()\n",
    "print(\"ğŸ“„ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­30è¡Œï¼‰:\")\n",
    "for i, line in enumerate(readme_md.splitlines()[:30], start=1):\n",
    "    print(f\"{i:02d}: {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4a4e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 11.3: LoRA ã‚¢ãƒ€ãƒ—ã‚¿ã‚’ HuggingFace Hub ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "README.md ã®ç”ŸæˆãŒå®Œäº†ã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "\n",
    "**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ã®ç¢ºèªäº‹é …ï¼š**\n",
    "- Step 11.2 ã® README.md ç”ŸæˆãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨\n",
    "- `adapter_config.json` ã¨ `adapter_model.safetensors`ï¼ˆã¾ãŸã¯ `.bin`ï¼‰ãŒå­˜åœ¨ã™ã‚‹ã“ã¨\n",
    "- `HF_REPO_ID` ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ï¼ˆStep 11.2 ã®ã‚³ãƒ¼ãƒ‰å†’é ­ã§å¤‰æ›´ï¼‰\n",
    "\n",
    "**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆï¼‰ï¼š**\n",
    "\n",
    "| ãƒ•ã‚¡ã‚¤ãƒ« | å¿…é ˆ |\n",
    "|---------|------|\n",
    "| `README.md` | âœ… å¿…é ˆ |\n",
    "| `adapter_config.json` | âœ… å¿…é ˆ |\n",
    "| `adapter_model.safetensors` / `.bin` | âœ… å¿…é ˆ |\n",
    "| `tokenizer.*` / `special_tokens_map.json` | ä»»æ„ |\n",
    "| `*.json` | ä»»æ„ |\n",
    "\n",
    "> âš ï¸ ä¸è¦ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã§é™¤å¤–ã•ã‚Œã¾ã™ã€‚  \n",
    "> å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¬ ã‘ã¦ã„ã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04244a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 11.3: LoRA ã‚¢ãƒ€ãƒ—ã‚¿ã‚’ HuggingFace Hub ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "# ============================================================\n",
    "# README.md ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã—ã¾ã™ã€‚\n",
    "# ä¸è¦ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã§é™¤å¤–ã—ã€ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°é ˜åŸŸçµŒç”±ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "\n",
    "import fnmatch\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# HuggingFace API ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆStep 11.1 ã® login() æ¸ˆã¿ã§ã‚ã‚‹ã“ã¨ï¼‰\n",
    "api = HfApi()\n",
    "\n",
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è¨­å®šï¼ˆStep 11.2 ã® HF_REPO_ID / PRIVATE ã‚’å¼•ãç¶™ãï¼‰\n",
    "try:\n",
    "    _repo_id = HF_REPO_ID\n",
    "    _private = PRIVATE\n",
    "except NameError:\n",
    "    _repo_id = \"YOUR_USERNAME/anime-character-lora\"\n",
    "    _private = False\n",
    "    print(\"âš ï¸  HF_REPO_ID æœªå®šç¾©ã€‚Step 11.2 ã®ã‚³ãƒ¼ãƒ‰ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "\n",
    "LORA_SAVE_DIR = Path(OUT_LORA_DIR)\n",
    "\n",
    "# -----------------------------\n",
    "# 3.1) å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª\n",
    "# -----------------------------\n",
    "required_files = {\n",
    "    \"adapter_config.json\",  # LoRA è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«\n",
    "    \"README.md\",            # ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ï¼ˆStep 11.2 ã§ç”Ÿæˆï¼‰\n",
    "}\n",
    "\n",
    "present = {p.name for p in LORA_SAVE_DIR.iterdir() if p.is_file()}\n",
    "missing = [f for f in required_files if f not in present]\n",
    "\n",
    "# adapter_model.safetensors ã¾ãŸã¯ .bin ã®å­˜åœ¨ç¢ºèª\n",
    "if not any(f.startswith(\"adapter_model.\") for f in present):\n",
    "    missing.append(\"adapter_model.(safetensors|bin)\")\n",
    "\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        \"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ä¸­æ­¢ã—ã¾ã—ãŸã€‚\\n\"\n",
    "        \"ä»¥ä¸‹ã®å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:\\n\"\n",
    "        + \"\\n\".join(f\"  - {m}\" for m in missing) +\n",
    "        \"\\n\\n\"\n",
    "        \"å¯¾å‡¦æ³•:\\n\"\n",
    "        \"  - README.md â†’ Step 11.2 ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\\n\"\n",
    "        \"  - adapter_config.json / adapter_model.* â†’ Step 6 (ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°) ã‚’å®Œäº†ã—ã¦ãã ã•ã„\"\n",
    "    )\n",
    "\n",
    "print(\"âœ… å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
    "print(f\"   ä¿å­˜å…ˆ: {LORA_SAVE_DIR}\")\n",
    "for f in sorted(present):\n",
    "    size_kb = (LORA_SAVE_DIR / f).stat().st_size / 1024\n",
    "    print(f\"   {f:45s} {size_kb:>8.1f} KB\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3.2) ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ã®é¸åˆ¥ï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆï¼‰\n",
    "# 3.2.1) LoRA é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "# 3.2.2) ã‚µãƒ³ãƒ—ãƒ«ç”»åƒï¼ˆtest_output.pngï¼‰\n",
    "# 3.2.3) ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ï¼ˆREADME.mdï¼‰\n",
    "# 3.2.4) è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆadapter_config.jsonï¼‰\n",
    "# -----------------------------\n",
    "# ä¸è¦ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–ã—ã€è¨±å¯ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®ã¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "ALLOW_PATTERNS = [\n",
    "    \"README.md\",\n",
    "    \"adapter_config.json\",\n",
    "    \"adapter_model.*\",\n",
    "    \"tokenizer.*\",\n",
    "    \"special_tokens_map.json\",\n",
    "    \"*.json\",\n",
    "    \"examples/*\",  # â† ã‚µãƒ³ãƒ—ãƒ«ç”»åƒãƒ•ã‚©ãƒ«ãƒ€\n",
    "]\n",
    "\n",
    "def is_allowed(name: str) -> bool:\n",
    "    return any(fnmatch.fnmatch(name, pat) for pat in ALLOW_PATTERNS)\n",
    "\n",
    "# ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°é ˜åŸŸï¼ˆä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ï¼‰ã‚’ä½œæˆ\n",
    "STAGE_DIR = Path(\"/content/hf_upload_stage\")\n",
    "if STAGE_DIR.exists():\n",
    "    shutil.rmtree(STAGE_DIR)\n",
    "STAGE_DIR.mkdir(parents=True)\n",
    "\n",
    "# è¨±å¯ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ã‚³ãƒ”ãƒ¼\n",
    "for p in LORA_SAVE_DIR.iterdir():\n",
    "    if p.is_file() and is_allowed(p.name):\n",
    "        (STAGE_DIR / p.name).write_bytes(p.read_bytes())\n",
    "\n",
    "# ========== è¿½åŠ : ãƒ†ã‚¹ãƒˆç”»åƒã‚’ examples ãƒ•ã‚©ãƒ«ãƒ€ã«å«ã‚ã‚‹ ==========\n",
    "test_image_path = Path(\"/content/test_output.png\")\n",
    "if test_image_path.exists():\n",
    "    examples_dir = STAGE_DIR / \"examples\"\n",
    "    examples_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (examples_dir / \"test_output.png\").write_bytes(test_image_path.read_bytes())\n",
    "    print(f\"âœ… ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ examples ãƒ•ã‚©ãƒ«ãƒ€ã«è¿½åŠ \")\n",
    "else:\n",
    "    print(f\"âš ï¸  ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_image_path}\")\n",
    "    print(f\"   (Step 10 ã®æ¨è«–ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„)\")\n",
    "\n",
    "staged_files = [p.name for p in sorted(STAGE_DIR.rglob(\"*\")) if p.is_file()]\n",
    "print(f\"\\nğŸ“¦ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ« ({len(staged_files)}å€‹):\")\n",
    "for f in staged_files:\n",
    "    size_kb = (STAGE_DIR / f).stat().st_size / 1024\n",
    "    print(f\"   {f:45s} {size_kb:>8.1f} KB\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3.3) ãƒªãƒã‚¸ãƒˆãƒªä½œæˆã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "# -----------------------------\n",
    "print(f\"\\nğŸš€ ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆ/ç¢ºèªä¸­: {_repo_id}\")\n",
    "api.create_repo(\n",
    "    repo_id=_repo_id,\n",
    "    repo_type=\"model\",\n",
    "    exist_ok=True,\n",
    "    private=_private,\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“¤ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "api.upload_folder(\n",
    "    folder_path=str(STAGE_DIR),\n",
    "    repo_id=_repo_id,\n",
    "    repo_type=\"model\",\n",
    "    commit_message=f\"Upload LoRA adapter (rank={_lora_rank}, alpha={_lora_alpha}, epochs={_epochs})\",\n",
    ")\n",
    "\n",
    "# ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°é ˜åŸŸã‚’å‰Šé™¤\n",
    "shutil.rmtree(STAGE_DIR)\n",
    "\n",
    "# -----------------------------\n",
    "# å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
    "# -----------------------------\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ‰ HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ”— ãƒ¢ãƒ‡ãƒ«URL: https://huggingface.co/{_repo_id}\")\n",
    "print(f\"\\nğŸ“– ä½¿ç”¨æ–¹æ³•:\")\n",
    "print(f\"   from diffusers import StableDiffusionPipeline\")\n",
    "print(f\"   from peft import PeftModel\")\n",
    "print(f\"   import torch\")\n",
    "print(f\"   pipe = StableDiffusionPipeline.from_pretrained(\")\n",
    "print(f\"       'runwayml/stable-diffusion-v1-5', torch_dtype=torch.float16\")\n",
    "print(f\"   )\")\n",
    "print(f\"   pipe.unet = PeftModel.from_pretrained(pipe.unet, '{_repo_id}')\")\n",
    "print(f\"   pipe = pipe.to('cuda')\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
