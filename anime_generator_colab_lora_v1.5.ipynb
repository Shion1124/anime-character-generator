{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1edacd",
   "metadata": {},
   "source": [
    "# ğŸ¨ anime-character-generator v1.5 (LoRA Edition)\n",
    "## Stable Diffusion v1.5 + LoRA Fine-tuning\n",
    "\n",
    "**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.5 (LoRAå®Ÿè£…ç‰ˆãƒ»èª²é¡Œã‚ã‚Š)  \n",
    "**èª¬æ˜**: Stable Diffusion v1.5 ã«LoRAã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨  \n",
    "**ã‚¬ã‚¤ãƒ‰**: [Day3-4 ãƒ–ãƒ­ã‚°è¨˜äº‹](https://shion.blog/)  \n",
    "**ã‚³ãƒ¼ãƒ‰**: [character_generator_v1_lora.py](../character_generator_v1_lora.py)\n",
    "\n",
    "Stable Diffusion v1.5 ã‚’ **ã‚¢ãƒ‹ãƒ¡ãƒ»å°è±¡æ´¾é¢¨** ã«ç‰¹åŒ–ã•ã›ã‚‹ãŸã‚ã€LoRA ã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ Google Colab (T4 GPU) ã§å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "## âš ï¸ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ v1.5 (è©¦è¡ŒéŒ¯èª¤ç‰ˆ) ã§ã™\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã§ãã¾ã™ãŒã€ä»¥ä¸‹ã®**æ—¢çŸ¥ã®èª²é¡Œ**ãŒã‚ã‚Šã¾ã™ã€‚è©³ç´°ã¯ä¸‹è¨˜ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f8a47",
   "metadata": {},
   "source": [
    "## âš ï¸ æ—¢çŸ¥ã®èª²é¡Œã¨ v2.0 ã§ã®è§£æ±ºæ–¹æ³•\n",
    "\n",
    "### èª²é¡Œ 1ï¸âƒ£: Character-level noise ã¸ã®è„†å¼±æ€§\n",
    "- **è«–æ–‡**: Gao et al. (2306.13103) ã€ŒText-to-Image Robustnessã€\n",
    "- **ç—‡çŠ¶**: ã€Œastronautã€â†’ã€Œastornautã€ï¼ˆ1æ–‡å­—é•ã„ï¼‰ã§ç”ŸæˆçµæœãŒåŠ‡çš„ã«å¤‰ã‚ã‚‹\n",
    "- **åŸå› **: å˜ä¸€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã§ã€ã‚¿ã‚¤ãƒã‚„ã‚°ãƒªãƒ•æ”»æ’ƒã«å¯¾å¿œã—ã¦ã„ãªã„\n",
    "- **URL**: https://arxiv.org/abs/2306.13103\n",
    "- **v2.0ã§ã®è§£æ±º**: Phase 1 ã§ LLM ã«ã‚ˆã‚‹å¤šå±¤å†—é•·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã‚’å®Ÿè£…\n",
    "\n",
    "### èª²é¡Œ 2ï¸âƒ£: æ¨è«–é€Ÿåº¦ãŒé…ã„\n",
    "- **å®Ÿæ¸¬**: 3.8ç§’/ç”»åƒ (T4 GPU, Stable Diffusion v1.5)\n",
    "- **æ”¹å–„æ©Ÿä¼š**: Latent Consistency Model (LCM) è’¸ç•™ã§ 12x é«˜é€ŸåŒ–å¯èƒ½\n",
    "- **URL**: https://arxiv.org/abs/2310.04378\n",
    "- **v2.0ã§ã®è§£æ±º**: Phase 2B ã§ LCM è’¸ç•™ã‚’å®Ÿè£… (1ç§’/ç”»åƒ é”æˆäºˆå®š)\n",
    "\n",
    "### èª²é¡Œ 3ï¸âƒ£: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›æœªå¯¾å¿œ\n",
    "- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®ã¿\n",
    "- Image-to-Image ã‚„ ControlNet ã«ã‚ˆã‚‹ ã‚¹ã‚±ãƒƒãƒãƒ»ãƒãƒ¼ã‚ºæŒ‡å®šç”Ÿæˆ æœªå®Ÿè£…\n",
    "- **v2.0ã§ã®è§£æ±º**: Phase 3 ã§å®Œå…¨ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ\n",
    "\n",
    "### èª²é¡Œ 4ï¸âƒ£: æœ¬ç•ªç’°å¢ƒå¯¾å¿œãŒãªã„\n",
    "- ç ”ç©¶ã‚¹ã‚¯ãƒªãƒ—ãƒˆå½¢å¼\n",
    "- REST API ã‚„ Web UI ãŒãªã„\n",
    "- ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤å¯¾å¿œãªã—\n",
    "- **v2.0ã§ã®è§£æ±º**: Phase 4 ã§ Streamlit UI + FastAPI + ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè£…\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… ã“ã‚Œã‚‰ã®èª²é¡Œã¯ v2.0 (Phase 1-4) ã§æ®µéšçš„ã«è§£æ±ºã•ã‚Œã¾ã™\n",
    "\n",
    "è©³ç´°: [IMPLEMENTATION_ROADMAP.md](../IMPLEMENTATION_ROADMAP.md)\n",
    "\n",
    "v2.0 ã§ã¯ ä»¥ä¸‹ã‚’æ®µéšçš„ã«å®Ÿè£…ã—ã¾ã™ï¼š\n",
    "- **Phase 1**: Gemini LLM ã«ã‚ˆã‚‹å¤šå±¤å†—é•·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆï¼ˆGao et al. è„†å¼±æ€§å¯¾å¿œï¼‰\n",
    "- **Phase 2A**: æ”¹å–„ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã«ã‚ˆã‚‹LoRAæœ€é©åŒ–\n",
    "- **Phase 2B**: LCM è’¸ç•™ã«ã‚ˆã‚‹ 12x æ¨è«–é«˜é€ŸåŒ–\n",
    "- **Phase 3**: Image-to-Image + ControlNet + ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆå¯¾å¿œ\n",
    "- **Phase 4**: Streamlit UI + FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ + ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ãƒ–ãƒ­ã‚°è¨˜äº‹ã¨ã®å¯¾å¿œ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ãƒ–ãƒ­ã‚°ã® Day3-4 è¨˜äº‹ã§èª¬æ˜ã•ã‚ŒãŸLoRAå®Ÿè£…ç‰ˆã§ã™ã€‚\n",
    "ãƒ–ãƒ­ã‚°ã¨å®Œå…¨ã«æ•´åˆã—ã¦ãŠã‚Šã€è¨˜äº‹ã‚’èª­ã¿ãªãŒã‚‰å®Ÿè¡Œã™ã‚‹ã“ã¨ã§\n",
    "LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŸºç¤ã‚’å­¦ã¹ã¾ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "**æ¨å¥¨**: v2.0 ã® Phase 1-4 å®Ÿè£…ã‚’ãŠå¾…ã¡ãã ã•ã„ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde6cb9",
   "metadata": {},
   "source": [
    "## Step 1: ç’°å¢ƒç¢ºèªãƒ»GPU ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ã®ç¢ºèª\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a3648",
   "metadata": {},
   "source": [
    "## Step 2: ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpeftä¸è¦ - ç´”ç²‹PyTorch LoRAã‚’ä½¿ç”¨ï¼‰\n",
    "!pip install -q diffusers transformers pillow torch tqdm safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa666c",
   "metadata": {},
   "source": [
    "## Step 3: Google Drive ã«ãƒã‚¦ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Google Drive ã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
    "drive.mount('/content/drive')\n",
    "print(\"âœ… Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a13c1",
   "metadata": {},
   "source": [
    "## Step 4: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™\n",
    "\n",
    "**äº‹å‰æº–å‚™ (ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œå‰):**\n",
    "1. ãƒ­ãƒ¼ã‚«ãƒ«ã§ `python scripts/download_danbooru.py --limit 60` ã‚’å®Ÿè¡Œ\n",
    "2. ç”Ÿæˆã•ã‚ŒãŸ `training_data/` ãƒ•ã‚©ãƒ«ãƒ€ã‚’ Google Drive ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "3. ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d51897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Google Drive ã‹ã‚‰ training_data ã‚’ã‚³ãƒ”ãƒ¼\n",
    "drive_path = Path(\"/content/drive/MyDrive/training_data\")\n",
    "local_path = Path(\"/content/training_data\")\n",
    "\n",
    "if drive_path.exists():\n",
    "    print(f\"âœ… Found: {drive_path}\")\n",
    "    # ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ (é€Ÿåº¦å‘ä¸Š)\n",
    "    if not local_path.exists():\n",
    "        os.symlink(drive_path, local_path)\n",
    "        print(f\"âœ… Symlink created: {local_path}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ\n",
    "    import json\n",
    "    metadata_file = drive_path / \"metadata.json\"\n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"ğŸ“Š Dataset: {len(metadata.get('training_data', []))} images\")\n",
    "else:\n",
    "    print(f\"âŒ Not found: {drive_path}\")\n",
    "    print(\"\\nPlease upload training_data/ to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efa079",
   "metadata": {},
   "source": [
    "## Step 5: train_lora.py ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "GitHub ã‹ã‚‰æœ€æ–°ã® train_lora.py ã‚’å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "import urllib.request\n",
    "import socket\n",
    "from pathlib import Path\n",
    "\n",
    "# ã‚¹ãƒ†ãƒƒãƒ— 5: å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰&ãƒ‘ãƒƒãƒé©ç”¨\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“¥ Step 5: Download train_lora.py from GitHub & Apply Device Patches\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "output_dir = Path(\"/content/lora_weights\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"âœ… Output directory ready: {output_dir}\\n\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª\n",
    "training_data_dir = Path(\"/content/training_data\")\n",
    "print(f\"ğŸ” Checking training data directory: {training_data_dir}\")\n",
    "print(f\"   Exists: {training_data_dir.exists()}\")\n",
    "\n",
    "if training_data_dir.exists():\n",
    "    print(f\"\\nğŸ“‚ Directory structure:\")\n",
    "    style_dirs = []\n",
    "    for item in sorted(training_data_dir.iterdir()):\n",
    "        if item.is_dir() and not item.name.startswith(\".\"):\n",
    "            image_count = len(list(item.glob(\"*.png\"))) + len(list(item.glob(\"*.jpg\"))) + len(list(item.glob(\"*.jpeg\")))\n",
    "            print(f\"   ğŸ“ {item.name}/ ({image_count} images)\")\n",
    "            style_dirs.append(item)\n",
    "        elif item.is_file() and not item.name.startswith(\".\"):\n",
    "            print(f\"   ğŸ“„ {item.name}\")\n",
    "\n",
    "    total_images = len(list(training_data_dir.rglob(\"*.png\"))) \\\n",
    "                 + len(list(training_data_dir.rglob(\"*.jpg\"))) \\\n",
    "                 + len(list(training_data_dir.rglob(\"*.jpeg\")))\n",
    "    print(f\"\\nğŸ“Š Total images: {total_images}\")\n",
    "\n",
    "    if total_images == 0:\n",
    "        print(\"âš ï¸  WARNING: No images found!\")\n",
    "        print(\"   Structure should be: /content/training_data/<style_name>/*.png\")\n",
    "else:\n",
    "    print(\"âŒ training_data directory not found! Creating...\")\n",
    "    training_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ================== train_lora.py ã®å–å¾— ==================\n",
    "print(f\"\\nğŸ“¥ Locating train_lora.py...\")\n",
    "train_script = Path(\"/content/train_lora.py\")\n",
    "\n",
    "github_urls = [\n",
    "    \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/master/train_lora.py\",\n",
    "    \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/main/train_lora.py\",\n",
    "]\n",
    "\n",
    "downloaded = False\n",
    "\n",
    "def download_with_timeout(url, dest_path, timeout=15):\n",
    "    \"\"\"URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰\"\"\"\n",
    "    socket.setdefaulttimeout(timeout)\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            content = response.read()\n",
    "        with open(dest_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "    finally:\n",
    "        socket.setdefaulttimeout(None)\n",
    "\n",
    "for url in github_urls:\n",
    "    try:\n",
    "        print(f\"   Trying: {url[:60]}...\")\n",
    "        download_with_timeout(url, train_script)\n",
    "        print(f\"   âœ… Downloaded from GitHub\")\n",
    "        downloaded = True\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Failed: {str(e)[:60]}\")\n",
    "\n",
    "if not downloaded:\n",
    "    local_sources = [Path(\"./train_lora.py\"), Path(\"../train_lora.py\")]\n",
    "    for local_path in local_sources:\n",
    "        if local_path.exists():\n",
    "            shutil.copy(local_path, train_script)\n",
    "            print(f\"   âœ… Copied from {local_path}\")\n",
    "            downloaded = True\n",
    "            break\n",
    "\n",
    "if not downloaded:\n",
    "    raise FileNotFoundError(\n",
    "        \"train_lora.py not found. Run Step 5.5 (Fallback) to get it via git clone.\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nâœ… train_lora.py ready: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# ================== ãƒ‘ãƒƒãƒé©ç”¨ ==================\n",
    "print(f\"\\nğŸ”§ Applying patches...\")\n",
    "\n",
    "with open(train_script, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "patches_applied = 0\n",
    "\n",
    "# ãƒ‘ãƒƒãƒ 1: magnitude device fix\n",
    "p1_old = 'self.magnitude = nn.Parameter(torch.randn_like(original_weight[:rank]))'\n",
    "p1_new = 'self.magnitude = nn.Parameter(torch.randn_like(original_weight[:rank]).to(linear.weight.device))'\n",
    "if p1_old in content:\n",
    "    content = content.replace(p1_old, p1_new)\n",
    "    print(\"  âœ… Patch 1: magnitude device fix\")\n",
    "    patches_applied += 1\n",
    "else:\n",
    "    print(\"  â„¹ï¸  Patch 1: Already applied\")\n",
    "\n",
    "# ãƒ‘ãƒƒãƒ 2: use_qlora parameter ã‚’ train() ã«è¿½åŠ \n",
    "if 'def train(' in content and 'use_qlora' not in content:\n",
    "    # train() ã‚·ã‚°ãƒãƒãƒ£ã« use_qlora ã‚’è¿½åŠ \n",
    "    old_sig = 'save_interval: int = 5,\\n    ):'\n",
    "    new_sig = 'save_interval: int = 5,\\n        use_qlora: bool = True,\\n    ):'\n",
    "    if old_sig in content:\n",
    "        content = content.replace(old_sig, new_sig)\n",
    "        print(\"  âœ… Patch 2: use_qlora parameter added to train()\")\n",
    "        patches_applied += 1\n",
    "    else:\n",
    "        print(\"  âš ï¸  Patch 2: Could not inject use_qlora (manual fix may be needed)\")\n",
    "elif 'use_qlora' in content:\n",
    "    print(\"  â„¹ï¸  Patch 2: use_qlora already present\")\n",
    "\n",
    "# ãƒ‘ãƒƒãƒ 3: training_log ã® use_qlora ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¿½åŠ \n",
    "if '\"lora_alpha\": self.lora_alpha,' in content and '\"use_qlora\"' not in content:\n",
    "    old_log = '\"lora_alpha\": self.lora_alpha,\\n                },'\n",
    "    new_log = '\"lora_alpha\": self.lora_alpha,\\n                    \"use_qlora\": use_qlora,\\n                },'\n",
    "    if old_log in content:\n",
    "        content = content.replace(old_log, new_log)\n",
    "        print(\"  âœ… Patch 3: use_qlora added to training_log config\")\n",
    "        patches_applied += 1\n",
    "\n",
    "with open(train_script, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(f\"\\nâœ… {patches_applied} patches applied\")\n",
    "\n",
    "sys.path.insert(0, \"/content\")\n",
    "print(f\"âœ… Python path updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abb8fe",
   "metadata": {},
   "source": [
    "### Step 5.5: Fallback - Create train_lora.py from template (if download fails)\n",
    "\n",
    "If the download failed, run this cell to create the training script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "print(\"ğŸ”„ Fallback: Creating train_lora.py from git clone...\")\n",
    "train_script = Path(\"/content/train_lora.py\")\n",
    "\n",
    "if train_script.exists() and train_script.stat().st_size > 10000:\n",
    "    print(f\"âœ… train_lora.py already exists ({train_script.stat().st_size / 1024:.1f} KB)\")\n",
    "else:\n",
    "    print(f\"ğŸ“¥ Attempting to clone from GitHub...\\n\")\n",
    "    \n",
    "    success = False\n",
    "    \n",
    "    # æ–¹æ³• 1: git clone\n",
    "    try:\n",
    "        print(\"  1ï¸âƒ£  Trying: git clone\")\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"clone\", \"--depth\", \"1\", \n",
    "             \"https://github.com/Shion1124/anime-character-generator.git\",\n",
    "             \"/tmp/anime-gen\"],\n",
    "            capture_output=True,\n",
    "            timeout=60,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        src = Path(\"/tmp/anime-gen/train_lora.py\")\n",
    "        if src.exists() and src.stat().st_size > 10000:\n",
    "            shutil.copy(src, train_script)\n",
    "            print(f\"     âœ… Success! Cloned and copied train_lora.py\")\n",
    "            print(f\"     ğŸ“¦ Size: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "            success = True\n",
    "        else:\n",
    "            print(f\"     âš ï¸  Clone succeeded but file not found/too small\")\n",
    "    \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"     âš ï¸  Timeout (60s)\")\n",
    "    except Exception as e:\n",
    "        print(f\"     âš ï¸  Error: {str(e)[:60]}\")\n",
    "    \n",
    "    # æ–¹æ³• 2: pip install (if git clone failed)\n",
    "    if not success:\n",
    "        try:\n",
    "            print(f\"\\n  2ï¸âƒ£  Trying: pip install from repo\")\n",
    "            result = subprocess.run(\n",
    "                [\"pip\", \"install\", \"-q\", \n",
    "                 \"git+https://github.com/Shion1124/anime-character-generator.git\"],\n",
    "                capture_output=True,\n",
    "                timeout=120,\n",
    "                text=True\n",
    "            )\n",
    "            \n",
    "            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸã‹ç¢ºèª\n",
    "            import importlib.util\n",
    "            spec = importlib.util.find_spec(\"train_lora\")\n",
    "            if spec is not None:\n",
    "                print(f\"     âœ… Package installed successfully\")\n",
    "                success = True\n",
    "            else:\n",
    "                print(f\"     âš ï¸  Package installed but import failed\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"     âš ï¸  Error: {str(e)[:60]}\")\n",
    "    \n",
    "    # æ–¹æ³• 3: ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (if both above failed)\n",
    "    if not success:\n",
    "        try:\n",
    "            print(f\"\\n  3ï¸âƒ£  Trying: Direct download via urllib\")\n",
    "            import urllib.request\n",
    "            import socket\n",
    "            \n",
    "            urls = [\n",
    "                \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/master/train_lora.py\",\n",
    "                \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/main/train_lora.py\",\n",
    "            ]\n",
    "            \n",
    "            for url in urls:\n",
    "                try:\n",
    "                    socket.setdefaulttimeout(10)\n",
    "                    with urllib.request.urlopen(url) as response:\n",
    "                        content = response.read()\n",
    "                    \n",
    "                    with open(train_script, 'wb') as f:\n",
    "                        f.write(content)\n",
    "                    \n",
    "                    socket.setdefaulttimeout(None)\n",
    "                    print(f\"     âœ… Downloaded successfully\")\n",
    "                    print(f\"     ğŸ“¦ Size: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "                    success = True\n",
    "                    break\n",
    "                except Exception as url_error:\n",
    "                    socket.setdefaulttimeout(None)\n",
    "                    print(f\"     âš ï¸  {url[:50]}... failed\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"     âš ï¸  Error: {str(e)[:60]}\")\n",
    "\n",
    "# Final verification\n",
    "print(f\"\\n{'='*60}\")\n",
    "if not train_script.exists():\n",
    "    print(f\"âŒ FAILED: train_lora.py could not be obtained!\")\n",
    "    print(f\"\\nğŸ”§ Manual Solution:\")\n",
    "    print(f\"   1. Download from: https://github.com/Shion1124/anime-character-generator\")\n",
    "    print(f\"   2. Upload train_lora.py to /content/\")\n",
    "    print(f\"   3. Run Step 6 again\")\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not obtain train_lora.py from any source.\\n\"\n",
    "        f\"Please upload it manually to /content/train_lora.py\"\n",
    "    )\n",
    "elif train_script.stat().st_size < 10000:\n",
    "    print(f\"âš ï¸  WARNING: train_lora.py exists but is only {train_script.stat().st_size} bytes!\")\n",
    "    print(f\"   It may be incomplete. Consider re-downloading.\")\n",
    "else:\n",
    "    print(f\"âœ… SUCCESS: train_lora.py is ready!\")\n",
    "    print(f\"   ğŸ“ Location: {train_script}\")\n",
    "    print(f\"   ğŸ“¦ Size: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "    print(f\"   âœ¨ You can now run Step 6 (Training)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9975f",
   "metadata": {},
   "source": [
    "## Step 5.6: Emergency Fallback - Embedded train_lora.py\n",
    "\n",
    "If all other methods fail, this cell can create train_lora.py with embedded code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ†˜ Emergency Fallback: Create train_lora.py\\n\")\n",
    "\n",
    "train_script = Path(\"/content/train_lora.py\")\n",
    "\n",
    "if train_script.exists() and train_script.stat().st_size > 10000:\n",
    "    print(f\"âœ… train_lora.py already exists ({train_script.stat().st_size / 1024:.1f} KB)\")\n",
    "    print(\"   No need to use this cell\\n\")\n",
    "else:\n",
    "    print(\"ğŸ“ Options to get train_lora.py:\\n\")\n",
    "    print(\"Option 1: Upload from GitHub Web UI\")\n",
    "    print(\"  1. Go to: https://github.com/Shion1124/anime-character-generator/blob/master/train_lora.py\")\n",
    "    print(\"  2. Click 'Raw' button\")\n",
    "    print(\"  3. Save the page (Cmd+S)\")\n",
    "    print(\"  4. Upload to Colab and move to /content/\\n\")\n",
    "    \n",
    "    print(\"Option 2: Try alternative HTTP method (slow but may work):\")\n",
    "    try:\n",
    "        import time\n",
    "        print(\"  Attempting download...\")\n",
    "        \n",
    "        # Try with requests library if available\n",
    "        try:\n",
    "            import requests\n",
    "            url = \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/master/train_lora.py\"\n",
    "            response = requests.get(url, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                with open(train_script, 'w') as f:\n",
    "                    f.write(response.text)\n",
    "                print(f\"  âœ… Downloaded successfully using requests!\")\n",
    "                print(f\"     Size: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸  HTTP Error {response.status_code}\")\n",
    "        except:\n",
    "            # Fallback to urllib\n",
    "            import urllib.request\n",
    "            import ssl\n",
    "            \n",
    "            # SSL è¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ï¼ˆé–‹ç™ºç’°å¢ƒç”¨ï¼‰\n",
    "            ssl_context = ssl.create_default_context()\n",
    "            ssl_context.check_hostname = False\n",
    "            ssl_context.verify_mode = ssl.CERT_NONE\n",
    "            \n",
    "            url = \"https://raw.githubusercontent.com/Shion1124/anime-character-generator/master/train_lora.py\"\n",
    "            print(f\"  Trying: {url[:60]}...\")\n",
    "            \n",
    "            request = urllib.request.Request(url)\n",
    "            request.add_header('User-Agent', 'Mozilla/5.0')\n",
    "            \n",
    "            with urllib.request.urlopen(request, context=ssl_context, timeout=30) as response:\n",
    "                content = response.read().decode('utf-8')\n",
    "            \n",
    "            with open(train_script, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            \n",
    "            print(f\"  âœ… Downloaded successfully!\")\n",
    "            print(f\"     Size: {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸  Failed: {str(e)[:80]}\\n\")\n",
    "        print(\"Option 3: Manual creation\")\n",
    "        print(\"  If you have local access to the file:\")\n",
    "        print(\"  1. Mount Google Drive: !from google.colab import drive\")\n",
    "        print(\"  2. Copy from Drive: !cp /content/drive/MyDrive/train_lora.py /content/\")\n",
    "        print(\"  (Make sure to upload train_lora.py to your Google Drive first)\\n\")\n",
    "\n",
    "# Final status\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if train_script.exists() and train_script.stat().st_size > 10000:\n",
    "    print(f\"âœ… train_lora.py is ready!\")\n",
    "    print(f\"   ğŸ“ {train_script}\")\n",
    "    print(f\"   ğŸ“¦ {train_script.stat().st_size / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(f\"â„¹ï¸  train_lora.py not yet obtained\")\n",
    "    print(f\"   Try one of the options above, then run Step 6\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a21a9a",
   "metadata": {},
   "source": [
    "## Step 6: DoRA + QLoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "\n",
    "**DoRA (Dominant Rank Adaptation):** LoRA ã®é€²åŒ–ç‰ˆ  \n",
    "- **Magnitude**: ä½å‘¨æ³¢ã‚¹ã‚±ãƒ¼ãƒ«æˆåˆ†ï¼ˆç”»åƒå…¨ä½“ã®ç‰¹æ€§ï¼‰\n",
    "- **Direction**: é«˜å‘¨æ³¢æ–¹å‘æˆåˆ†ï¼ˆç´°éƒ¨ãƒ»ãƒã‚¤ã‚ºãƒ»ã‚¹ã‚¿ã‚¤ãƒ«è©³ç´°ï¼‰\n",
    "\n",
    "**QLoRA (Quantized LoRA):** æ··åˆç²¾åº¦å­¦ç¿’  \n",
    "- **Direction æˆåˆ†ã‚’ float16 é‡å­åŒ–** â†’ ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ï¼ˆï½60%ï¼‰\n",
    "- **Magnitude** ã¯é«˜ç²¾åº¦ã®ã¾ã¾ï¼ˆå­¦ç¿’å®‰å®šæ€§ï¼‰\n",
    "- T4 GPU ã§ã‚‚ rank=32-64 ã§è¨“ç·´å¯èƒ½\n",
    "\n",
    "**é‡è¦:** \n",
    "- æ¨™æº–: 20ï½30åˆ†ï¼ˆ10 ã‚¨ãƒãƒƒã‚¯, rank=32ï¼‰\n",
    "- QLoRA: åŒæ™‚é–“ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ 60% æ”¹å–„\n",
    "- Colab ã®æ¥ç¶šã‚’ä¿æŒã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb324c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import inspect\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ¯ Step 6: DoRA + QLoRA Training\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆT4 OOM å¯¾ç­–ç‰ˆï¼‰\n",
    "EPOCHS = 10\n",
    "LORA_RANK = 32\n",
    "BATCH_SIZE = 1  # 2 â†’ 1 (T4 OOM å¯¾ç­–)\n",
    "GRAD_ACCUM_STEPS = 4  # å‹¾é…è“„ç© (å®ŸåŠ¹ãƒãƒƒãƒ = 1 Ã— 4 = 4)\n",
    "LEARNING_RATE = 1e-5  # 1e-4 â†’ 1e-5 (NaN å¯¾ç­–)\n",
    "USE_QLORA = False  # True â†’ False (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ float32ã€å®‰å®šæ€§é‡è¦–)\n",
    "SAVE_INTERVAL = 5\n",
    "\n",
    "print(f\"\"\"\n",
    "âš™ï¸  Configuration (T4 Memory-Optimized):\n",
    "   Epochs: {EPOCHS}\n",
    "   LoRA Rank: {LORA_RANK}\n",
    "   Batch Size: {BATCH_SIZE} (reduced for T4 VRAM)\n",
    "   Gradient Accumulation: {GRAD_ACCUM_STEPS} steps (effective batch = {BATCH_SIZE * GRAD_ACCUM_STEPS})\n",
    "   Learning Rate: {LEARNING_RATE} (reduced from 1e-4)\n",
    "   QLoRA: {USE_QLORA} (disabled for numerical stability)\n",
    "   Mixed Precision: AMP enabled (autocast + GradScaler)\n",
    "   Gradient Checkpointing: enabled (VRAM ç¯€ç´„)\n",
    "   Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n",
    "\n",
    "ğŸ“ Memory optimizations:\n",
    "   - AMP (float16 forward, float32 gradients)\n",
    "   - Gradient checkpointing (recompute activations)\n",
    "   - Gradient accumulation (batch_size=1 Ã— 4 steps = effective 4)\n",
    "\"\"\")\n",
    "\n",
    "# VRAM ç¢ºèª\n",
    "if torch.cuda.is_available():\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"ğŸ“Š GPU VRAM: {total_mem:.1f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ VRAM cache cleared\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª\n",
    "training_data_dir = Path(\"/content/training_data\")\n",
    "total_images = len(list(training_data_dir.rglob(\"*.png\"))) \\\n",
    "             + len(list(training_data_dir.rglob(\"*.jpg\"))) \\\n",
    "             + len(list(training_data_dir.rglob(\"*.jpeg\")))\n",
    "\n",
    "print(f\"ğŸ“Š Dataset check: {total_images} images found\")\n",
    "if total_images == 0:\n",
    "    print(\"âŒ ERROR: No training images found!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "try:\n",
    "    train_script = Path(\"/content/train_lora.py\")\n",
    "    if not train_script.exists():\n",
    "        raise FileNotFoundError(f\"{train_script} not found! Run Step 5 first.\")\n",
    "\n",
    "    print(f\"âœ… train_lora.py found: {train_script.stat().st_size / 1024:.1f} KB\\n\")\n",
    "\n",
    "    sys.path.insert(0, \"/content\")\n",
    "\n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦æœ€æ–°ç‰ˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "    if \"train_lora\" in sys.modules:\n",
    "        del sys.modules[\"train_lora\"]\n",
    "\n",
    "    print(\"ğŸ“¦ Importing train_lora module...\")\n",
    "    from train_lora import LoRATrainer\n",
    "    print(\"âœ… Successfully imported LoRATrainer\\n\")\n",
    "\n",
    "    print(\"ğŸš€ Initializing DoRA trainer (AMP mixed precision)...\")\n",
    "    trainer = LoRATrainer(\n",
    "        model_id=\"runwayml/stable-diffusion-v1-5\",\n",
    "        output_dir=\"/content/lora_weights\",\n",
    "        lora_rank=LORA_RANK,\n",
    "        lora_alpha=LORA_RANK,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "    # train() ãŒå„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‹å‹•çš„ã«ç¢ºèª\n",
    "    train_sig = inspect.signature(trainer.train)\n",
    "    train_kwargs = {\n",
    "        \"data_dir\": \"/content/training_data\",\n",
    "        \"num_epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"save_interval\": SAVE_INTERVAL,\n",
    "    }\n",
    "\n",
    "    if \"use_qlora\" in train_sig.parameters:\n",
    "        train_kwargs[\"use_qlora\"] = USE_QLORA\n",
    "    if \"gradient_accumulation_steps\" in train_sig.parameters:\n",
    "        train_kwargs[\"gradient_accumulation_steps\"] = GRAD_ACCUM_STEPS\n",
    "\n",
    "    print(f\"ğŸ“ Starting training ({EPOCHS} epochs Ã— {total_images} images)...\")\n",
    "    print(f\"   {'âœ… QLoRA enabled (float16)' if USE_QLORA else 'âœ… Using float32 (numerically stable)'}\")\n",
    "    print(f\"   âš¡ AMP + Gradient Checkpointing enabled\\n\")\n",
    "\n",
    "    training_log = trainer.train(**train_kwargs)\n",
    "\n",
    "    print(f\"\\nâœ… Training completed!\")\n",
    "\n",
    "    if training_log:\n",
    "        history = training_log.get(\"history\", [])\n",
    "        status = training_log.get(\"status\", \"unknown\")\n",
    "        print(f\"   Status: {status}\")\n",
    "        print(f\"   Epochs completed: {len(history)}\")\n",
    "        if history:\n",
    "            initial_loss = history[0].get('loss', float('nan'))\n",
    "            final_loss = history[-1].get('loss', float('nan'))\n",
    "            print(f\"   Initial loss: {initial_loss:.6f}\")\n",
    "            print(f\"   Final loss:   {final_loss:.6f}\")\n",
    "            \n",
    "            # æ”¹å–„åº¦ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "            if initial_loss > 0 and final_loss < initial_loss:\n",
    "                improvement = (initial_loss - final_loss) / initial_loss * 100\n",
    "                print(f\"   ğŸ¯ Improvement: {improvement:.1f}%\")\n",
    "            elif final_loss > initial_loss:\n",
    "                print(f\"   âš ï¸  Loss increased - training may be unstable\")\n",
    "            \n",
    "            # NaN æ¤œå‡ºæ•°ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "            valid_epochs = sum(1 for h in history if not (h.get('loss', 0) <= 0 or h.get('loss', float('inf')) > 1000))\n",
    "            print(f\"   âœ… Valid epochs: {valid_epochs}/{len(history)}\")\n",
    "\n",
    "except FileNotFoundError as fe:\n",
    "    print(f\"\\nâŒ File Not Found: {fe}\")\n",
    "    print(f\"   Run Step 5 (and Step 5.5 if needed) to obtain train_lora.py\")\n",
    "\n",
    "except ImportError as ie:\n",
    "    print(f\"\\nâŒ Import Error: {ie}\")\n",
    "    import subprocess\n",
    "    subprocess.run(\n",
    "        [\"pip\", \"install\", \"-q\", \"diffusers\", \"transformers\", \"pillow\", \"tqdm\", \"safetensors\"],\n",
    "        timeout=120\n",
    "    )\n",
    "    print(\"âœ… Dependencies installed. Please re-run this cell.\")\n",
    "    raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Training error: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "    print(f\"\\nğŸ” Diagnostic:\")\n",
    "    print(f\"   Python {sys.version.split()[0]}, PyTorch {torch.__version__}\")\n",
    "    print(f\"   CUDA: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   GPU: {torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB)\")\n",
    "        print(f\"   VRAM allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "        print(f\"   VRAM reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
    "\n",
    "    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ä¿å­˜\n",
    "    import json\n",
    "    output_dir = Path(\"/content/lora_weights\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    error_log = {\n",
    "        \"error\": str(e),\n",
    "        \"error_type\": type(e).__name__,\n",
    "        \"traceback\": traceback.format_exc(),\n",
    "        \"config\": {\"epochs\": EPOCHS, \"rank\": LORA_RANK, \"batch_size\": BATCH_SIZE,\n",
    "                   \"gradient_accumulation_steps\": GRAD_ACCUM_STEPS,\n",
    "                   \"learning_rate\": LEARNING_RATE, \"use_qlora\": USE_QLORA, \"images\": total_images}\n",
    "    }\n",
    "    with open(output_dir / \"error_log.json\", \"w\") as f:\n",
    "        json.dump(error_log, f, indent=2)\n",
    "    print(f\"   Error saved to: /content/lora_weights/error_log.json\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a21c5c",
   "metadata": {},
   "source": [
    "## Step 7: å­¦ç¿’çµæœã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"ğŸ” Training Result Verification...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª\n",
    "output_dir = Path(\"/content/lora_weights\")\n",
    "print(f\"ğŸ“ Output directory: {output_dir}\")\n",
    "print(f\"   Exists: {output_dir.exists()}\")\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"\\nğŸ“‚ Contents:\")\n",
    "    for file in sorted(output_dir.glob(\"*\")):\n",
    "        if file.is_file():\n",
    "            size = file.stat().st_size\n",
    "            if size > 1024*1024:\n",
    "                print(f\"   {file.name:40s} {size/(1024*1024):>8.2f} MB\")\n",
    "            else:\n",
    "                print(f\"   {file.name:40s} {size:>8.0f} bytes\")\n",
    "\n",
    "# å­¦ç¿’ãƒ­ã‚°ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "log_file = Path(\"/content/lora_weights/training_log.json\")\n",
    "print(f\"\\nğŸ” Looking for training_log.json...\")\n",
    "print(f\"   Path: {log_file}\")\n",
    "print(f\"   Exists: {log_file.exists()}\")\n",
    "\n",
    "if not log_file.exists():\n",
    "    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨ºæ–­\n",
    "    print(\"\\nâš ï¸  training_log.json not found!\")\n",
    "    print(\"\\nğŸ”´ Possible causes:\")\n",
    "    print(\"   1. Training failed silently (check AnimeDataset)\")\n",
    "    print(\"   2. No images in training_data/\")\n",
    "    print(\"   3. Exception during training (check stderr)\")\n",
    "    print(\"   4. Output directory not created\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª\n",
    "    data_dir = Path(\"/content/training_data\")\n",
    "    if data_dir.exists():\n",
    "        print(f\"\\nğŸ“Š Dataset check:\")\n",
    "        total_images = len(list(data_dir.rglob(\"*.png\"))) + len(list(data_dir.rglob(\"*.jpg\")))\n",
    "        print(f\"   Images found: {total_images}\")\n",
    "        if total_images == 0:\n",
    "            print(\"   âŒ No images found! Training cannot proceed.\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ Data directory not found: {data_dir}\")\n",
    "else:\n",
    "    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿\n",
    "    try:\n",
    "        with open(log_file) as f:\n",
    "            training_log = json.load(f)\n",
    "        \n",
    "        print(\"\\nâœ… training_log.json loaded successfully\")\n",
    "        \n",
    "        # å­¦ç¿’ãŒå®Ÿè¡Œã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯\n",
    "        history = training_log.get(\"history\", [])\n",
    "        if len(history) == 0:\n",
    "            print(\"âš ï¸  Warning: history is empty (no epochs completed)\")\n",
    "            print(\"   Config:\", json.dumps(training_log.get(\"config\", {}), indent=2))\n",
    "        else:\n",
    "            # å­¦ç¿’æ›²ç·šã‚’è¡¨ç¤º\n",
    "            losses = [h['loss'] for h in history]\n",
    "            epochs = list(range(1, len(losses) + 1))\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(epochs, losses, 'b-', linewidth=2, marker='o')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('DoRA Training Loss Curve')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.yscale('log')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('/content/training_curve.png', dpi=100)\n",
    "            plt.show()\n",
    "            \n",
    "            # çµ±è¨ˆæƒ…å ±\n",
    "            print(f\"\\nâœ… Training completed successfully!\")\n",
    "            print(f\"ğŸ“Š Total epochs: {len(losses)}\")\n",
    "            print(f\"ğŸ“‰ Final loss: {losses[-1]:.6f}\")\n",
    "            print(f\"ğŸ“ˆ Initial loss: {losses[0]:.6f}\")\n",
    "            if losses[0] > losses[-1]:\n",
    "                improvement = (losses[0] - losses[-1]) / losses[0] * 100\n",
    "                print(f\"ğŸ¯ Loss improvement: {improvement:.1f}%\")\n",
    "            else:\n",
    "                print(f\"âš ï¸  Loss increased (may indicate training issues)\")\n",
    "            \n",
    "            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®šè¡¨ç¤º\n",
    "            config = training_log.get(\"config\", {})\n",
    "            print(f\"\\nâš™ï¸  Training config:\")\n",
    "            for key, value in config.items():\n",
    "                print(f\"   {key}: {value}\")\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\nâŒ Error parsing training_log.json: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc79c7",
   "metadata": {},
   "source": [
    "## Step 6.5: Diagnostic - Check training status and fix issues\n",
    "\n",
    "Run this if training failed or training_log.json is missing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc4431",
   "metadata": {},
   "source": [
    "## Step 8: LoRA é‡ã¿ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4545af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "lora_dir = Path(\"/content/lora_weights\")\n",
    "print(\"ğŸ“ Output files:\")\n",
    "print()\n",
    "\n",
    "for file in sorted(lora_dir.glob(\"*\")):\n",
    "    if file.is_file():\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {file.name:40s} {size_mb:>8.2f} MB\")\n",
    "\n",
    "# ãƒ¡ã‚¤ãƒ³ã® LoRA é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "lora_model = lora_dir / \"anime-impressionist-lora.safetensors\"\n",
    "if lora_model.exists():\n",
    "    size_mb = lora_model.stat().st_size / (1024 * 1024)\n",
    "    print(f\"\\nâœ… Main LoRA weights: {lora_model.name} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d7328",
   "metadata": {},
   "source": [
    "## Step 9: Google Drive ã«çµæœã‚’ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f330d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’æ¸ˆã¿ LoRA é‡ã¿ã‚’ Google Drive ã«ä¿å­˜\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "lora_weights_dir = Path(\"/content/lora_weights\")\n",
    "drive_output_dir = Path(\"/content/drive/MyDrive/lora_weights\")\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "drive_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
    "for file in lora_weights_dir.glob(\"*\"):\n",
    "    if file.is_file():\n",
    "        destination = drive_output_dir / file.name\n",
    "        shutil.copy2(file, destination)\n",
    "        print(f\"âœ… Saved: {file.name}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Output saved to: {drive_output_dir}\")\n",
    "print(\"\\nğŸ’¾ Download instructions:\")\n",
    "print(\"1. Open Google Drive\")\n",
    "print(\"2. Navigate to /lora_weights/\")\n",
    "print(\"3. Download 'anime-impressionist-lora.safetensors'\")\n",
    "print(\"4. Place in: anime-character-generator/ root directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb12ff",
   "metadata": {},
   "source": [
    "## Step 10: æ¨è«–ãƒ†ã‚¹ãƒˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ LoRA ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA ã‚’ä½¿ç”¨ã—ãŸæ¨è«–ãƒ†ã‚¹ãƒˆ\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "print(\"â³ Loading model...\")\n",
    "\n",
    "# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# LoRA é‡ã¿ãƒ­ãƒ¼ãƒ‰\n",
    "try:\n",
    "    # PEFT ã‚’ä½¿ç”¨ã—ãŸ LoRA ãƒ­ãƒ¼ãƒ‰\n",
    "    from peft import PeftModel\n",
    "    # (LoRA ãƒ­ãƒ¼ãƒ‰å®Ÿè£…)\n",
    "    print(\"âœ… LoRA weights loaded\")\n",
    "except:\n",
    "    print(\"âš ï¸ LoRA loading requires additional setup\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "prompt = \"1girl, watercolor painting style, masterpiece, high quality, anime\"\n",
    "negative_prompt = \"low quality, nsfw\"\n",
    "\n",
    "print(f\"\\nğŸ¨ Generating: {prompt}...\")\n",
    "\n",
    "# ç”»åƒç”Ÿæˆ\n",
    "with torch.no_grad():\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=512,\n",
    "        width=512,\n",
    "        num_inference_steps=20,\n",
    "        guidance_scale=7.0\n",
    "    ).images[0]\n",
    "\n",
    "# çµæœè¡¨ç¤º\n",
    "image.save(\"/content/test_output.png\")\n",
    "print(\"âœ… Image saved: test_output.png\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20208be4",
   "metadata": {},
   "source": [
    "## âœ… å®Œäº†ï¼\n",
    "\n",
    "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**\n",
    "1. LoRA é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "2. ãƒ­ãƒ¼ã‚«ãƒ«ã§ `character_generator.py --use_lora=True` ã§æ¨è«–\n",
    "3. çµæœã‚’ç¢ºèª\n",
    "\n",
    "**å‚è€ƒ:**\n",
    "- [GitHub ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/Shion1124/anime-character-generator)\n",
    "- [HuggingFace ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/runwayml/stable-diffusion-v1-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5464a",
   "metadata": {},
   "source": [
    "## Step 11: HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ LoRA ãƒ¢ãƒ‡ãƒ«ã‚’ HuggingFace Model Hub ã§å…¬é–‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1041206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# èªè¨¼ï¼ˆäº‹å‰ã« huggingface-cli login ã‚’å®Ÿè¡Œï¼‰\n",
    "api = HfApi()\n",
    "\n",
    "# ãƒªãƒã‚¸ãƒˆãƒªè¨­å®š\n",
    "username = \"YOUR_USERNAME\"  # è‡ªåˆ†ã® HuggingFace ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«å¤‰æ›´\n",
    "repo_name = \"anime-impressionist-lora\"\n",
    "repo_id = f\"{username}/{repo_name}\"\n",
    "\n",
    "print(f\"ğŸš€ HuggingFace Hub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {repo_id}\")\n",
    "\n",
    "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆREADME.mdä½œæˆ\n",
    "readme_content = \"\"\"# ğŸ¨ anime-impressionist-lora\n",
    "\n",
    "**æ–‡ä½“:** å°è±¡æ´¾é¢¨ã€æ°´å½©ç”»é¢¨ã€ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼  \n",
    "**ãƒ¢ãƒ‡ãƒ«:** Stable Diffusion v1.5 + LoRA (Low-Rank Adaptation)  \n",
    "**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:** ç´„ 4 MB (è»½é‡ãƒ»é«˜é€Ÿ)\n",
    "\n",
    "## ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±\n",
    "\n",
    "| é …ç›® | è©³ç´° |\n",
    "|------|------|\n",
    "| **ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«** | `runwayml/stable-diffusion-v1-5` |\n",
    "| **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•** | LoRA (PEFT) |\n",
    "| **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿** | Danbooru 300 æš (5 ã‚¹ã‚¿ã‚¤ãƒ«) |\n",
    "| **å­¦ç¿’æ™‚é–“** | ç´„ 1-2 æ™‚é–“ (Colab T4 GPU) |\n",
    "| **LoRA ãƒ©ãƒ³ã‚¯** | 8 |\n",
    "| **LoRA ã‚¢ãƒ«ãƒ•ã‚¡** | 32 |\n",
    "\n",
    "## ğŸš€ ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "### æ–¹æ³• 1: diffusers + PEFT (æ¨å¥¨)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe.unet = PeftModel.from_pretrained(\n",
    "    pipe.unet,\n",
    "    \"{repo_id}\",\n",
    "    adapter_name=\"anime_lora\"\n",
    ")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"1girl, watercolor painting style, masterpiece, anime\"\n",
    "image = pipe(prompt=prompt, num_inference_steps=20).images[0]\n",
    "image.save(\"output.png\")\n",
    "```\n",
    "\n",
    "## ğŸ“ˆ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è©³ç´°\n",
    "\n",
    "- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: Danbooru 300 æš (5 ã‚¹ã‚¿ã‚¤ãƒ«)\n",
    "- **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: lr=1e-4, rank=8, alpha=32\n",
    "- **ã‚¨ãƒãƒƒã‚¯**: 50\n",
    "- **æœ€é©åŒ–**: AdamW\n",
    "\n",
    "## ğŸ“‹ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n",
    "\n",
    "[OpenRAIL License](https://huggingface.co/spaces/CompVis/stable-diffusion-license)\n",
    "\n",
    "## ğŸ¤ å‚è€ƒ\n",
    "\n",
    "- [anime-character-generator](https://github.com/Shion1124/anime-character-generator)\n",
    "- [PEFT Documentation](https://github.com/huggingface/peft)\n",
    "\"\"\"\n",
    "\n",
    "# README.md ã‚’ä¸€æ™‚ä¿å­˜\n",
    "readme_path = Path(lora_weights_dir) / \"README.md\"\n",
    "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"âœ… README.md ã‚’ç”Ÿæˆã—ã¾ã—ãŸ ({len(readme_content)} æ–‡å­—)\")\n",
    "\n",
    "# ãƒªãƒã‚¸ãƒˆãƒªä½œæˆï¼ˆæ—¢å­˜ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰\n",
    "try:\n",
    "    api.create_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True, private=False)\n",
    "    print(f\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆ: {repo_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ: {e}\")\n",
    "\n",
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "files_to_upload = [\n",
    "    (\"anime-impressionist-lora.safetensors\", \"LoRA é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«\"),\n",
    "    (\"adapter_config.json\", \"LoRA è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«\"),\n",
    "    (\"training_log.json\", \"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°\"),\n",
    "    (\"README.md\", \"ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰\")\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "for filename, description in files_to_upload:\n",
    "    file_path = Path(lora_weights_dir) / filename\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"âš ï¸ {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (ã‚¹ã‚­ãƒƒãƒ—)\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=str(file_path),\n",
    "            path_in_repo=filename,\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "        file_size = file_path.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"âœ… {filename} ({file_size:.1f} MB) - {description}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {filename}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ‰ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼\")\n",
    "print(f\"ğŸ“ ãƒ¢ãƒ‡ãƒ« URL: https://huggingface.co/{repo_id}\")\n",
    "print(f\"ğŸ’¡ ä½¿ç”¨æ–¹æ³•: model = {repo_id}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
