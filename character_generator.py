#!/usr/bin/env python3
"""
anime-character-generator v2.0 (Development)
Stable Diffusion v1.5 + LLM Ã— è«–æ–‡ãƒ™ãƒ¼ã‚¹æ”¹å–„

ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã€‘  
Version: 2.0 (Phase 1-4 å®Ÿè£…ä¸­)
Date: 2026-02-19ã€œ
Status: æ”¹å–„ç‰ˆ å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º

ã€v1.5 ã‹ã‚‰ã®æ”¹å–„ã€‘
âœ… Phase 1: Gemini LLM ã«ã‚ˆã‚‹å¤šå±¤å†—é•·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (Gao et al. å¯¾å¿œ)
ğŸ”„ Phase 2A: æ”¹å–„ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªæœ€é©åŒ–æ‰‹æ³•ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–ï¼ˆv1.5ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
ğŸ”„ Phase 2B: LCM è’¸ç•™ã«ã‚ˆã‚‹ 12x æ¨è«–é«˜é€ŸåŒ–
ğŸ”„ Phase 3: Image-to-Image + ControlNet ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ
ğŸ”„ Phase 4: API + UI + ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤

è©³ç´°: IMPLEMENTATION_ROADMAP.md, PHASE_[1-4]_*.md å‚ç…§

ä½¿ç”¨ä¾‹:
    python character_generator.py --emotion happy --style casual
    python character_generator.py --all
    python character_generator.py --use-robust-prompt --emotion happy --style formal
"""

import argparse
import os
import torch
from pathlib import Path
from diffusers import StableDiffusionPipeline
from PIL import Image, ImageDraw, ImageFont
import re

try:
    from prompt_optimizer import RobustPromptGenerator
    HAS_ROBUST_PROMPT = True
except ImportError:
    HAS_ROBUST_PROMPT = False
    print("âš ï¸  RobustPromptGenerator not available. Use --use-robust-prompt to enable.")


class AnimeCharacterGenerator:
    def __init__(self, device: str = "auto", use_robust_prompt: bool = False):
        """
        åˆæœŸåŒ–
        
        Args:
            device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹ ('cuda', 'cpu', or 'auto')
            use_robust_prompt: RobustPromptGenerator ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        if device == "auto":
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
            
        self.dtype = torch.float16 if self.device == "cuda" else torch.float32
        
        print(f"ğŸ“¦ Device: {self.device} | Dtype: {self.dtype}")
        print(f"âœ“ GPU Available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"âœ“ GPU: {torch.cuda.get_device_name(0)}")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        print("\nğŸ“¦ Loading Stable Diffusion v1.5...")
        self.pipe = StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=self.dtype,
            safety_checker=None
        )
        self.pipe = self.pipe.to(self.device)
        self.pipe.enable_attention_slicing()
        print("âœ… Model ready!")
        
        # RobustPromptGenerator åˆæœŸåŒ–
        self.robust_prompt_generator = None
        if use_robust_prompt and HAS_ROBUST_PROMPT:
            try:
                print("\nğŸ“¦ Loading RobustPromptGenerator...")
                self.robust_prompt_generator = RobustPromptGenerator()
                print("âœ… RobustPromptGenerator ready!")
            except Exception as e:
                print(f"âš ï¸  Failed to load RobustPromptGenerator: {e}")
                self.robust_prompt_generator = None
        
        # ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.base_prompt = "1girl, anime character, masterpiece, high quality"
        
        # æ„Ÿæƒ…å®šç¾©
        self.emotions = {
            "happy": "happy smile, cheerful, joyful",
            "angry": "angry expression, intense eyes",
            "sad": "sad expression, melancholic",
            "surprised": "surprised expression, wide eyes"
        }
        
        # ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
        self.styles = {
            "with_hat": "wearing hat, stylish, fashionable",
            "with_earrings": "wearing earrings, jewelry, elegant",
            "with_makeup": "with makeup, beautiful, glamorous",
            "formal": "wearing formal dress, elegant, professional",
            "casual": "casual outfit, relaxed, friendly",
            "long_hair": "long brown hair, soft flowing hair",
            "blush": "soft blush on cheeks",
            "fireplace": "warm fireplace in background",
            "warm_lighting": "warm ambient lighting, soft orange glow",
            "cozy_room": "cozy indoor setting",
            "bokeh": "cinematic bokeh lights",
            "portrait": "upper body portrait",
            "depth_of_field": "shallow depth of field",
            "high_detail": "highly detailed",
            "soft_shading": "soft anime shading",
            "masterpiece": "masterpiece, best quality"
        }
    
    def generate_image(
        self,
        prompt: str,
        output_path: str = None,
        num_inference_steps: int = 20,
        guidance_scale: float = 7.0,
        height: int = 512,
        width: int = 512,
        seed: int = None,
    ) -> Image.Image:
        """
        å˜ä¸€ç”»åƒç”Ÿæˆ
        
        Args:
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            output_path: ä¿å­˜å…ˆãƒ‘ã‚¹
            num_inference_steps: æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°
            guidance_scale: ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¹ã‚±ãƒ¼ãƒ«
            height: ç”»åƒé«˜ã•
            width: ç”»åƒå¹…
            seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰
            
        Returns:
            PIL Image
        """
        
        if seed is not None:
            torch.manual_seed(seed)
        
        with torch.no_grad():
            image = self.pipe(
                prompt=prompt,
                negative_prompt="low quality, blurry",
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                height=height,
                width=width
            ).images[0]
        
        if output_path:
            os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
            image.save(output_path)
            print(f"  âœ… Saved: {output_path}")
        
        return image
    
    def generate_image_with_optimized_prompt(
        self,
        emotion: str,
        style: str,
        output_path: str = None,
        num_inference_steps: int = 20,
        guidance_scale: float = 7.0,
        height: int = 512,
        width: int = 512,
        seed: int = None,
    ) -> tuple:
        """
        RobustPromptGenerator ã‚’ä½¿ç”¨ã—ãŸæœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç”»åƒç”Ÿæˆ
        
        Args:
            emotion: æ„Ÿæƒ…ï¼ˆ"happy", "angry", "sad", "surprised"ï¼‰
            style: ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆstyles è¾æ›¸ã®ã‚­ãƒ¼ï¼‰
            output_path: ä¿å­˜å…ˆãƒ‘ã‚¹
            num_inference_steps: æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°
            guidance_scale: ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¹ã‚±ãƒ¼ãƒ«
            height: ç”»åƒé«˜ã•
            width: ç”»åƒå¹…
            seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        
        Returns:
            (PIL.Image, prompt_info) ã®ã‚¿ãƒ—ãƒ«
        """
        
        if not self.robust_prompt_generator:
            print("âš ï¸  RobustPromptGenerator not available, using fallback...")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            emotion_desc = self.emotions.get(emotion, emotion)
            style_desc = self.styles.get(style, style)
            prompt = f"{self.base_prompt}, {emotion_desc}, {style_desc}"
            
            image = self.generate_image(
                prompt=prompt,
                output_path=output_path,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                height=height,
                width=width,
                seed=seed
            )
            
            return image, {
                "positive_prompt": prompt,
                "negative_prompt": "low quality, blurry",
                "confidence": 0.5,
                "method": "fallback"
            }
        
        # RobustPromptGenerator ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt_info = self.robust_prompt_generator.generate_prompt(
            emotion=emotion,
            style=style,
            quality_level="masterpiece"
        )
        
        final_prompt = prompt_info["positive_prompt"]
        negative_prompt = prompt_info["negative_prompt"]
        
        print(f"\nğŸ¤– Optimized Prompt (Confidence: {prompt_info['confidence']:.2f}):")
        print(f"  Positive: {final_prompt[:80]}...")
        print(f"  Negative: {negative_prompt[:80]}...")
        
        if seed is not None:
            torch.manual_seed(seed)
        
        with torch.no_grad():
            image = self.pipe(
                prompt=final_prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                height=height,
                width=width
            ).images[0]
        
        if output_path:
            os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
            image.save(output_path)
            print(f"  âœ… Saved: {output_path}")
        
        return image, prompt_info
    
    def generate_emotions(self, output_dir: str = "./outputs/emotions") -> dict:
        """
        å…¨æ„Ÿæƒ…ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        
        Returns:
            {emotion_name: PIL.Image} ã®è¾æ›¸
        """
        print("\nğŸ­ GENERATING EMOTIONS...\n")
        os.makedirs(output_dir, exist_ok=True)
        
        results = {}
        for emotion_name, emotion_desc in self.emotions.items():
            prompt = f"{self.base_prompt}, {emotion_desc}"
            print(f"  [{emotion_name.upper()}] Generating...", end="", flush=True)
            
            filepath = os.path.join(output_dir, f"character_{emotion_name}.png")
            image = self.generate_image(prompt, filepath)
            results[emotion_name] = image
        
        print(f"\nâœ… Emotions generation complete!")
        return results
    
    def generate_styles(self, output_dir: str = "./outputs/styles") -> dict:
        """
        å…¨ã‚¹ã‚¿ã‚¤ãƒ«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        
        Returns:
            {style_name: PIL.Image} ã®è¾æ›¸
        """
        print("\nğŸ‘— GENERATING STYLES...\n")
        os.makedirs(output_dir, exist_ok=True)
        
        results = {}
        for style_name, style_desc in self.styles.items():
            prompt = f"{self.base_prompt}, {style_desc}"
            print(f"  [{style_name.upper()}] Generating...", end="", flush=True)
            
            filepath = os.path.join(output_dir, f"character_{style_name}.png")
            image = self.generate_image(prompt, filepath)
            results[style_name] = image
        
        print(f"\nâœ… Styles generation complete!")
        return results
    
    def generate_all(self):
        """å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ + çµæœè¡¨ç¤º"""
        emotion_images = self.generate_emotions()
        style_images = self.generate_styles()
        
        # ã‚°ãƒªãƒƒãƒ‰å½¢å¼ã§åˆæˆ
        print("\nğŸ“Š Creating composite grid images...")
        self._create_grid_composite(emotion_images, "emotion_results", rows=2, cols=2)
        self._create_grid_composite(style_images, "style_results", rows=2, cols=4)
        
        print("\n" + "="*60)
        print("âœ… GENERATION COMPLETE!")
        print("="*60)
        print(f"\nğŸ“ Generated {len(emotion_images) + len(style_images)} images")
        print(f"ğŸ“ Output directory: ./outputs/")
    
    def _get_next_version(self, base_filename: str) -> str:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’å–å¾—
        ä¾‹: style_results_v1.png â†’ style_results_v2.png
        """
        output_dir = "./outputs"
        existing_files = []
        
        if os.path.exists(output_dir):
            existing_files = os.listdir(output_dir)
        
        # ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åã«åˆè‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        pattern = rf'^{re.escape(base_filename)}_v(\d+)\.png$'
        versions = []
        
        for fn in existing_files:
            match = re.match(pattern, fn)
            if match:
                versions.append(int(match.group(1)))
        
        # æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯æœ€å¤§å€¤+1ã€ãªã„å ´åˆã¯1
        next_version = max(versions) + 1 if versions else 1
        return f"{base_filename}_v{next_version}.png"
    
    def _create_grid_composite(
        self, 
        images: dict, 
        base_filename: str,
        rows: int = 2, 
        cols: int = 2,
        img_size: int = 512,
        gap: int = 10
    ):
        """
        è¤‡æ•°ç”»åƒã‚’ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§åˆæˆ
        
        Args:
            images: {name: PIL.Image} ã®è¾æ›¸
            base_filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ãªã—ï¼‰
            rows: ã‚°ãƒªãƒƒãƒ‰è¡Œæ•°
            cols: ã‚°ãƒªãƒƒãƒ‰åˆ—æ•°
            img_size: å„ç”»åƒã®ã‚µã‚¤ã‚º
            gap: ç”»åƒé–“ã®ã‚®ãƒ£ãƒƒãƒ—
        """
        os.makedirs("./outputs", exist_ok=True)
        
        # ä½¿ç”¨ã™ã‚‹ç”»åƒã‚’å–å¾—ï¼ˆæœ€å¤§ rows*colsï¼‰
        use_images = list(images.items())[:rows*cols]
        
        # ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºè¨ˆç®—
        canvas_width = cols * img_size + (cols - 1) * gap + gap * 2
        canvas_height = rows * img_size + (rows - 1) * gap + gap * 2
        
        # ã‚­ãƒ£ãƒ³ãƒã‚¹ä½œæˆï¼ˆç™½èƒŒæ™¯ï¼‰
        canvas = Image.new('RGB', (canvas_width, canvas_height), color='white')
        
        # å„ç”»åƒã‚’ãƒšãƒ¼ã‚¹ãƒˆ
        for idx, (name, img) in enumerate(use_images):
            row = idx // cols
            col = idx % cols
            
            # ãƒšãƒ¼ã‚¹ãƒˆä½ç½®
            x = gap + col * (img_size + gap)
            y = gap + row * (img_size + gap)
            
            # ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã¦ãƒšãƒ¼ã‚¹ãƒˆ
            resized_img = img.resize((img_size, img_size), Image.Resampling.LANCZOS)
            canvas.paste(resized_img, (x, y))
        
        # æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’å–å¾—ã—ã¦ä¿å­˜
        output_filename = self._get_next_version(base_filename)
        output_path = f"./outputs/{output_filename}"
        
        canvas.save(output_path, quality=95)
        print(f"  âœ… Saved: {output_filename}")
    
    def _display_results(self, images: dict, output_file: str, rows: int, cols: int):
        """çµæœç”»åƒã‚’è¡¨ç¤ºãƒ»ä¿å­˜ï¼ˆéæ¨å¥¨ï¼šäº’æ›æ€§ã§æ®‹ã™ï¼‰"""
        # ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ _create_grid_composite ã«ç½®ãæ›ã‚ã£ãŸ
        pass


def main():
    parser = argparse.ArgumentParser(description="ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è‡ªå‹•ç”Ÿæˆ")
    parser.add_argument("--emotion", choices=["happy", "angry", "sad", "surprised"],
                       help="æ„Ÿæƒ…ã‚’æŒ‡å®š")
    parser.add_argument("--style", 
                       choices=["with_hat", "with_earrings", "with_makeup", "formal", "casual",
                               "long_hair", "blush", "fireplace", "warm_lighting", "cozy_room",
                               "bokeh", "portrait", "depth_of_field", "high_detail", 
                               "soft_shading", "masterpiece"],
                       help="ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®š")
    parser.add_argument("--all", action="store_true", help="å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ")
    parser.add_argument("--device", choices=["cuda", "cpu"], default="auto",
                       help="å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹")
    parser.add_argument("--use-robust-prompt", action="store_true",
                       help="RobustPromptGenerator (Gemini) ã‚’ä½¿ç”¨ã—ã¦æœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ")
    
    args = parser.parse_args()
    
    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿åˆæœŸåŒ–
    generator = AnimeCharacterGenerator(
        device=args.device,
        use_robust_prompt=args.use_robust_prompt
    )
    
    if args.all:
        generator.generate_all()
    elif args.emotion and args.style:
        # ç‰¹å®šã®æ„Ÿæƒ…+ã‚¹ã‚¿ã‚¤ãƒ«ã§ç”Ÿæˆ
        if args.use_robust_prompt and generator.robust_prompt_generator:
            print(f"\nğŸ¨ Generating: {args.emotion} + {args.style} (with RobustPromptGenerator)")
            image, prompt_info = generator.generate_image_with_optimized_prompt(
                emotion=args.emotion,
                style=args.style
            )
            image.show()
        else:
            emotion_desc = generator.emotions[args.emotion]
            style_desc = generator.styles[args.style]
            prompt = f"{generator.base_prompt}, {emotion_desc}, {style_desc}"
            print(f"\nğŸ¨ Generating: {args.emotion} + {args.style}")
            image = generator.generate_image(prompt)
            image.show()
    elif args.emotion:
        # æ„Ÿæƒ…ã®ã¿ã§ç”Ÿæˆ
        generator.generate_emotions()
    elif args.style:
        # ã‚¹ã‚¿ã‚¤ãƒ«ã®ã¿ã§ç”Ÿæˆ
        generator.generate_styles()
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
