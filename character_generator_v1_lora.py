#!/usr/bin/env python3
"""
anime-character-generator v1.5 (LoRA Edition)
Stable Diffusion v1.5 + LoRA Fine-tuning

ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã€‘
Version: 1.5
Date: 2026-02-17 ãƒ–ãƒ­ã‚°åŸ·ç­†æ™‚
Status: LoRA å®Ÿè£…ç‰ˆï¼ˆãƒ–ãƒ­ã‚°ã®æœªç€æ‰‹çŠ¶æ…‹ã‹ã‚‰å®Ÿè£…ï¼‰

ã€å®Ÿè£…å†…å®¹ã€‘
- Stable Diffusion v1.5 ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
- PEFT ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚ˆã‚‹ LoRA (Low-Rank Adaptation)
- Google Colab T4 GPU ã§ã®å®Ÿè¡Œæƒ³å®š
- Float16 ç²¾åº¦ã€Attention Slicing ã«ã‚ˆã‚‹æœ€é©åŒ–

ã€æ—¢çŸ¥ã®èª²é¡Œã€‘ âš ï¸
ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯è©¦è¡ŒéŒ¯èª¤ã®çµæœç‰ˆã§ã™ã€‚ä»¥ä¸‹ã®èª²é¡ŒãŒã‚ã‚Šã¾ã™ï¼š

1. Character-level noise ã¸ã®è„†å¼±æ€§
   - Gao et al. (2306.13103) ãŒæŒ‡æ‘˜ã™ã‚‹ taipo/glyph æ”»æ’ƒã«å¯¾å¿œã—ã¦ã„ãªã„
   - å˜ä¸€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã®ãŸã‚
   è§£æ±ºæ–¹æ³•: v2.0 Phase 1 ã§ Gemini LLM ã«ã‚ˆã‚‹å¤šå±¤å†—é•·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ

2. æ¨è«–é€Ÿåº¦ãŒé…ã„
   - 20 ã‚¹ãƒ†ãƒƒãƒ—ã§ 3.8ç§’/ç”»åƒ (T4 GPU)
   - Latent Consistency Models (LCM) ã«ã‚ˆã‚‹ 12x é«˜é€ŸåŒ–æ©Ÿä¼šã‚’æœªæ´»ç”¨
   è§£æ±ºæ–¹æ³•: v2.0 Phase 2B ã§ LCM è’¸ç•™ã‚’å®Ÿè£…

3. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›æœªå¯¾å¿œ
   - ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®ã¿
   - Image-to-Image, ControlNet, ã‚¹ã‚±ãƒƒãƒå…¥åŠ›ãªã©æœªå®Ÿè£…
   è§£æ±ºæ–¹æ³•: v2.0 Phase 3 ã§å®Œå…¨ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ

4. æœ¬ç•ªç’°å¢ƒå¯¾å¿œãªã—
   - ç ”ç©¶ã‚¹ã‚¯ãƒªãƒ—ãƒˆå½¢å¼
   - REST API, Web UI, ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæœªå®Ÿè£…
   è§£æ±ºæ–¹æ³•: v2.0 Phase 4 ã§ Streamlit UI + FastAPI + ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè£…

ã“ã‚Œã‚‰ã®èª²é¡Œã¯ v2.0 (Phase 1-4) ã§æ®µéšçš„ã«è§£æ±ºã•ã‚Œã¾ã™ã€‚
è©³ç´°ã¯: IMPLEMENTATION_ROADMAP.md ã‚’å‚ç…§

ã€è«–æ–‡ãƒ™ãƒ¼ã‚¹ã€‘
- Ho et al. (2020): DDPM ã®åŸºç¤ç†è«–
  URL: https://arxiv.org/abs/2006.11239
- Rombach et al. (2022): Stable Diffusion v1.5
  URL: https://arxiv.org/abs/2112.10752
- Hu et al. (2021): LoRA - Low-Rank Adaptation
  URL: https://arxiv.org/abs/2106.09685
- Gao et al. (2306.13103): Text-to-Image Robustness
  URL: https://arxiv.org/abs/2306.13103
"""

from diffusers import StableDiffusionPipeline
import torch
from pathlib import Path
from typing import Dict, Optional
from PIL import Image
import os
import re
import argparse

class LoRACharacterGenerator:
    """ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆLoRAæ¨è«–ç‰ˆï¼‰"""
    
    def __init__(
        self,
        device: str = "auto",
        model_id: str = "runwayml/stable-diffusion-v1-5",
        lora_path: Optional[str] = None,
        lora_rank: int = 32
    ):
        """
        åˆæœŸåŒ–å‡¦ç†
        
        Args:
            device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹ ('cuda', 'cpu', or 'auto')
            model_id: Hugging Face ã®ãƒ¢ãƒ‡ãƒ« ID
            lora_path: LoRA ã‚¦ã‚§ã‚¤ãƒˆã®ãƒ‘ã‚¹ï¼ˆæ¨è«–ç”¨ï¼‰
            lora_rank: LoRA ãƒ©ãƒ³ã‚¯ï¼ˆå­¦ç¿’æ™‚ã¨ä¸€è‡´ã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
        
        Raises:
            RuntimeError: GPU ãŒåˆ©ç”¨ä¸å¯ãªå ´åˆ
        """
        # ãƒ‡ãƒã‚¤ã‚¹æ±ºå®š
        if device == "auto":
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
        
        if self.device == "cuda" and not torch.cuda.is_available():
            raise RuntimeError("CUDA requested but not available")
        
        self.dtype = torch.float16 if self.device == "cuda" else torch.float32
        self.lora_path = lora_path
        self.lora_rank = lora_rank
        
        print(f"ğŸ“± Device: {self.device}")
        print(f"ğŸ“Š Precision: {self.dtype}")
        
        if self.device == "cuda":
            print(f"   GPU: {torch.cuda.get_device_name(0)}")
            print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        print(f"\nğŸ“¦ Loading {model_id}...")
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=self.dtype,
            safety_checker=None  # æ¨è«–é«˜é€ŸåŒ–
        )
        self.pipe = self.pipe.to(self.device)
        self.pipe.enable_attention_slicing()  # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
        
        # LoRA ã‚¦ã‚§ã‚¤ãƒˆãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨è«–ç”¨ï¼‰
        if lora_path:
            self._load_lora_weights(lora_path)
        
        print("âœ… Model loaded successfully")
        
        # ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾©
        self.base_prompt = "1girl, anime character, masterpiece, high quality"
        self.emotions = {
            "happy": "happy smile, cheerful, joyful",
            "angry": "angry expression, intense eyes",
            "sad": "sad expression, melancholic",
            "surprised": "surprised expression, wide eyes"
        }
        self.styles = {
            "with_hat": "wearing hat, stylish, fashionable",
            "with_earrings": "wearing earrings, jewelry, elegant",
            "with_makeup": "with makeup, beautiful, glamorous",
            "formal": "wearing formal dress, elegant, professional",
            "casual": "casual outfit, relaxed, friendly",
            "long_hair": "long brown hair, soft flowing hair",
            "blush": "soft blush on cheeks",
            "fireplace": "warm fireplace in background",
            "warm_lighting": "warm ambient lighting, soft orange glow",
            "cozy_room": "cozy indoor setting",
            "bokeh": "cinematic bokeh lights",
            "portrait": "upper body portrait",
            "depth_of_field": "shallow depth of field",
            "high_detail": "highly detailed",
            "soft_shading": "soft anime shading",
            "masterpiece": "masterpiece, best quality"
        }
    
    def _load_lora_weights(self, lora_path: str) -> None:
        """
        LoRA ã‚¦ã‚§ã‚¤ãƒˆã‚’èª­ã¿è¾¼ã‚€ï¼ˆæ¨è«–ç”¨ï¼‰
        
        Args:
            lora_path: LoRA ã‚¦ã‚§ã‚¤ãƒˆã®ãƒ‘ã‚¹
        """
        try:
            from peft import PeftModel
        except ImportError:
            print("âŒ PEFT ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("   pip install peft")
            raise
        
        print(f"\nğŸ”„ Loading LoRA weights: {lora_path}")
        
        if not Path(lora_path).exists():
            raise FileNotFoundError(f"LoRA path not found: {lora_path}")
        
        # UNet ã« LoRA ã‚¦ã‚§ã‚¤ãƒˆã‚’é©ç”¨
        try:
            self.pipe.unet = PeftModel.from_pretrained(
                self.pipe.unet,
                lora_path,
                adapter_name="default"
            )
            print(f"âœ… LoRA weights loaded: {lora_path}")
        except Exception as e:
            print(f"âŒ LoRA loading error: {e}")
            raise
    
    def generate_image(
        self,
        prompt: str,
        negative_prompt: str = "low quality, blurry",
        num_steps: int = 20,
        guidance_scale: float = 7.0,
        seed: int = None
    ) -> Image.Image:
        """
        å˜ä¸€ç”»åƒç”Ÿæˆï¼ˆLoRA é©ç”¨ç‰ˆï¼‰
        
        âš ï¸  æ³¨æ„: v1.5 ã®å˜ä¸€ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã§ã¯ã€
        ã‚¿ã‚¤ãƒã‚„ã‚°ãƒªãƒ•æ”»æ’ƒã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚
        v2.0 ã¯ Gemini LLM ã«ã‚ˆã‚‹å¤šå±¤å†—é•·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å¯¾å¿œäºˆå®šã€‚
        """
        
        if seed is not None:
            torch.manual_seed(seed)
            torch.cuda.manual_seed(seed)
        
        with torch.no_grad():
            image = self.pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=num_steps,
                guidance_scale=guidance_scale,
                height=512,
                width=512
            ).images[0]
        
        return image
    
    def generate_collection(
        self,
        collection_type: str = "all",
        output_dir: str = "./outputs"
    ) -> Dict[str, str]:
        """
        è¤‡æ•°ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆLoRA é©ç”¨ç‰ˆï¼‰
        
        Args:
            collection_type: 'emotions', 'styles', 'all'
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
        Returns:
            {name: filepath} ã®è¾æ›¸
        """
        output_path = Path(output_dir) / f"{collection_type}_lora"
        output_path.mkdir(parents=True, exist_ok=True)
        
        results = {}
        prompts_to_generate = {}
        
        if collection_type in ["emotions", "all"]:
            prompts_to_generate.update(self.emotions)
        if collection_type in ["styles", "all"]:
            prompts_to_generate.update(self.styles)
        
        total = len(prompts_to_generate)
        
        print(f"ğŸ¨ Generating {total} images with LoRA...")
        
        for idx, (name, desc) in enumerate(prompts_to_generate.items(), 1):
            full_prompt = f"{self.base_prompt}, {desc}"
            
            print(f"[{idx}/{total}] Generating: {name}...", end="", flush=True)
            
            # ãƒ¡ãƒ¢ãƒªæ¸…ç†
            torch.cuda.empty_cache()
            
            try:
                image = self.generate_image(full_prompt)
                filepath = output_path / f"character_{name}_lora.png"
                image.save(str(filepath))
                results[name] = str(filepath)
                print(" âœ…")
            
            except Exception as e:
                print(f" âŒ Error: {e}")
                continue
        
        return results
    
    def _get_next_version(self, base_filename: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’å–å¾—"""
        output_dir = "./outputs"
        existing_files = os.listdir(output_dir) if os.path.exists(output_dir) else []
        
        pattern = rf'^{re.escape(base_filename)}_v(\d+)\.png$'
        versions = []
        
        for fn in existing_files:
            match = re.match(pattern, fn)
            if match:
                versions.append(int(match.group(1)))
        
        next_version = max(versions) + 1 if versions else 1
        return f"{base_filename}_v{next_version}.png"


def main():
    parser = argparse.ArgumentParser(
        description="Anime character generator v1.5 (LoRA Edition)",
        epilog="""
ä½¿ç”¨ä¾‹:

1. LoRA ã‚¦ã‚§ã‚¤ãƒˆãªã—ã§å®Ÿè¡Œï¼ˆãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã¿ï¼‰:
   python character_generator_v1_lora.py --all

2. LoRA ã‚¦ã‚§ã‚¤ãƒˆé©ç”¨ã§å®Ÿè¡Œ:
   python character_generator_v1_lora.py \\
     --lora_path ./lora_weights/anime-lora-final \\
     --all

3. ç‰¹å®šã®æ„Ÿæƒ…ã‚’ç”Ÿæˆ:
   python character_generator_v1_lora.py \\
     --lora_path ./lora_weights/anime-lora-final \\
     --emotion happy

ã€æ—¢çŸ¥ã®èª²é¡Œã€‘
- ã‚¿ã‚¤ãƒ/ã‚°ãƒªãƒ•æ”»æ’ƒã«å¯¾å¿œã—ã¦ã„ãªã„ (v2.0 Phase 1 ã§è§£æ±ºäºˆå®š)
- æ¨è«–é€Ÿåº¦ãŒé…ã„ (v2.0 Phase 2B ã§ LCM è’¸ç•™ã§ 12 å€é«˜é€ŸåŒ–äºˆå®š)
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›æœªå¯¾å¿œ (v2.0 Phase 3 ã§å¯¾å¿œäºˆå®š)

è©³ç´°: IMPLEMENTATION_ROADMAP.md å‚ç…§
        """
    )
    
    parser.add_argument(
        "--lora_path",
        type=str,
        default=None,
        help="LoRA ã‚¦ã‚§ã‚¤ãƒˆã®ãƒ‘ã‚¹ï¼ˆä¾‹: ./lora_weights/anime-lora-finalï¼‰"
    )
    
    parser.add_argument(
        "--emotion",
        choices=["happy", "angry", "sad", "surprised"],
        help="Generate specific emotion"
    )
    
    parser.add_argument(
        "--style",
        choices=[
            "with_hat", "with_earrings", "with_makeup", "formal", "casual",
            "long_hair", "blush", "fireplace", "warm_lighting", "cozy_room",
            "bokeh", "portrait", "depth_of_field", "high_detail", "soft_shading", "masterpiece"
        ],
        help="Generate specific style"
    )
    
    parser.add_argument(
        "--all",
        action="store_true",
        help="Generate all variations"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./outputs",
        help="Output directory (default: ./outputs)"
    )
    
    args = parser.parse_args()
    
    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿åˆæœŸåŒ–
    generator = LoRACharacterGenerator(lora_path=args.lora_path)
    
    # ç”Ÿæˆå®Ÿè¡Œ
    if args.all:
        print("\n" + "="*60)
        print("ğŸ¨ LoRA Edition - Full Collection Generation")
        print("="*60)
        results = generator.generate_collection(
            collection_type="all",
            output_dir=args.output_dir
        )
    elif args.emotion or args.style:
        # ç‰¹å®šã®çµ„ã¿åˆã‚ã›
        prompt_parts = [generator.base_prompt]
        if args.emotion:
            prompt_parts.append(generator.emotions[args.emotion])
        if args.style:
            prompt_parts.append(generator.styles[args.style])
        
        prompt = ", ".join(prompt_parts)
        image = generator.generate_image(prompt)
        
        emotion_part = args.emotion or "any"
        style_part = args.style or "any"
        output_path = Path(args.output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        filepath = output_path / f"character_{emotion_part}_{style_part}_lora.png"
        image.save(str(filepath))
        
        results = {f"{emotion_part}_{style_part}": str(filepath)}
    else:
        parser.print_help()
        return
    
    print(f"\nâœ… Generation complete! Generated {len(results)} images")
    
    if args.lora_path:
        print(f"ğŸ“Œ LoRA weights: {args.lora_path}")
    else:
        print(f"âš ï¸  LoRA weights not loaded (using base model only)")


if __name__ == "__main__":
    main()
