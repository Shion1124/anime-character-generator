#!/usr/bin/env python3
"""
Anime Character LoRA Training Script - Checkpoint ãƒ‘ã‚¹å®Ÿè£…ç‰ˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Stable Diffusion v1.5 ã« LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨ã—ã¾ã™ã€‚
ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜æ©Ÿèƒ½ã§ Colab ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­å¯¾å¿œã€‚

å®Ÿè¡Œä¾‹ï¼ˆæ–°è¦å­¦ç¿’ï¼‰:
    python train_lora.py \\
        --data_dir ../training_data \\
        --output_dir ./lora_weights \\
        --epochs 20 \\
        --batch_size 2

å®Ÿè¡Œä¾‹ï¼ˆå¾©å¸°ï¼‰:
    python train_lora.py \\
        --data_dir ../training_data \\
        --output_dir ./lora_weights \\
        --resume_from ./lora_weights/checkpoint-epoch-15 \\
        --epochs 20

ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
    pip install -q diffusers transformers pillow torch tqdm safetensors peft accelerate xformers

å‚è€ƒæ–‡çŒ®:
    - Ho et al. (2020): Denoising Diffusion Probabilistic Models (DDPM)
    - Rombach et al. (2022): Latent Diffusion Models
    - Hu et al. (2021): LoRA - Low-Rank Adaptation
    - Luo et al. (2023): Latent Consistency Models (LCM)

å­¦ç¿’æ™‚é–“è¦‹ç©ã‚‚ã‚Šï¼ˆColab T4ï¼‰:
    20 epoch Ã— 300 images â†’ ç´„ 10-12 æ™‚é–“ï¼ˆåˆ†å‰²å®Ÿè¡Œæ¨å¥¨ï¼‰
    ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: æ¯ 5 epochï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­å¯¾å¿œï¼‰
"""

import os
import argparse
import json
from pathlib import Path
from typing import List, Dict, Optional
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
import time


class AnimeDataset(Dataset):
    """ã‚¢ãƒ‹ãƒ¡ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, data_dir: str, resolution: int = 512):
        self.data_dir = Path(data_dir)
        self.image_paths = []
        
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ç”»åƒã‚’åé›†
        for style_dir in self.data_dir.glob("*"):
            if style_dir.is_dir():
                self.image_paths.extend(list(style_dir.glob("*.png")))
                self.image_paths.extend(list(style_dir.glob("*.jpg")))
        
        if not self.image_paths:
            raise ValueError(f"âŒ {data_dir} ã«ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        self.resolution = resolution
        self.transform = transforms.Compose([
            transforms.Resize(resolution, interpolation=transforms.InterpolationMode.LANCZOS),
            transforms.CenterCrop(resolution),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])
        
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(self.image_paths)} ç”»åƒ")
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        try:
            image = Image.open(self.image_paths[idx]).convert("RGB")
            return self.transform(image)
        except Exception as e:
            print(f"âš ï¸  ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {self.image_paths[idx]} - {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªç”»åƒã‚’è¿”ã™
            return self[torch.randint(0, len(self), (1,)).item()]


class LoRATrainer:
    """
    LoRA ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ - ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½ä»˜ã
    
    Colab ã§ã®åˆ†å‰²å®Ÿè¡Œå¯¾å¿œï¼š
    - æ¯ 5 epoch ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
    - --resume_from ã§ä¸­æ–­å¾©å¸°
    """
    
    def __init__(
        self,
        model_name: str = "runwayml/stable-diffusion-v1-5",
        device: str = "cuda",
        lora_rank: int = 32,
        lora_alpha: float = 32.0,
    ):
        """
        Args:
            model_name: Hugging Face Hub ã®ãƒ¢ãƒ‡ãƒ«å
            device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹
            lora_rank: LoRA ãƒ©ãƒ³ã‚¯
            lora_alpha: LoRA ã‚¢ãƒ«ãƒ•ã‚¡å€¤
        """
        self.model_name = model_name
        self.device = device
        self.lora_rank = lora_rank
        self.lora_alpha = lora_alpha
        self.pipe = None
        
        print(f"ğŸ“¦ Model: {model_name}")
        print(f"ğŸ’¾ Device: {device}")
        print(f"ğŸ¯ LoRA Config: rank={lora_rank}, alpha={lora_alpha}")
    
    def setup_model(self):
        """Stable Diffusion + LoRA ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            from diffusers import StableDiffusionPipeline
            from peft import LoraConfig, get_peft_model
        except ImportError:
            print("âŒ å¿…é ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
            print("   pip install -q diffusers peft")
            raise
        
        print("\nğŸš€ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
        self.pipe = StableDiffusionPipeline.from_pretrained(
            self.model_name,
            torch_dtype=torch.float16,
            safety_checker=None,
            variant="fp16"
        ).to(self.device)
        
        # VAE ã¨ Text Encoder ã¯å‡çµ
        self.pipe.vae.requires_grad_(False)
        self.pipe.text_encoder.requires_grad_(False)
        
        # LoRA è¨­å®š
        lora_config = LoraConfig(
            r=self.lora_rank,
            lora_alpha=self.lora_alpha,
            target_modules=["to_k", "to_v", "to_q", "to_out"],
            lora_dropout=0.1,
            bias="none"
        )
        
        # UNet ã« LoRA é©ç”¨
        self.pipe.unet = get_peft_model(self.pipe.unet, lora_config)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ±è¨ˆ
        total_params = sum(p.numel() for p in self.pipe.unet.parameters())
        trainable_params = sum(p.numel() for p in self.pipe.unet.parameters() if p.requires_grad)
        
        print(f"ğŸ“Š Total UNet params: {total_params:,}")
        print(f"ğŸ¯ Trainable (LoRA) params: {trainable_params:,}")
        print(f"ğŸ“‰ Compression ratio: {trainable_params/total_params:.4%}")
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        try:
            import xformers
            self.pipe.enable_xformers_memory_efficient_attention()
            print("âœ… xFormers ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ– æœ‰åŠ¹")
        except ImportError:
            print("âš ï¸  xFormers éã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæ¨å¥¨: pip install xformersï¼‰")
        
        self.pipe.unet.enable_gradient_checkpointing()
        print("âœ… Gradient checkpointing æœ‰åŠ¹")
        
        return self.pipe
    
    def train(
        self,
        data_dir: str,
        output_dir: str = "./lora_weights",
        epochs: int = 20,
        batch_size: int = 2,
        learning_rate: float = 1e-4,
        gradient_accumulation_steps: int = 1,
        resume_from: Optional[str] = None,
    ):
        """
        LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        
        Args:
            data_dir: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆtraining_data ãªã©ï¼‰
            output_dir: LoRA ã‚¦ã‚§ã‚¤ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            epochs: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆæ¨å¥¨: 20ï¼‰
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆT4æ¨å¥¨: 2ï¼‰
            learning_rate: å­¦ç¿’ç‡
            gradient_accumulation_steps: å‹¾é…ç´¯ç©ã‚¹ãƒ†ãƒƒãƒ—
            resume_from: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å¸°ã™ã‚‹ãƒ‘ã‚¹
        """
        
        # ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        self.setup_model()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
        print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ä¸­...")
        dataset = AnimeDataset(data_dir)
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=0,  # Colabå¯¾å¿œ
        )
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
        optimizer = torch.optim.AdamW(
            filter(lambda p: p.requires_grad, self.pipe.unet.parameters()),
            lr=learning_rate,
            weight_decay=0.01
        )
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
        num_training_steps = len(dataloader) * epochs
        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, num_training_steps
        )
        
        # ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
        from diffusers import DDPMScheduler
        noise_scheduler = DDPMScheduler.from_pretrained(
            self.model_name,
            subfolder="scheduler"
        )
        
        # å¾©å¸°å‡¦ç†
        start_epoch = 0
        if resume_from:
            print(f"\nğŸ”„ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å¸°: {resume_from}")
            checkpoint_path = Path(resume_from)
            
            if checkpoint_path.exists():
                self.pipe.unet.load_adapter(str(checkpoint_path), adapter_name="default")
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–‹å§‹ã‚¨ãƒãƒƒã‚¯å–å¾—
                metadata_path = checkpoint_path / "training_metadata.json"
                if metadata_path.exists():
                    with open(metadata_path) as f:
                        metadata = json.load(f)
                        start_epoch = metadata.get("epoch", 0)
                        print(f"âœ… Epoch {start_epoch} ã‹ã‚‰é–‹å§‹")
        
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
        self.pipe.unet.train()
        self.pipe.vae.eval()
        self.pipe.text_encoder.eval()
        
        print(f"\n" + "="*60)
        print(f"ğŸš€ LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹")
        print(f"="*60)
        print(f"ğŸ“Š Dataset: {len(dataset)} images")
        print(f"â±ï¸  Estimated time: ç´„ {epochs * 30 // 60} æ™‚é–“ (Colab T4)")
        print(f"ğŸ’¾ Checkpoint: æ¯ 5 epoch ã”ã¨ã«ä¿å­˜")
        print(f"="*60 + "\n")
        
        training_log = {
            "model": self.model_name,
            "epochs": epochs,
            "batch_size": batch_size,
            "learning_rate": learning_rate,
            "lora_rank": self.lora_rank,
            "lora_alpha": self.lora_alpha,
            "losses": []
        }
        
        total_steps = 0
        
        for epoch in range(start_epoch, epochs):
            epoch_loss = 0.0
            epoch_start_time = time.time()
            
            pbar = tqdm(
                dataloader,
                desc=f"Epoch {epoch+1}/{epochs}",
                disable=False
            )
            
            for batch_idx, pixel_values in enumerate(pbar):
                pixel_values = pixel_values.to(self.device, dtype=torch.float16)
                
                # VAE ã§æ½œåœ¨ç©ºé–“ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                with torch.no_grad():
                    latents = self.pipe.vae.encode(pixel_values).latent_dist.sample()
                    latents = latents * 0.18215  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                
                # ãƒã‚¤ã‚ºã¨ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                noise = torch.randn_like(latents)
                timesteps = torch.randint(
                    0, noise_scheduler.config.num_train_timesteps,
                    (latents.shape[0],),
                    device=self.device
                )
                
                # ãƒã‚¤ã‚ºè¿½åŠ 
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                
                # ãƒ€ãƒŸãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                with torch.no_grad():
                    encoder_hidden_states = self.pipe.text_encoder(
                        torch.zeros(
                            latents.shape[0], 77,
                            dtype=torch.long,
                            device=self.device
                        )
                    )[0]
                
                # UNet äºˆæ¸¬
                model_pred = self.pipe.unet(
                    noisy_latents,
                    timesteps,
                    encoder_hidden_states
                ).sample
                
                # MSE æå¤±
                loss = torch.nn.functional.mse_loss(model_pred, noise)
                
                # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒƒãƒ—
                loss.backward()
                
                if (batch_idx + 1) % gradient_accumulation_steps == 0:
                    optimizer.step()
                    optimizer.zero_grad()
                
                lr_scheduler.step()
                
                epoch_loss += loss.item()
                total_steps += 1
                pbar.set_postfix({
                    "loss": f"{loss.item():.6f}",
                    "step": total_steps
                })
            
            avg_loss = epoch_loss / len(dataloader)
            epoch_time = time.time() - epoch_start_time
            
            print(f"  ğŸ“Š Loss: {avg_loss:.6f} | â±ï¸  {epoch_time:.1f}ç§’")
            training_log["losses"].append({
                "epoch": epoch + 1,
                "loss": avg_loss,
                "time_seconds": epoch_time
            })
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆæ¯ 5 epochï¼‰
            if (epoch + 1) % 5 == 0 or epoch == epochs - 1:
                checkpoint_dir = output_path / f"checkpoint-epoch-{epoch+1}"
                checkpoint_dir.mkdir(parents=True, exist_ok=True)
                
                print(f"\nğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: {checkpoint_dir}")
                self.pipe.unet.save_pretrained(str(checkpoint_dir))
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                metadata = {
                    "epoch": epoch + 1,
                    "total_steps": total_steps,
                    "loss": avg_loss,
                    "learning_rate": learning_rate,
                }
                with open(checkpoint_dir / "training_metadata.json", "w") as f:
                    json.dump(metadata, f, indent=2)
                
                print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå®Œäº†\n")
        
        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        final_dir = output_path / "anime-lora-final"
        final_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nâœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {final_dir}")
        self.pipe.unet.save_pretrained(str(final_dir))
        
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°ä¿å­˜
        with open(output_path / "training_log.json", "w") as f:
            json.dump(training_log, f, indent=2)
        
        print(f"\n" + "="*60)
        print(f"âœ… LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†")
        print(f"="*60)
        print(f"ğŸ“ å‡ºåŠ›: {output_dir}")
        print(f"ğŸ“Š ç·ã‚¨ãƒãƒƒã‚¯: {epochs}")
        print(f"â±ï¸  ç·å­¦ç¿’æ™‚é–“: {sum(log['time_seconds'] for log in training_log['losses'])/3600:.1f} æ™‚é–“")
        print(f"ğŸ“‰ æœ€çµ‚æå¤±: {training_log['losses'][-1]['loss']:.6f}")
        print(f"\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"   HuggingFace ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰:")
        print(f"   python upload_to_huggingface.py \\")
        print(f"       --model-path {final_dir} \\")
        print(f"       --repo-name anime-character-lora")
        print(f"="*60)
        
        return self.pipe


def main():
    parser = argparse.ArgumentParser(
        description="Anime Character LoRA Training - ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¯¾å¿œç‰ˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # æ–°è¦å­¦ç¿’ï¼ˆ20 epochï¼‰
  python train_lora.py \\
    --data_dir ../training_data \\
    --output_dir ./lora_weights \\
    --epochs 20 \\
    --batch_size 2

  # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å¸°ï¼ˆ15 epoch ãŒçµ‚ã‚ã£ã¦ã„ã‚‹å ´åˆï¼‰
  python train_lora.py \\
    --data_dir ../training_data \\
    --output_dir ./lora_weights \\
    --resume_from ./lora_weights/checkpoint-epoch-15 \\
    --epochs 20

å­¦ç¿’æ™‚é–“è¦‹ç©ã‚‚ã‚Šï¼ˆColab T4ï¼‰:
  1 epoch â‰ˆ 30-40 åˆ†
  20 epoch â‰ˆ 10-12 æ™‚é–“ï¼ˆåˆ†å‰²å®Ÿè¡Œæ¨å¥¨ï¼‰
  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã§ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­å¾Œã«å¾©å¸°å¯èƒ½
        """
    )
    
    parser.add_argument(
        "--data_dir",
        type=str,
        default="../training_data",
        help="ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ../training_dataï¼‰"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./lora_weights",
        help="LoRA ã‚¦ã‚§ã‚¤ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./lora_weightsï¼‰"
    )
    
    parser.add_argument(
        "--epochs",
        type=int,
        default=20,
        help="ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆæ¨å¥¨: 20, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰"
    )
    
    parser.add_argument(
        "--batch_size",
        type=int,
        default=2,
        help="ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆColab T4 æ¨å¥¨: 2, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰"
    )
    
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=1e-4,
        help="å­¦ç¿’ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1e-4ï¼‰"
    )
    
    parser.add_argument(
        "--lora_rank",
        type=int,
        default=32,
        help="LoRA ãƒ©ãƒ³ã‚¯ï¼ˆæ¨å¥¨: 32, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 32ï¼‰"
    )
    
    parser.add_argument(
        "--resume_from",
        type=str,
        default=None,
        help="ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å¸°ï¼ˆä¾‹: ./lora_weights/checkpoint-epoch-15ï¼‰"
    )
    
    args = parser.parse_args()
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
    trainer = LoRATrainer(
        lora_rank=args.lora_rank,
        lora_alpha=float(args.lora_rank)  # alpha = rank
    )
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
    trainer.train(
        data_dir=args.data_dir,
        output_dir=args.output_dir,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        resume_from=args.resume_from,
    )


if __name__ == "__main__":
    main()

