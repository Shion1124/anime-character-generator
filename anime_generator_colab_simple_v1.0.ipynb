{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4556ab5",
   "metadata": {},
   "source": [
    "# ğŸ¨ anime-character-generator v1.0\n",
    "## Stable Diffusion + PyTorch (Colabç‰ˆãƒ»ã‚·ãƒ³ãƒ—ãƒ«)\n",
    "\n",
    "**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0  \n",
    "**èª¬æ˜**: PyTorch + Diffusers ã®åŸºæœ¬çš„ãªå®Ÿè£…  \n",
    "**ã‚¬ã‚¤ãƒ‰**: [Day3-4 ãƒ–ãƒ­ã‚°è¨˜äº‹](https://shion.blog/)  \n",
    "**ã‚³ãƒ¼ãƒ‰**: [character_generator_v1.py](../character_generator_v1.py)\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ç‰ˆã§ã™ã€‚ãƒ–ãƒ­ã‚°ã§è©³ç´°ã«èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "Google Colab ç’°å¢ƒã§å‹•ä½œç¢ºèªæ¸ˆã¿ã®ç°¡æ˜“ç‰ˆã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: GPU ç¢ºèª\n",
    "import torch\n",
    "print(f\"âœ“ GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæœ€æ–°ç‰ˆãƒ»ç«¶åˆå›é¿ï¼‰\n",
    "!pip install -q --upgrade setuptools wheel\n",
    "!pip install -q diffusers transformers accelerate safetensors\n",
    "!pip install -q pillow torchvision\n",
    "print(\"âœ… Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "\n",
    "print(\"âœ… All libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "print(f\"ğŸ“¦ Loading model... (device: {device})\")\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=dtype,\n",
    "    safety_checker=None\n",
    ")\n",
    "pipe = pipe.to(device)\n",
    "pipe.enable_attention_slicing()\n",
    "\n",
    "print(\"âœ… Model ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: æ„Ÿæƒ…ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ\n",
    "import os\n",
    "os.makedirs(\"outputs/emotions\", exist_ok=True)\n",
    "\n",
    "emotions = {\n",
    "    \"happy\": \"happy smile, cheerful, joyful\",\n",
    "    \"angry\": \"angry expression, intense eyes\",\n",
    "    \"sad\": \"sad expression, melancholic\",\n",
    "    \"surprised\": \"surprised expression, wide eyes\"\n",
    "}\n",
    "\n",
    "base = \"1girl, anime character, masterpiece, high quality\"\n",
    "emotion_images = {}\n",
    "\n",
    "print(\"\\nğŸ­ GENERATING EMOTIONS...\\n\")\n",
    "\n",
    "for emotion_name, emotion_desc in emotions.items():\n",
    "    prompt = f\"{base}, {emotion_desc}\"\n",
    "    print(f\"  [{emotion_name.upper()}] Generating...\", end=\"\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=\"low quality, blurry\",\n",
    "            num_inference_steps=20,\n",
    "            guidance_scale=7.0,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "    \n",
    "    filepath = f\"outputs/emotions/character_{emotion_name}.png\"\n",
    "    image.save(filepath)\n",
    "    emotion_images[emotion_name] = image\n",
    "    print(\" âœ…\")\n",
    "\n",
    "print(\"\\nâœ… Emotions complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49089231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: ã‚¹ã‚¿ã‚¤ãƒ«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆ16ç¨®é¡ï¼‰\n",
    "os.makedirs(\"outputs/styles\", exist_ok=True)\n",
    "\n",
    "styles = {\n",
    "    \"with_hat\": \"wearing hat, stylish, fashionable\",\n",
    "    \"with_earrings\": \"wearing earrings, jewelry, elegant\",\n",
    "    \"with_makeup\": \"with makeup, beautiful, glamorous\",\n",
    "    \"formal\": \"wearing formal dress, elegant, professional\",\n",
    "    \"casual\": \"casual outfit, relaxed, friendly\",\n",
    "    \"long_hair\": \"long brown hair, soft flowing hair\",\n",
    "    \"blush\": \"soft blush on cheeks\",\n",
    "    \"fireplace\": \"warm fireplace in background\",\n",
    "    \"warm_lighting\": \"warm ambient lighting, soft orange glow\",\n",
    "    \"cozy_room\": \"cozy indoor setting\",\n",
    "    \"bokeh\": \"cinematic bokeh lights\",\n",
    "    \"portrait\": \"upper body portrait\",\n",
    "    \"depth_of_field\": \"shallow depth of field\",\n",
    "    \"high_detail\": \"highly detailed\",\n",
    "    \"soft_shading\": \"soft anime shading\",\n",
    "    \"masterpiece\": \"masterpiece, best quality\"\n",
    "}\n",
    "\n",
    "style_images = {}\n",
    "\n",
    "print(\"ğŸ‘— GENERATING STYLES (16 variations)...\\n\")\n",
    "\n",
    "for i, (style_name, style_desc) in enumerate(styles.items(), 1):\n",
    "    prompt = f\"{base}, {style_desc}\"\n",
    "    print(f\"  [{i:2d}/16] {style_name.upper()}...\", end=\"\", flush=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=\"low quality, blurry\",\n",
    "            num_inference_steps=20,\n",
    "            guidance_scale=7.0,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "    \n",
    "    filepath = f\"outputs/styles/character_{style_name}.png\"\n",
    "    image.save(filepath)\n",
    "    style_images[style_name] = image\n",
    "    print(\" âœ…\")\n",
    "\n",
    "print(\"\\nâœ… Styles complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b67c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: æ„Ÿæƒ…çµæœã‚’ã‚°ãƒªãƒƒãƒ‰å½¢å¼ã§åˆæˆ\n",
    "def get_next_version(base_filename):\n",
    "    \"\"\"æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’å–å¾—\"\"\"\n",
    "    existing_files = os.listdir(\"outputs\")\n",
    "    pattern = rf'^{re.escape(base_filename)}_v(\\d+)\\.png$'\n",
    "    versions = []\n",
    "    for fn in existing_files:\n",
    "        match = re.match(pattern, fn)\n",
    "        if match:\n",
    "            versions.append(int(match.group(1)))\n",
    "    next_version = max(versions) + 1 if versions else 1\n",
    "    return f\"{base_filename}_v{next_version}.png\"\n",
    "\n",
    "def create_grid_composite(images_dict, base_filename, rows=2, cols=2, img_size=512, gap=10):\n",
    "    \"\"\"è¤‡æ•°ç”»åƒã‚’ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§åˆæˆ\"\"\"\n",
    "    use_images = list(images_dict.items())[:rows*cols]\n",
    "    \n",
    "    # ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºè¨ˆç®—\n",
    "    canvas_width = cols * img_size + (cols - 1) * gap + gap * 2\n",
    "    canvas_height = rows * img_size + (rows - 1) * gap + gap * 2\n",
    "    \n",
    "    # ã‚­ãƒ£ãƒ³ãƒã‚¹ä½œæˆ\n",
    "    canvas = Image.new('RGB', (canvas_width, canvas_height), color='white')\n",
    "    \n",
    "    # ç”»åƒã‚’ãƒšãƒ¼ã‚¹ãƒˆ\n",
    "    for idx, (name, img) in enumerate(use_images):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        x = gap + col * (img_size + gap)\n",
    "        y = gap + row * (img_size + gap)\n",
    "        resized_img = img.resize((img_size, img_size), Image.Resampling.LANCZOS)\n",
    "        canvas.paste(resized_img, (x, y))\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    output_filename = get_next_version(base_filename)\n",
    "    canvas.save(f\"outputs/{output_filename}\", quality=95)\n",
    "    print(f\"âœ… æ„Ÿæƒ…çµæœ: {output_filename}\")\n",
    "    return canvas\n",
    "\n",
    "emotion_grid = create_grid_composite(emotion_images, \"emotion_results\", rows=2, cols=2)\n",
    "emotion_grid.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: ã‚¹ã‚¿ã‚¤ãƒ«çµæœã‚’ã‚°ãƒªãƒƒãƒ‰å½¢å¼ã§åˆæˆ\n",
    "style_grid = create_grid_composite(style_images, \"style_results\", rows=2, cols=4)\n",
    "style_grid.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Š Generated composite images:\")\n",
    "print(f\"   - emotion_results_v1.png (2x2 grid)\")\n",
    "print(f\"   - style_results_v1.png (2x4 grid)\")\n",
    "print(f\"\\nğŸ“ Total images: {len(emotion_images) + len(style_images)}\")\n",
    "print(f\"\\nğŸ“¥ To download:\")\n",
    "print(\"   1. Left sidebar â†’ Files icon\")\n",
    "print(\"   2. outputs/ folder â†’ Right click\")\n",
    "print(\"   3. Download\")\n",
    "print(\"\\nâœ¨ Success!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
