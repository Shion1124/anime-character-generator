# Phase 4: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆUI + API + Cloudï¼‰å®Ÿè£…ã‚¬ã‚¤ãƒ‰

**å¯¾è±¡ãƒ•ã‚§ãƒ¼ã‚º**: Phase 4 (æœ¬ç•ªç’°å¢ƒå±•é–‹)  
**æ¨å®šæœŸé–“**: 7-10æ—¥  
**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**: Streamlit (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰) + FastAPI (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰) + Docker (ã‚³ãƒ³ãƒ†ãƒŠåŒ–) + GCP/Heroku (ã‚¯ãƒ©ã‚¦ãƒ‰)  
**ä¾å­˜**: Phase 2A LoRA + Phase 2B LCM (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) + Phase 3 ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«  
**æˆæœç‰©**: å®Œå…¨ãªProduction ã‚µãƒ¼ãƒ“ã‚¹ (Web UI + REST API)

---

## ğŸ“– èƒŒæ™¯ï¼šãªãœãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãŒå¿…è¦ã‹ï¼Ÿ

### å•é¡Œ: ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ã®åˆ¶é™

Phase 1-3 ã¾ã§ã¯é–‹ç™ºç’°å¢ƒã§ã®ã¿å®Ÿè¡Œï¼š

```
åˆ¶é™äº‹é …:
  âŒ ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½¿ç”¨ä¸å¯
  âŒ Colab ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¾å­˜
  âŒ GPU ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èµ·å‹•ãƒ»åœæ­¢ã®æ‰‹é–“
  âŒ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãªã—
  âŒ REST API ãªã—ï¼ˆä»–ã‚¢ãƒ—ãƒªã‹ã‚‰ã®é€£æºä¸å¯ï¼‰
```

### è§£æ±ºç­–: Production-ready ã‚µãƒ¼ãƒ“ã‚¹

Phase 4 ã§å®Ÿè£…ã™ã‚‹ 3-å±¤æ§‹æˆï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web UI (Streamlit)                â”‚ â† ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹
â”‚   - ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰                 â”‚
â”‚   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›                   â”‚
â”‚   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REST API (FastAPI)                â”‚ â† ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
â”‚   - /generate (T2I)                 â”‚
â”‚   - /img2img (I2I)                  â”‚
â”‚   - /controlnet (Pose/Edge)         â”‚
â”‚   - /inpaint (å±€æ‰€ç·¨é›†)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI Model Layer                    â”‚ â† æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   - Stable Diffusion v1.5           â”‚
â”‚   - LoRA (Phase 2A)                 â”‚
â”‚   - LCM (Phase 2B)                  â”‚
â”‚   - ControlNet (Phase 3)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ:
  é–‹ç™º: localhost:8000
  æœ¬ç•ª: GCP/Heroku (auto-scaling)
```

---

## ğŸ¯ æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³

```
Internet
   â†‘
   â”‚ HTTPS
   â–¼
[Load Balancer (GCP)]
   â”‚
   â”œâ”€ [Instance 1] â†’ [GPU] â†’ [Model Cache]
   â”œâ”€ [Instance 2] â†’ [GPU] â†’ [Model Cache]
   â””â”€ [Instance 3] â†’ [GPU] â†’ [Model Cache]
   
   ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°:
   - ãƒ¢ãƒ‡ãƒ«ã¯ 1 å›ã®ã¿ãƒ­ãƒ¼ãƒ‰
   - ç”Ÿæˆç”»åƒã¯ Redis ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é‡è¤‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯å³åº§ã«è¿”å´
```

### æŠ€è¡“é¸å®šç†ç”±

| å±¤ | ãƒ„ãƒ¼ãƒ« | ç†ç”± |
|---|-------|-----|
| ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ | Streamlit | Python ãƒã‚¤ãƒ†ã‚£ãƒ–ã€é«˜é€Ÿãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚° |
| ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ | FastAPI | éåŒæœŸå¯¾å¿œã€è‡ªå‹•ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ |
| ã‚³ãƒ³ãƒ†ãƒŠ | Docker | ç’°å¢ƒçµ±ä¸€ã€æœ¬ç•ªç§»è¡Œã®å®¹æ˜“ã• |
| ã‚¯ãƒ©ã‚¦ãƒ‰ | GCP Compute Engine | GPU ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å®‰ä¾¡ã€è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œ |
| ä»£æ›¿æ¡ˆ | Heroku | ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç°¡æ˜“ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹å‹• |

---

## ğŸ› ï¸ å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—

### Step 1: FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

**ãƒ•ã‚¡ã‚¤ãƒ«**: `api_server.py` ã‚’æ–°è¦ä½œæˆ

```python
#!/usr/bin/env python3
"""
FastAPI Backend: ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ç”Ÿæˆ REST API

ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:
  POST /generate        â†’ ãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒ
  POST /img2img         â†’ ç”»åƒâ†’ç”»åƒ
  POST /controlnet      â†’ ControlNet
  POST /inpaint         â†’ å±€æ‰€ç·¨é›†
  GET  /health          â†’ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
  GET  /models          â†’ ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«æƒ…å ±

ä½¿ç”¨ä¾‹:
  pip install fastapi uvicorn python-multipart
  python api_server.py
  # http://localhost:8000/docs ã§ Swagger UI
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import torch
import os
from pathlib import Path
from PIL import Image
import io
import base64
import time
from datetime import datetime
import json
import uvicorn
import logging

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from character_generator import AnimeCharacterGenerator
from multimodal_pipeline import MultimodalPipeline

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========== Pydantic Models ==========

class GenerateRequest(BaseModel):
    """T2I ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    prompt: str
    negative_prompt: Optional[str] = ""
    num_steps: Optional[int] = 20
    guidance_scale: Optional[float] = 7.5
    use_lcm: Optional[bool] = False

class Img2ImgRequest(BaseModel):
    """I2I ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    prompt: str
    negative_prompt: Optional[str] = ""
    strength: Optional[float] = 0.8
    num_steps: Optional[int] = 20
    guidance_scale: Optional[float] = 7.5

class ControlNetRequest(BaseModel):
    """ControlNet ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    prompt: str
    negative_prompt: Optional[str] = ""
    mode: Optional[str] = "pose"  # pose / edges / depth
    num_steps: Optional[int] = 20
    guidance_scale: Optional[float] = 7.5

class InpaintRequest(BaseModel):
    """Inpainting ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    prompt: str
    negative_prompt: Optional[str] = ""
    strength: Optional[float] = 0.8
    num_steps: Optional[int] = 30

# ========== FastAPI App ==========

app = FastAPI(
    title="Anime Character Generation API",
    version="1.0.0",
    description="Phase 1-3 çµ±åˆã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ç”Ÿæˆ API",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS æœ‰åŠ¹åŒ–ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ==========

generator = None
multimodal = None
generation_count = 0
start_time = datetime.now()

# ========== åˆæœŸåŒ– ==========

@app.on_event("startup")
async def startup_event():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚"""
    
    global generator, multimodal
    
    logger.info("ğŸš€ Initializing API Server")
    
    # GPU ãƒã‚§ãƒƒã‚¯
    if not torch.cuda.is_available():
        logger.warning("âš ï¸  CUDA not available, using CPU (slow)")
    else:
        logger.info(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    logger.info("ğŸ“¦ Loading character generator")
    generator = AnimeCharacterGenerator(
        use_lcm=False  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: LCM ãªã—ï¼ˆç²¾åº¦å„ªå…ˆï¼‰
    )
    
    logger.info("ğŸ“¦ Loading multimodal pipeline")
    multimodal = MultimodalPipeline(
        lora_path="./lora_weights/anime-lora-final",
        use_lcm=False
    )
    
    logger.info("âœ… API Server ready")

# ========== ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ==========

@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    
    uptime = (datetime.now() - start_time).total_seconds()
    
    return {
        "status": "ok",
        "uptime_seconds": uptime,
        "gpu_available": torch.cuda.is_available(),
        "total_generations": generation_count,
        "memory_mb": {
            "reserved": torch.cuda.memory_reserved() / 1024 / 1024,
            "allocated": torch.cuda.memory_allocated() / 1024 / 1024
        }
    }

@app.get("/models")
async def get_models_info():
    """ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«æƒ…å ±"""
    
    return {
        "base_model": "runwayml/stable-diffusion-v1-5",
        "lora": "./lora_weights/anime-lora-final",
        "features": [
            "text-to-image",
            "image-to-image",
            "controlnet-pose",
            "controlnet-edge",
            "inpainting"
        ],
        "gpu_memory_mb": {
            "total": torch.cuda.get_device_properties(0).total_memory / 1024 / 1024 if torch.cuda.is_available() else 0
        }
    }

@app.post("/generate")
async def generate_image(request: GenerateRequest):
    """
    ãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒ (T2I)
    
    ä¾‹:
    ```
    curl -X POST http://localhost:8000/generate \
      -H "Content-Type: application/json" \
      -d '{
        "prompt": "beautiful anime girl",
        "num_steps": 20
      }'
    ```
    """
    
    global generation_count
    
    if not generator:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    try:
        logger.info(f"Generating: {request.prompt[:50]}")
        
        start = time.time()
        
        image = generator.generate_image(
            prompt=request.prompt,
            negative_prompt=request.negative_prompt,
            num_inference_steps=request.num_steps,
            guidance_scale=request.guidance_scale
        )
        
        elapsed = time.time() - start
        generation_count += 1
        
        # ç”»åƒã‚’ base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        image_bytes = io.BytesIO()
        image.save(image_bytes, format="PNG")
        image_b64 = base64.b64encode(image_bytes.getvalue()).decode()
        
        return {
            "success": True,
            "image_base64": image_b64,
            "generation_time_s": elapsed,
            "prompt": request.prompt,
            "total_generations": generation_count
        }
    
    except Exception as e:
        logger.error(f"Generation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/img2img")
async def img2img(
    input_image: UploadFile = File(...),
    prompt: str = Form(...),
    negative_prompt: str = Form(""),
    strength: float = Form(0.8),
    num_steps: int = Form(20)
):
    """
    Image-to-Image å¤‰æ›
    
    ä¾‹:
    ```
    curl -X POST http://localhost:8000/img2img \
      -F "input_image=@sketch.png" \
      -F "prompt=anime girl" \
      -F "strength=0.8"
    ```
    """
    
    global generation_count
    
    if not multimodal:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    try:
        # ç”»åƒèª­ã¿è¾¼ã¿
        image_data = await input_image.read()
        input_img = Image.open(io.BytesIO(image_data))
        
        logger.info(f"I2I: {prompt[:50]}")
        
        start = time.time()
        
        output = multimodal.image_to_image(
            input_image=input_img,
            prompt=prompt,
            negative_prompt=negative_prompt,
            strength=strength,
            num_inference_steps=num_steps
        )
        
        elapsed = time.time() - start
        generation_count += 1
        
        # Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        output_bytes = io.BytesIO()
        output.save(output_bytes, format="PNG")
        output_b64 = base64.b64encode(output_bytes.getvalue()).decode()
        
        return {
            "success": True,
            "image_base64": output_b64,
            "generation_time_s": elapsed,
            "prompt": prompt,
            "strength": strength
        }
    
    except Exception as e:
        logger.error(f"I2I error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/inpaint")
async def inpaint(
    input_image: UploadFile = File(...),
    mask_image: UploadFile = File(...),
    prompt: str = Form(...),
    negative_prompt: str = Form("")
):
    """
    å±€æ‰€ç·¨é›† (Inpainting)
    
    ä¾‹:
    ```
    curl -X POST http://localhost:8000/inpaint \
      -F "input_image=@character.png" \
      -F "mask_image=@mask.png" \
      -F "prompt=blue hair"
    ```
    """
    
    global generation_count
    
    if not multimodal:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    try:
        # ç”»åƒèª­ã¿è¾¼ã¿
        input_data = await input_image.read()
        mask_data = await mask_image.read()
        
        input_img = Image.open(io.BytesIO(input_data))
        mask_img = Image.open(io.BytesIO(mask_data))
        
        logger.info(f"Inpainting: {prompt[:50]}")
        
        start = time.time()
        
        output = multimodal.inpaint(
            input_image=input_img,
            mask_image=mask_img,
            prompt=prompt,
            negative_prompt=negative_prompt
        )
        
        elapsed = time.time() - start
        generation_count += 1
        
        # Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        output_bytes = io.BytesIO()
        output.save(output_bytes, format="PNG")
        output_b64 = base64.b64encode(output_bytes.getvalue()).decode()
        
        return {
            "success": True,
            "image_base64": output_b64,
            "generation_time_s": elapsed,
            "prompt": prompt
        }
    
    except Exception as e:
        logger.error(f"Inpainting error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ========== ãƒ¡ã‚¤ãƒ³ ==========

if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
```

### Step 2: Streamlit ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰

**ãƒ•ã‚¡ã‚¤ãƒ«**: `streamlit_app.py` ã‚’æ–°è¦ä½œæˆ

```python
#!/usr/bin/env python3
"""
Streamlit Web UI: ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ç”Ÿæˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰

å®Ÿè¡Œ:
    streamlit run streamlit_app.py --server.port=8501
"""

import streamlit as st
from streamlit_option_menu import option_menu
import requests
import base64
from PIL import Image
import io
import time

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Anime Character Generator",
    page_icon="âœ¨",
    layout="wide"
)

# API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
API_URL = "http://localhost:8000"

# ========== Sidebar ==========

st.sidebar.title("ğŸ¨ Anime Generator")
st.sidebar.markdown("---")

# ãƒ¡ãƒ‹ãƒ¥ãƒ¼
with st.sidebar:
    selected = option_menu(
        menu_title="ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
        options=["T2Iï¼ˆãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒï¼‰", "I2Iï¼ˆç”»åƒâ†’ç”»åƒï¼‰", "Inpaintingï¼ˆå±€æ‰€ç·¨é›†ï¼‰", "ãƒãƒƒãƒå‡¦ç†", "API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ"],
        icons=["sparkles", "image", "pencil-square", "files", "book"],
        menu_icon="cast"
    )

st.sidebar.markdown("---")

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
try:
    health = requests.get(f"{API_URL}/health", timeout=2).json()
    st.sidebar.metric("ğŸŸ¢ Status", "Online")
    st.sidebar.metric("ç”Ÿæˆæ•°", health["total_generations"])
except:
    st.sidebar.metric("ğŸ”´ Status", "Offline")
    st.error("âš ï¸  API ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

# ========== ãƒšãƒ¼ã‚¸å®Ÿè£… ==========

if selected == "T2Iï¼ˆãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒï¼‰":
    st.title("âœ¨ ãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒ ç”Ÿæˆ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        prompt = st.text_area(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="beautiful anime girl, long hair, masterpiece",
            height=100
        )
        negative_prompt = st.text_area(
            "ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="low quality, blurry",
            height=50
        )
    
    with col2:
        num_steps = st.slider("ã‚¹ãƒ†ãƒƒãƒ—æ•°", 10, 50, 20)
        guidance_scale = st.slider("Guidance Scale", 1.0, 20.0, 7.5)
        use_lcm = st.checkbox("LCM ä½¿ç”¨ï¼ˆé«˜é€ŸåŒ–ï¼‰")
    
    if st.button("ğŸ¨ ç”Ÿæˆ", use_container_width=True):
        with st.spinner("ç”Ÿæˆä¸­..."):
            try:
                start = time.time()
                
                response = requests.post(
                    f"{API_URL}/generate",
                    json={
                        "prompt": prompt,
                        "negative_prompt": negative_prompt,
                        "num_steps": num_steps,
                        "guidance_scale": guidance_scale,
                        "use_lcm": use_lcm
                    },
                    timeout=300
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # ç”»åƒè¡¨ç¤º
                    image_data = base64.b64decode(data["image_base64"])
                    image = Image.open(io.BytesIO(image_data))
                    
                    elapsed = time.time() - start
                    
                    st.image(image, use_column_width=True)
                    st.success(f"âœ… ç”Ÿæˆå®Œäº† ({elapsed:.1f}s)")
                    st.json({
                        "prompt": data["prompt"],
                        "generation_time_s": f"{data['generation_time_s']:.2f}",
                        "total_generations": data["total_generations"]
                    })
                else:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.json()['detail']}")
            
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")


elif selected == "I2Iï¼ˆç”»åƒâ†’ç”»åƒï¼‰":
    st.title("ğŸ–¼ï¸  Image-to-Image å¤‰æ›")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("å…¥åŠ›ç”»åƒ")
        uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"])
        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, use_column_width=True)
    
    with col2:
        st.subheader("è¨­å®š")
        prompt = st.text_area("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", value="anime character, masterpiece")
        strength = st.slider("å¤‰æ›´åº¦", 0.0, 1.0, 0.8)
        num_steps = st.slider("ã‚¹ãƒ†ãƒƒãƒ—æ•°", 10, 50, 20)
    
    if st.button("âœ¨ å¤‰æ›", use_container_width=True) and uploaded_file:
        with st.spinner("å‡¦ç†ä¸­..."):
            try:
                files = {
                    "input_image": uploaded_file.getvalue(),
                }
                data = {
                    "prompt": prompt,
                    "strength": strength,
                    "num_steps": num_steps
                }
                
                response = requests.post(
                    f"{API_URL}/img2img",
                    files=files,
                    data=data,
                    timeout=300
                )
                
                if response.status_code == 200:
                    result = response.json()
                    
                    output_data = base64.b64decode(result["image_base64"])
                    output_image = Image.open(io.BytesIO(output_data))
                    st.image(output_image, use_column_width=True)
                    st.success(f"âœ… å®Œäº† ({result['generation_time_s']:.1f}s)")
                else:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.json()['detail']}")
            
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")


elif selected == "Inpaintingï¼ˆå±€æ‰€ç·¨é›†ï¼‰":
    st.title("âœï¸  å±€æ‰€ç·¨é›† (Inpainting)")
    
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        st.subheader("å…ƒç”»åƒ")
        image_file = st.file_uploader("ç”»åƒ", type=["png", "jpg"], key="base_img")
        if image_file:
            st.image(image_file, use_column_width=True)
    
    with col2:
        st.subheader("ãƒã‚¹ã‚¯")
        mask_file = st.file_uploader("ãƒã‚¹ã‚¯ç”»åƒï¼ˆç™½=ç·¨é›†ï¼‰", type=["png", "jpg"], key="mask_img")
        if mask_file:
            st.image(mask_file, use_column_width=True)
    
    with col3:
        st.subheader("è¨­å®š")
        prompt = st.text_area("ç·¨é›†å†…å®¹", value="blue hair")
    
    if st.button("ğŸ¨ é©ç”¨", use_container_width=True) and image_file and mask_file:
        with st.spinner("å‡¦ç†ä¸­..."):
            try:
                response = requests.post(
                    f"{API_URL}/inpaint",
                    files={
                        "input_image": image_file.getvalue(),
                        "mask_image": mask_file.getvalue()
                    },
                    data={"prompt": prompt},
                    timeout=300
                )
                
                if response.status_code == 200:
                    result = response.json()
                    output_data = base64.b64decode(result["image_base64"])
                    output_image = Image.open(io.BytesIO(output_data))
                    st.image(output_image, use_column_width=True)
                    st.success(f"âœ… å®Œäº† ({result['generation_time_s']:.1f}s)")
                else:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼")
            
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")


elif selected == "ãƒãƒƒãƒå‡¦ç†":
    st.title("ğŸ“¦ ãƒãƒƒãƒå‡¦ç†")
    st.info("è¤‡æ•°ç”»åƒã®ä¸€æ‹¬ç”Ÿæˆã¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµŒç”±ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")
    
    st.code("""
# Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹
import requests

for i in range(10):
    response = requests.post(f"{API_URL}/generate", json={
        "prompt": "anime girl"
    })
    # çµæœå‡¦ç†
    """, language="python")


elif selected == "API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ":
    st.title("ğŸ“š API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    
    st.markdown("""
    ### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    
    #### POST /generate
    ãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒ ç”Ÿæˆ
    
    **ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:**
    ```json
    {
      "prompt": "beautiful anime girl",
      "negative_prompt": "",
      "num_steps": 20,
      "guidance_scale": 7.5,
      "use_lcm": false
    }
    ```
    
    **ãƒ¬ã‚¹ãƒãƒ³ã‚¹:**
    ```json
    {
      "success": true,
      "image_base64": "...",
      "generation_time_s": 5.2,
      "total_generations": 42
    }
    ```
    
    ---
    
    #### POST /img2img
    Image-to-Image å¤‰æ›
    
    **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
    - `input_image`: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
    - `prompt`: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    - `strength`: å¤‰æ›´åº¦ (0-1)
    - `num_steps`: ã‚¹ãƒ†ãƒƒãƒ—æ•°
    
    ---
    
    #### POST /inpaint
    å±€æ‰€ç·¨é›†
    
    **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
    - `input_image`: å…ƒç”»åƒ
    - `mask_image`: ãƒã‚¹ã‚¯ç”»åƒ
    - `prompt`: ç·¨é›†å†…å®¹
    
    ---
    
    #### GET /health
    ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    
    #### GET /models
    ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«æƒ…å ±
    
    ---
    
    ### å®Œå…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    
    http://localhost:8000/docs (Swagger UI)
    """)
```

### Step 3: Docker & Deployment

```dockerfile
# Dockerfile

FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

WORKDIR /app

# Python ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && apt-get install -y \
    python3.10 python3-pip git && \
    rm -rf /var/lib/apt/lists/*

# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
COPY requirements_deploy.txt .
RUN pip install -q -r requirements_deploy.txt

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ”ãƒ¼
COPY api_server.py .
COPY streamlit_app.py .
COPY character_generator.py .
COPY multimodal_pipeline.py .
COPY lora_weights/ ./lora_weights/

# ãƒãƒ¼ãƒˆ
EXPOSE 8000 8501

# ã‚¹ã‚¿ãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
COPY docker-entrypoint.sh .
RUN chmod +x docker-entrypoint.sh

CMD ["./docker-entrypoint.sh"]
```

```bash
# docker-entrypoint.sh

#!/bin/bash

# API ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
python api_server.py &

# Streamlit UI èµ·å‹•
streamlit run streamlit_app.py \
  --server.port=8501 \
  --server.address=0.0.0.0 \
  --client.toolbarPosition=bottom
```

```yaml
# docker-compose.yml

version: '3.8'

services:
  anime-generator:
    build: .
    ports:
      - "8000:8000"  # API
      - "8501:8501"  # Streamlit UI
    environment:
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./outputs:/app/outputs
      - ./lora_weights:/app/lora_weights
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

## ğŸ“Š ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥

### é–‹ç™ºç’°å¢ƒ

```bash
# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ
python api_server.py  # ã‚¿ãƒ¼ãƒŸãƒŠãƒ« 1
streamlit run streamlit_app.py --server.port=8501  # ã‚¿ãƒ¼ãƒŸãƒŠãƒ« 2

# ã‚¢ã‚¯ã‚»ã‚¹
# API: http://localhost:8000/docs
# UI: http://localhost:8501
```

### æœ¬ç•ªç’°å¢ƒ (GCP)

```bash
# Container Registry ã¸ãƒ—ãƒƒã‚·ãƒ¥
docker build -t gcr.io/PROJECT_ID/anime-gen:latest .
docker push gcr.io/PROJECT_ID/anime-gen:latest

# Cloud Run ã¸ãƒ‡ãƒ—ãƒ­ã‚¤
gcloud run deploy anime-generator \
  --image gcr.io/PROJECT_ID/anime-gen:latest \
  --platform managed \
  --region us-central1 \
  --memory 16Gi \
  --cpu 4 \
  --gpu 1  # GPU T4
  --timeout 600
```

### æœ¬ç•ªç’°å¢ƒ (Heroku)

```bash
# Heroku CLI
heroku login
heroku create anime-character-generator
heroku config:set GPU_MEMORY=0.9

# ãƒ‡ãƒ—ãƒ­ã‚¤
git push heroku main

# ç¢ºèª
heroku logs --tail
```

---

## âœ… å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

ãƒ•ã‚§ãƒ¼ã‚º 4 å®Ÿè£…ã®å®Œäº†åŸºæº–ï¼š

### Backend (FastAPI)
- [ ] `api_server.py` å®Ÿè£…å®Œäº†
- [ ] å…¨ 5 ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå‹•ä½œç¢ºèª
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£…
- [ ] ã‚¹ãƒ¯ãƒƒã‚¬ãƒ¼ UI ãƒ†ã‚¹ãƒˆ (`/docs`)
- [ ] ãƒ­ãƒ¼ã‚«ãƒ«å‹•ä½œç¢ºèª

### Frontend (Streamlit)
- [ ] `streamlit_app.py` å®Ÿè£…å®Œäº†
- [ ] 5 ãƒšãƒ¼ã‚¸ãƒ¡ãƒ‹ãƒ¥ãƒ¼å®Ÿè£…
- [ ] ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ç¢ºèª
- [ ] T2I, I2I, Inpainting ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] UI ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ç¢ºèª

### Docker & Cloud
- [ ] `Dockerfile` ä½œæˆå®Œäº†
- [ ] `docker-compose.yml` ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ­ãƒ¼ã‚«ãƒ« Docker å®Ÿè¡Œç¢ºèª
- [ ] GCP Deploy ãƒ†ã‚¹ãƒˆ
- [ ] Heroku Deploy ãƒ†ã‚¹ãƒˆ

### Integration
- [ ] API â†” UI é€£æºç¢ºèª
- [ ] ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ç¢ºèª
- [ ] ãƒãƒ«ãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆåŒæ™‚å‡¦ç†ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ç¢ºèª

### Documentation
- [ ] ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †æ›¸ä½œæˆ
- [ ] API ä»•æ§˜æ›¸ä½œæˆ
- [ ] ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰
- [ ] ãƒ–ãƒ­ã‚°è¨˜äº‹ã€ŒProduction ç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã€

---

## ğŸ“ Phase 1-4 å®Œäº†æ™‚ã®åˆ°é”ç‚¹

```
âœ… Phase 1: LLM Ã— Prompt Optimization
   - RobustPromptGenerator å®Ÿè£…
   - Anthropic Claude API çµ±åˆ
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

âœ… Phase 2A: LoRA Fine-tuning
   - 300 æšã® anime ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
   - 20 ã‚¨ãƒãƒƒã‚¯å­¦ç¿’å®Œäº†
   - anime-lora-final/ å‡ºåŠ›

âœ… Phase 2B: LCM Distillation
   - 4-step LCM ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ
   - æ¨è«– 12x é«˜é€ŸåŒ–ç¢ºèª

âœ… Phase 3: Multimodal Operations
   - Image-to-Image ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
   - ControlNet (Pose/Edges)
   - Inpainting å±€æ‰€ç·¨é›†

âœ… Phase 4: Production Deployment
   - FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
   - Streamlit ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
   - Docker ã‚³ãƒ³ãƒ†ãƒŠåŒ–
   - GCP/Heroku æœ¬ç•ªå±•é–‹

çµæœ: ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã® AI ã‚µãƒ¼ãƒ“ã‚¹å®Œæˆ ğŸš€
```

---

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼** ğŸ‰

æ¬¡ã¯ â†’ [IMPLEMENTATION_ROADMAP.md](IMPLEMENTATION_ROADMAP.md) ã§å…¨ä½“é€²æ—ã‚’ç¢ºèª

