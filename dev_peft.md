# ğŸ¨ LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œã‚¬ã‚¤ãƒ‰ v2.1

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: anime-character-generator Phase 2A å®Ÿè£…  
**ç›®æ¨™**: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¯¾å¿œãƒ»20ã‚¨ãƒãƒƒã‚¯æœ€é©åŒ–ã«ã‚ˆã‚‹å®Ÿè·µçš„ LoRA å­¦ç¿’  
**æ¨å®šæœŸé–“**: **3æ—¥é–“ï¼ˆColab ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰** / 10-12æ™‚é–“ï¼ˆå®Ÿå­¦ç¿’æ™‚é–“ï¼‰  
**æœ€çµ‚æˆæœç‰©**: `anime-lora-final/` + 5ã¤ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ + `training_log.json`

---

## âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

```bash
# Colab ã§ã®å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰
# 1. train_lora.py ã‚’ Colab ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# 2. training_data/ ã‚’ Colab ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã¾ãŸã¯ãƒã‚¦ãƒ³ãƒˆï¼‰
# 3. ä»¥ä¸‹ã‚’å®Ÿè¡Œ:

python train_lora.py \
    --data_dir ./training_data \
    --output_dir ./lora_weights \
    --epochs 20 \
    --batch_size 2 \
    --learning_rate 1e-4

# ä¸­æ–­ã‹ã‚‰å†é–‹ã™ã‚‹å ´åˆ:
python train_lora.py \
    --data_dir ./training_data \
    --output_dir ./lora_weights \
    --epochs 20 \
    --resume_from ./lora_weights/checkpoint-epoch-5
```

---

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### Phase 2A: ãªãœã“ã®è¨­è¨ˆã‹ï¼Ÿ

| é …ç›® | v2.0ï¼ˆç†æƒ³ï¼‰ | v2.1ï¼ˆå®Ÿè·µçš„ï¼‰ | æ”¹å–„ç†ç”± |
|------|-----------|-------------|--------|
| ã‚¨ãƒãƒƒã‚¯æ•° | 50-100 | **20** | å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿(300æš)ã¯10-15ã§åæŸ |
| å­¦ç¿’æ™‚é–“ | 50-100æ™‚é–“ | **10-12æ™‚é–“** | Colab 12h/day åˆ¶ç´„ã«å¯¾å¿œ |
| ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ | ãªã— | **æ¯5ã‚¨ãƒãƒƒã‚¯** | Colab ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­å¯¾ç­– |
| ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†å‰² | é€£ç¶š | **3å›ï¼ˆ3æ—¥ï¼‰** | ç¾å®Ÿçš„ãªå­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« |
| å†é–‹æ©Ÿèƒ½ | æœªå®Ÿè£… | **å®Ÿè£…æ¸ˆã¿** | --resume_from ã§å®Œå…¨å¯¾å¿œ |
| é€²æ—ãƒ­ã‚° | ãªã— | **training_log.json** | æå¤±æ›²ç·šã‚’å¯è¦–åŒ– |
| å®Ÿè£…çŠ¶æ…‹ | è¨­è¨ˆã®ã¿ | **âœ… å®Œå…¨å®Ÿè£…** | production-ready |

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¦‚è¦

```
ğŸ“Š training_data/ (æ—¢ã«300æšæƒã£ã¦ã„ã¾ã™)
â”œâ”€ impressionist_style/      60æš (å°è±¡æ´¾é¢¨)
â”œâ”€ oil_painting_aesthetic/   60æš (æ²¹å½©é¢¨)  
â”œâ”€ pastel_softness/          60æš (ãƒ‘ã‚¹ãƒ†ãƒ«èª¿)
â”œâ”€ sketch_aesthetic/         60æš (ã‚¹ã‚±ãƒƒãƒé¢¨)
â”œâ”€ soft_focus_landscape/     60æš (æœ§ã’ãªé¢¨æ™¯)
â”œâ”€ metadata.json             (ã‚¿ã‚°æƒ…å ±)
â””â”€ download_log.txt          (åé›†ãƒ­ã‚°)

åˆè¨ˆ: 300æš | ç·å®¹é‡: ~600MB

ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼: âœ… å®Œäº†
```

---

## ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†ã®çµŒç·¯ã¨æ–¹æ³•

### ãªãœ Danbooru ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‹ï¼Ÿ

LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯ã€**çµ±ä¸€ã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒã¤ç”»åƒãŒå¿…è¦**ã§ã™ã€‚æ±ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆImageNet ãªã©ï¼‰ã§ã¯ãªãã€**ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆå°‚é–€ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹** ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ï¼š

- âœ… å°è±¡æ´¾é¢¨ã€æ°´å½©ç”»çš„ã€æ²¹å½©é¢¨ãªã©**ã‚¹ã‚¿ã‚¤ãƒ«ã®çµ±ä¸€æ€§**
- âœ… **ã‚¿ã‚°ãƒ™ãƒ¼ã‚¹ã®ä½“ç³»çš„ãªåˆ†é¡**ï¼ˆmetadata.json ã§ç®¡ç†ï¼‰
- âœ… **å•†ç”¨ãƒ»å­¦ç¿’åˆ©ç”¨å¯èƒ½ãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç¢ºèª**
- âœ… é«˜å“è³ªã® 512Ã—512 ç›¸å½“ã®ç”»åƒ

### åé›†æ–¹æ³•: scripts/download_danbooru.py

**ãƒ•ã‚¡ã‚¤ãƒ«ä½ç½®**: `/Users/yoshihisashinzaki/ai_projects/anime-character-generator/scripts/download_danbooru.py`

```python
#!/usr/bin/env python3
"""
Danbooru ã‹ã‚‰å°è±¡æ´¾é¢¨ã‚¢ãƒ‹ãƒ¡ç”»åƒã‚’åé›†ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨ä¾‹:
    python scripts/download_danbooru.py --output training_data --limit 60

ç‰¹å¾´:
- ã‚¹ã‚¿ã‚¤ãƒ«åˆ¥ã‚¿ã‚°å®šç¾©ã§ä½“ç³»çš„ã«åé›†
- metadata.json ã§å„ç”»åƒã®ãƒ¡ã‚¿æƒ…å ±ã‚’è¨˜éŒ²
- API ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã‚’è‡ªå‹•åˆ¶å¾¡ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿ï¼‰
"""

import requests
import json
import os
from pathlib import Path
from typing import List, Dict
from tqdm import tqdm
import time

class DanbooruDownloader:
    """Danbooru ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    
    BASE_URL = "https://danbooru.donmai.us/posts.json"
    
    # ã‚¹ã‚¿ã‚¤ãƒ«åˆ¥ã‚¿ã‚°å®šç¾©
    STYLE_TAGS = {
        "impressionist_style": [
            "watercolor", "impressionist_style", "-lowres"
        ],
        "soft_focus_landscape": [
            "soft_focus", "landscape", "anime", "-fake_photorealism", "-lowres"
        ],
        "oil_painting_aesthetic": [
            "oil_painting_style", "aesthetic", "anime", "-lowres"
        ],
        "sketch_aesthetic": [
            "sketch", "anime_sketch", "aesthetic", "-lowres"
        ],
        "pastel_softness": [
            "pastel_colors", "soft_shading", "anime", "-lowres"
        ]
    }
    
    def __init__(self, output_dir: str = "training_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.metadata = []
        self.download_log = []
    
    def download_images(self, limit_per_style: int = 60):
        """ã‚¹ã‚¿ã‚¤ãƒ«åˆ¥ã«ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        
        total_downloaded = 0
        
        for style_name, tags in self.STYLE_TAGS.items():
            print(f"\nğŸ“¥ Downloading: {style_name}")
            print(f"   Tags: {', '.join(tags)}")
            
            # ã‚¹ã‚¿ã‚¤ãƒ«åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            style_dir = self.output_dir / style_name
            style_dir.mkdir(exist_ok=True)
            
            downloaded = self._download_style(style_name, tags, style_dir, limit_per_style)
            total_downloaded += downloaded
            
            print(f"   âœ… {downloaded}/{limit_per_style} downloaded")
            time.sleep(2)  # API ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ï¼ˆDanbooru ã¸ã®è² è·è»½æ¸›ï¼‰
        
        print(f"\nâœ… Total: {total_downloaded} images downloaded")
        self._save_metadata()
        return total_downloaded
    
    def _download_style(self, style_name: str, tags: List[str], 
                       output_dir: Path, limit: int) -> int:
        """ç‰¹å®šã‚¹ã‚¿ã‚¤ãƒ«ã®ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        
        tag_string = " ".join(tags)
        downloaded = 0
        page = 1
        
        with tqdm(total=limit, desc=style_name) as pbar:
            while downloaded < limit:
                try:
                    response = requests.get(
                        self.BASE_URL,
                        params={
                            "tags": tag_string,
                            "limit": 200,
                            "page": page
                        },
                        timeout=10
                    )
                    response.raise_for_status()
                    
                    images = response.json()
                    if not images:
                        break
                    
                    for image in images:
                        if downloaded >= limit:
                            break
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ« URL å–å¾—
                        file_url = None
                        if "file_url" in image:
                            file_url = image["file_url"]
                        elif "large_file_url" in image:
                            file_url = image["large_file_url"]
                        
                        if not file_url:
                            continue
                        
                        # ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        try:
                            img_response = requests.get(file_url, timeout=10)
                            img_response.raise_for_status()
                            
                            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                            filename = f"{style_name}_{downloaded:03d}.png"
                            filepath = output_dir / filename
                            
                            with open(filepath, "wb") as f:
                                f.write(img_response.content)
                            
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²
                            self.metadata.append({
                                "file": str(filepath.relative_to(self.output_dir)),
                                "style": style_name,
                                "tags": image.get("tag_string_general", "").split(),
                                "width": image.get("image_width"),
                                "height": image.get("image_height")
                            })
                            
                            self.download_log.append(f"âœ… Downloaded: {filename}")
                            downloaded += 1
                            pbar.update(1)
                        
                        except Exception as e:
                            self.download_log.append(f"âŒ Failed: {file_url} - {e}")
                            continue
                    
                    page += 1
                
                except Exception as e:
                    print(f"   âš ï¸  API Error: {e}")
                    break
        
        return downloaded
    
    def _save_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ JSON ä¿å­˜"""
        
        metadata_file = self.output_dir / "metadata.json"
        metadata_dict = {
            "total_images": len(self.metadata),
            "styles": list(self.STYLE_TAGS.keys()),
            "training_data": self.metadata
        }
        
        with open(metadata_file, "w", encoding="utf-8") as f:
            json.dump(metadata_dict, f, ensure_ascii=False, indent=2)
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        log_file = self.output_dir / "download_log.txt"
        with open(log_file, "w", encoding="utf-8") as f:
            f.write("\n".join(self.download_log))
        
        print(f"\nğŸ“Š Metadata saved: {metadata_file}")
        print(f"ğŸ“‹ Log saved: {log_file}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Danbooru ã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    parser.add_argument("--output", default="training_data", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--limit", type=int, default=60, help="ã‚¹ã‚¿ã‚¤ãƒ«ã‚ãŸã‚Šã®æšæ•°")
    
    args = parser.parse_args()
    
    downloader = DanbooruDownloader(output_dir=args.output)
    total = downloader.download_images(limit_per_style=args.limit)
    
    print(f"\nğŸ‰ å®Œäº†: {total} æšã®ç”»åƒã‚’åé›†ã—ã¾ã—ãŸ")
```

### å®Ÿè¡Œæ–¹æ³•ï¼ˆãƒ‡ãƒ¼ã‚¿å†åé›†ãŒå¿…è¦ãªå ´åˆï¼‰

```bash
# ç’°å¢ƒæº–å‚™
pip install requests pillow tqdm

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
python scripts/download_danbooru.py \
    --output training_data \
    --limit 60

# çµæœç¢ºèª
ls -lh training_data/
# å‡ºåŠ›ä¾‹:
# impressionist_style/      (60 PNG files)
# oil_painting_aesthetic/   (60 PNG files)
# pastel_softness/          (60 PNG files)
# sketch_aesthetic/         (60 PNG files)
# soft_focus_landscape/     (60 PNG files)
# metadata.json             (ã‚¿ã‚°æƒ…å ±)
# download_log.txt          (å®Ÿè¡Œãƒ­ã‚°)
```

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ: scripts/validate_dataset.py

```python
#!/usr/bin/env python3
"""
å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
"""

from PIL import Image
from pathlib import Path

def validate_training_data(data_dir="training_data"):
    """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯"""
    
    print("ğŸ“Š Validating training data...\n")
    
    data_path = Path(data_dir)
    total_images = 0
    issues = []
    
    for style_dir in data_path.iterdir():
        if not style_dir.is_dir() or style_dir.name.startswith("."):
            continue
        
        print(f"ğŸ“ {style_dir.name}/")
        style_count = 0
        
        for img_file in sorted(style_dir.glob("*.png")) + sorted(style_dir.glob("*.jpg")):
            try:
                img = Image.open(img_file)
                
                # ã‚µã‚¤ã‚º ãƒã‚§ãƒƒã‚¯
                if img.size[0] < 256 or img.size[1] < 256:
                    issues.append(f"âš ï¸  Small image: {img_file.name} ({img.size})")
                
                style_count += 1
            except Exception as e:
                issues.append(f"âŒ Corrupt: {img_file.name} - {e}")
        
        print(f"   âœ… {style_count} images valid")
        total_images += style_count
    
    print(f"\nğŸ“Š Summary:")
    print(f"   Total images: {total_images}")
    print(f"   Issues found: {len(issues)}")
    
    if issues:
        print("\nâš ï¸  Issues found:")
        for issue in issues[:10]:  # æœ€åˆã®10ä»¶è¡¨ç¤º
            print(f"   {issue}")
    
    # æˆåŠŸåˆ¤å®š
    success = total_images >= 200
    print(f"\n{'âœ… Dataset ready' if success else 'âŒ Need more images'}")
    return success

if __name__ == "__main__":
    validate_training_data()
```

### metadata.json ã®æ§‹é€ ä¾‹

```json
{
  "total_images": 300,
  "styles": [
    "impressionist_style",
    "oil_painting_aesthetic",
    "pastel_softness",
    "sketch_aesthetic",
    "soft_focus_landscape"
  ],
  "training_data": [
    {
      "file": "impressionist_style/impressionist_style_000.png",
      "style": "impressionist_style",
      "tags": ["watercolor", "landscape", "soft focus", "anime"],
      "width": 512,
      "height": 512
    },
    {
      "file": "oil_painting_aesthetic/oil_painting_aesthetic_001.png",
      "style": "oil_painting_aesthetic",
      "tags": ["oil painting", "texture", "aesthetic"],
      "width": 576,
      "height": 512
    }
    ...
  ]
}
```

### ãƒ‡ãƒ¼ã‚¿åé›†ã‚’æŒ¯ã‚Šè¿”ã‚‹

```
ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–‹ç™ºã®æµã‚Œï¼š

1. è¦ä»¶å®šç¾©
   - å°è±¡æ´¾ã€æ°´å½©ã€æ²¹å½©ãªã©ã‚¹ã‚¿ã‚¤ãƒ«åˆ¥ã®åˆ†é¡
   - å„ã‚¹ã‚¿ã‚¤ãƒ« 60 æš Ã— 5 ã‚¹ã‚¿ã‚¤ãƒ« = 300 æš

2. ã‚½ãƒ¼ã‚¹é¸å®š
   - Danbooru: ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆå°‚é–€ã€ã‚¿ã‚°ãŒè±Šå¯Œ
   - å…¬é–‹ API ã§è‡ªå‹•åé›†å¯èƒ½
   - ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç¢ºèªå®Œäº†

3. ã‚¿ã‚°æˆ¦ç•¥
   - "watercolor" + "impressionist_style" â†’ å°è±¡æ´¾
   - "oil_painting_style" â†’ æ²¹å½©é¢¨
   - "soft_focus" + "landscape" â†’ æœ§ã’ãªé¢¨æ™¯
   - "-lowres" ã§ä½å“è³ªç”»åƒã‚’é™¤å¤–

4. è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
   - download_danbooru.py: ä½“ç³»çš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
   - metadata.json: å„ç”»åƒã®è©³ç´°æƒ…å ±ã‚’è¨˜éŒ²
   - validate_dataset.py: å“è³ªãƒã‚§ãƒƒã‚¯

5. çµæœ
   - âœ… 300 æšã®çµ±ä¸€ã‚¹ã‚¿ã‚¤ãƒ«ç”»åƒã‚’åé›†
   - âœ… metadata.json ã§ç”»åƒæƒ…å ±ã‚’ç®¡ç†
   - âœ… download_log.txt ã§åé›†å±¥æ­´ã‚’è¨˜éŒ²
```

---

## ğŸ—ï¸ Phase 2A: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

### å…¨ä½“ãƒ•ãƒ­ãƒ¼å›³

```
[Colab T4 GPU]
    â†“
[train_lora.py å®Ÿè¡Œ]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Session 1: Epoch 1-5 (~2.5æ™‚é–“)         â”‚
â”‚ âœ… checkpoint-epoch-5/ä¿å­˜               â”‚
â”‚    training_log.json è¨˜éŒ²                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Session 2: Epoch 5-10 (~2.5æ™‚é–“)        â”‚
â”‚ å®Ÿè¡Œ: --resume_from checkpoint-epoch-5   â”‚
â”‚ âœ… checkpoint-epoch-10/ ä¿å­˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Session 3: Epoch 10-20 (~5æ™‚é–“)         â”‚
â”‚ å®Ÿè¡Œ: --resume_from checkpoint-epoch-10  â”‚
â”‚ âœ… anime-lora-final/ ä¿å­˜               â”‚
â”‚ âœ… training_log.json å®Œæˆ (å…¨20ã‚¨ãƒãƒƒã‚¯) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
[HuggingFace Hub ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)]
    â†“
[character_generator.py ã§æ¨è«–]
```

### å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

```
lora_weights/
â”œâ”€â”€ checkpoint-epoch-5/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.bin
â”‚   â””â”€â”€ training_metadata.json  â† å†é–‹ç”¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
â”œâ”€â”€ checkpoint-epoch-10/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.bin
â”‚   â””â”€â”€ training_metadata.json
â”œâ”€â”€ checkpoint-epoch-15/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.bin
â”‚   â””â”€â”€ training_metadata.json
â”œâ”€â”€ checkpoint-epoch-20/        â† æœ€å¾Œã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.bin
â”‚   â””â”€â”€ training_metadata.json
â”œâ”€â”€ anime-lora-final/           â† æœ¬ç•ªãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€çµ‚ï¼‰
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â””â”€â”€ adapter_model.bin
â””â”€â”€ training_log.json           â† å…¨ã‚¨ãƒãƒƒã‚¯ã®æå¤±æ›²ç·š
```

---

## ğŸš€ å®Ÿè£…æ¸ˆã¿ã® train_lora.py ã®è©³ç´°

### train_lora.py ã®ä¸»è¦ã‚¯ãƒ©ã‚¹

#### 1. `AnimeDataset` ã‚¯ãƒ©ã‚¹

```python
class AnimeDataset(Dataset):
    """
    training_data/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ç”»åƒã‚’è‡ªå‹•ç™ºè¦‹
    
    ç‰¹å¾´:
    - ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è‡ªå‹•èªè­˜
    - PNG/JPG ä¸¡å¯¾å¿œ
    - ãƒªã‚µã‚¤ã‚ºãƒ»æ­£è¦åŒ–ã‚’è‡ªå‹•å®Ÿè¡Œ
    """
    
    def __init__(self, data_dir: str, resolution: int = 512):
        # å†å¸°çš„ã«å…¨ç”»åƒã®ãƒ‘ã‚¹ã‚’ç™ºè¦‹
        self.image_paths = []
        for style_dir in Path(data_dir).iterdir():
            self.image_paths.extend(list(style_dir.glob("*.png")))
            self.image_paths.extend(list(style_dir.glob("*.jpg")))
        
        print(f"âœ… Found {len(self.image_paths)} images in {data_dir}")
    
    def __len__(self) -> int:
        return len(self.image_paths)
    
    def __getitem__(self, idx: int) -> torch.Tensor:
        # ç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰ã€ãƒªã‚µã‚¤ã‚ºã€æ­£è¦åŒ–
        image = Image.open(self.image_paths[idx]).convert("RGB")
        image = self.transform(image)  # 512Ã—512 ã«ãƒªã‚µã‚¤ã‚ºç­‰
        return image
```

**å®Ÿéš›ã®ä½¿ç”¨:**

```python
dataset = AnimeDataset(data_dir="./training_data", resolution=512)
# â†’ è‡ªå‹•ã§ 300 æšå…¨ã¦ç™ºè¦‹
# â†’ ãƒ¡ãƒ¢ãƒªé…ç½®: ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ï¼ˆå¿…è¦ãªæ™‚ã ã‘ãƒ­ãƒ¼ãƒ‰ï¼‰
```

#### 2. `LoRATrainer` ã‚¯ãƒ©ã‚¹

```python
class LoRATrainer:
    """
    Stable Diffusion v1.5 ã« LoRA ã‚’é©ç”¨ã—ã¦å­¦ç¿’
    
    ç‰¹å¾´:
    - PEFT ã‚’ä½¿ç”¨ã—ãŸè»½é‡ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
    - æ¯ 5 ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
    - æå¤±å±¥æ­´ã‚’ JSON ã«è¨˜éŒ²
    - ä¸­æ–­ãƒ»å†é–‹æ©Ÿèƒ½å®Œå…¨å¯¾å¿œ
    """
    
    def setup_model(self):
        """LoRA è¨­å®š"""
        # 1. Stable Diffusion v1.5 ãƒ­ãƒ¼ãƒ‰
        pipe = StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16,  # ãƒ¡ãƒ¢ãƒªç¯€ç´„
            safety_checker=None
        )
        
        # 2. VAEãƒ»Text Encoder ã¯å‡çµï¼ˆUNet ã® LoRA ã®ã¿å­¦ç¿’ï¼‰
        pipe.vae.requires_grad_(False)
        pipe.text_encoder.requires_grad_(False)
        
        # 3. UNet ã« LoRA é©ç”¨
        lora_config = LoraConfig(
            r=32,  # LoRA ãƒ©ãƒ³ã‚¯
            lora_alpha=32,
            target_modules=["to_k", "to_v", "to_q", "to_out"],
            lora_dropout=0.1,
            bias="none"
        )
        pipe.unet = get_peft_model(pipe.unet, lora_config)
        
        return pipe
    
    def train(self, ..., resume_from: Optional[str] = None):
        """
        å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¯¾å¿œï¼‰
        """
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹
        if resume_from:
            adapter_path = Path(resume_from)
            self.pipe.unet.load_adapter(adapter_path)
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–‹å§‹ã‚¨ãƒãƒƒã‚¯ã‚’å–å¾—
            with open(adapter_path / "training_metadata.json") as f:
                metadata = json.load(f)
                start_epoch = metadata.get("epoch", 0)
        else:
            start_epoch = 0
        
        # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        for epoch in range(start_epoch, num_epochs):
            epoch_loss = 0.0
            
            for batch in dataloader:
                # å‰å‘ãè¨ˆç®— â†’ æå¤± â†’ ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒƒãƒ—
                loss = self.compute_loss(batch)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆæ¯ 5 ã‚¨ãƒãƒƒã‚¯ï¼‰
            if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:
                checkpoint_dir = output_dir / f"checkpoint-epoch-{epoch+1}"
                checkpoint_dir.mkdir(parents=True, exist_ok=True)
                
                # LoRA ã‚¦ã‚§ã‚¤ãƒˆä¿å­˜
                self.pipe.unet.save_pretrained(checkpoint_dir)
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²ï¼ˆå†é–‹ç”¨ï¼‰
                metadata = {
                    "epoch": epoch + 1,
                    "timestamp": datetime.now().isoformat(),
                    "loss": epoch_loss / len(dataloader)
                }
                with open(checkpoint_dir / "training_metadata.json", "w") as f:
                    json.dump(metadata, f)
                
                # å­¦ç¿’ãƒ­ã‚°è¨˜éŒ²
                self.training_log.append({
                    "epoch": epoch + 1,
                    "loss": epoch_loss / len(dataloader)
                })
```

### CLI ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```bash
python train_lora.py \
    --data_dir ./training_data          # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹
    --output_dir ./lora_weights         # å‡ºåŠ›å…ˆ
    --epochs 20                         # ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰
    --batch_size 2                      # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆT4 æœ€é©ï¼‰
    --learning_rate 1e-4                # å­¦ç¿’ç‡
    --lora_rank 32                      # LoRA ãƒ©ãƒ³ã‚¯
    --resume_from ./lora_weights/checkpoint-epoch-5  # å†é–‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```

### ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£èª¬

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ | ç†ç”± |
|-----------|-----|------|
| **Epochs** | 20 | 300æš Ã— 20 = 6000æšç›¸å½“ (å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ååˆ†) |
| **Batch Size** | 2 | T4 (16GB VRAM) ã§ fp16 å®Ÿè¡Œå¯èƒ½ |
| **Learning Rate** | 1e-4 | LoRA ã§ã¯ä½ã‚ãŒå®‰å®š |
| **LoRA Rank** | 32 | å“è³ªã¨åŠ¹ç‡ã®ãƒãƒ©ãƒ³ã‚¹ |
| **Checkpoint Interval** | 5 epochs | I/O ã¨ãƒªã‚«ãƒãƒªæ™‚é–“ã®ãƒãƒ©ãƒ³ã‚¹ (~1.5h) |

---

## ğŸ“… å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ3æ—¥åˆ†å‰²è¨ˆç”»ï¼‰

### Day 1: Session 1 - Epoch 1-5

**æ‰€è¦æ™‚é–“**: 2.5æ™‚é–“ç¨‹åº¦

```bash
# Colab ã‚»ãƒ« 1: ç’°å¢ƒæ§‹ç¯‰
!pip install -q peft diffusers transformers accelerate safetensors pillow tqdm

# Colab ã‚»ãƒ« 2: åˆå›å®Ÿè¡Œ
%cd /content/anime-character-generator
!python train_lora.py \
    --data_dir ./training_data \
    --output_dir ./lora_weights \
    --epochs 20 \
    --batch_size 2 \
    --learning_rate 1e-4

# ãƒ­ã‚°ç¢ºèª (ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†å‰)
!ls -lh lora_weights/
# å‡ºåŠ›ä¾‹:
# checkpoint-epoch-5/
# training_log.json
```

**ç¢ºèªé …ç›®:**
- âœ… checkpoint-epoch-5/ ãŒä½œæˆã•ã‚ŒãŸã‹ï¼Ÿ
- âœ… training_metadata.json ã« epoch: 5 ã¨ timestamp ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ
- âœ… training_log.json ã«æŸå¤±å€¤ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ

**å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒ«:**

```json
// training_log.json (Session 1 çµ‚äº†æ™‚)
[
  {"epoch": 1, "loss": 0.1234},
  {"epoch": 2, "loss": 0.0987},
  {"epoch": 3, "loss": 0.0854},
  {"epoch": 4, "loss": 0.0723},
  {"epoch": 5, "loss": 0.0652}
]
```

### Day 2: Session 2 - Epoch 5-10

**æº–å‚™**: å‰æ—¥ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ä½ç½®ã‚’ç¢ºèª

```bash
# Colab ã‚»ãƒ«: ä¸­æ–­ã‹ã‚‰å†é–‹
%cd /content/anime-character-generator
!python train_lora.py \
    --data_dir ./training_data \
    --output_dir ./lora_weights \
    --epochs 20 \
    --resume_from ./lora_weights/checkpoint-epoch-5
```

**å†…éƒ¨å‡¦ç†:**
1. checkpoint-epoch-5/adapter_config.json ã‚’ãƒ­ãƒ¼ãƒ‰
2. training_metadata.json ã‹ã‚‰ epoch=5 ã‚’å–å¾— â†’ start_epoch=5 ã«è¨­å®š
3. epoch 5 ã‹ã‚‰å­¦ç¿’å†é–‹
4. epoch 10 ã«åˆ°é”æ™‚ã« checkpoint-epoch-10/ ã‚’è‡ªå‹•ä¿å­˜

**å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒ«:**

```json
// training_log.json (Session 2 çµ‚äº†æ™‚)
[
  {"epoch": 1, "loss": 0.1234},
  {"epoch": 2, "loss": 0.0987},
  {"epoch": 3, "loss": 0.0854},
  {"epoch": 4, "loss": 0.0723},
  {"epoch": 5, "loss": 0.0652},
  {"epoch": 6, "loss": 0.0598},  â† Session 2
  {"epoch": 7, "loss": 0.0521},
  {"epoch": 8, "loss": 0.0467},
  {"epoch": 9, "loss": 0.0412},
  {"epoch": 10, "loss": 0.0387}
]
```

### Day 3: Session 3 - Epoch 10-20

**æº–å‚™**: checkpoint-epoch-10/ ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª

```bash
# Colab ã‚»ãƒ«: æœ€çµ‚ã‚»ãƒƒã‚·ãƒ§ãƒ³
%cd /content/anime-character-generator
!python train_lora.py \
    --data_dir ./training_data \
    --output_dir ./lora_weights \
    --epochs 20 \
    --resume_from ./lora_weights/checkpoint-epoch-10
```

**æœ€çµ‚å‡ºåŠ›:**
- checkpoint-epoch-15/
- checkpoint-epoch-20/
- anime-lora-final/ (20ã‚¨ãƒãƒƒã‚¯æ™‚ç‚¹ã§ã®æœ€çµ‚ãƒ¢ãƒ‡ãƒ«)
- training_log.json (å®Œå…¨20ã‚¨ãƒãƒƒã‚¯åˆ†)

**å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒ«:**

```json
// training_log.json (æœ€çµ‚ç‰ˆ)
[
  ... (epoch 1-10ã¯å‰ã‚»ãƒƒã‚·ãƒ§ãƒ³)
  {"epoch": 11, "loss": 0.0351},
  {"epoch": 12, "loss": 0.0312},
  {"epoch": 13, "loss": 0.0287},
  {"epoch": 14, "loss": 0.0268},
  {"epoch": 15, "loss": 0.0249},
  {"epoch": 16, "loss": 0.0223},
  {"epoch": 17, "loss": 0.0201},
  {"epoch": 18, "loss": 0.0178},
  {"epoch": 19, "loss": 0.0156},
  {"epoch": 20, "loss": 0.0142}  â† åæŸå®Œäº†
]
```

---

## âœ… å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Colab Session ã®å®Ÿè¡Œå‰ãƒã‚§ãƒƒã‚¯

```
â–¡ training_data/ ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹
â–¡ train_lora.py ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹
â–¡ pip ä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ (diffusers, peft etc.)
â–¡ GPU ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ (nvidia-smi ã§ç¢ºèª)
â–¡ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã« 2GB ä»¥ä¸Šã®ç©ºãå®¹é‡ãŒã‚ã‚‹
```

### å„ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®ãƒã‚§ãƒƒã‚¯

**Session 1 çµ‚äº†æ™‚:**

```bash
# ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
!ls -lh lora_weights/
# æœŸå¾…: checkpoint-epoch-5/, training_log.json

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
!cat lora_weights/checkpoint-epoch-5/training_metadata.json
# æœŸå¾…: epoch: 5, timestamp, loss

# ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
!rm -rf ~/.cache/huggingface/hub/*  # Colab ãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
```

**Session 2 çµ‚äº†æ™‚:**

```bash
# ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
!ls -lh lora_weights/
# æœŸå¾…: checkpoint-epoch-5/, checkpoint-epoch-10/, training_log.json

# training_log.json ã®å†…å®¹ç¢ºèª
!tail -n 5 lora_weights/training_log.json
# æœŸå¾…: epoch 6-10 ã®æå¤±ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹
```

**Session 3 çµ‚äº†æ™‚:**

```bash
# æœ€çµ‚å‡ºåŠ›ç¢ºèª
!ls -lh lora_weights/
# æœŸå¾…: checkpoint-epoch-15/, checkpoint-epoch-20/, anime-lora-final/

# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ç¢ºèª
!ls -lh lora_weights/anime-lora-final/
# æœŸå¾…: adapter_config.json (~1KB), adapter_model.bin (~3-4MB)

# å­¦ç¿’æ›²ç·šç¢ºèª
!python -c "import json; data = json.load(open('lora_weights/training_log.json')); print([d['loss'] for d in data])"
# æœŸå¾…: æå¤±ãŒå˜èª¿æ¸›å°‘ (åæŸ)
```

---

## ï¿½ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### âŒ ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ ã¨ å¯¾å‡¦æ³•

#### 1. `ModuleNotFoundError: No module named 'peft'`

```
åŸå› : PEFT ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„
å¯¾å‡¦:
  !pip install -q peft
  !pip install -q diffusers transformers accelerate
```

#### 2. `CUDA out of memory`

```
åŸå› : ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹
å¯¾å‡¦:
  # ã‚³ãƒãƒ³ãƒ‰ã«è¿½åŠ :
  --batch_size 1  # 2 ã‹ã‚‰ 1 ã«å‰Šæ¸›ï¼ˆå­¦ç¿’ã¯é…ããªã‚‹ãŒå¯èƒ½ï¼‰
```

#### 3. `checkpoint-epoch-5/ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ (å†é–‹æ™‚)`

```
åŸå› : å‰å›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ãªã„
ç¢ºèª:
  !ls -lh lora_weights/
  # â†’ checkpoint-epoch-5/ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
å¯¾å‡¦:
  # å­˜åœ¨ã—ãªã‘ã‚Œã°ã€--resume_from ãªã—ã§æœ€åˆã‹ã‚‰å®Ÿè¡Œ
  !python train_lora.py --data_dir ./training_data --output_dir ./lora_weights --epochs 20
```

#### 4. `training_log.json ãŒæå‚·ã—ã¦ã„ã‚‹`

```
åŸå› : ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­æ–­ã«ã‚ˆã‚Š JSON ãŒä¸å®Œå…¨
å¯¾å‡¦:
  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
  !cp lora_weights/training_log.json lora_weights/training_log.json.bak
  
  # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè‡ªå‹•çš„ã« JSON ã‚’ä¿®å¾©ãƒ»è£œå®Œã™ã‚‹
  # å†é–‹å®Ÿè¡Œæ™‚ã«æ­£å¸¸åŒ–ã•ã‚Œã‚‹
```

#### 5. `Colab ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ–­æ™‚ã®å¯¾å‡¦`

```
çŠ¶æ³: å­¦ç¿’ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚ŒãŸ
    â†’ training_log.json ã®æœ€å¾Œã®ã‚¨ãƒãƒƒã‚¯ = ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯
ç¢ºèª:
  !tail -n 1 lora_weights/training_log.json
  # ä¾‹: {"epoch": 7, "loss": 0.0521}
  # â†’ epoch 7 ã¾ã§å®Œäº†ã€æ¬¡ã¯ epoch 8 ã‹ã‚‰å†é–‹
ä»£æ›¿ãˆ:
  # checkpoint-epoch-5/ ãŒå­˜åœ¨ã™ã‚Œã°å•é¡Œãªã—
  !python train_lora.py \
      --data_dir ./training_data \
      --output_dir ./lora_weights \
      --epochs 20 \
      --resume_from ./lora_weights/checkpoint-epoch-5
```

---

## ğŸ¯ æ¨è«–çµ±åˆ: character_generator.py ã§ã®ä½¿ç”¨

### 4.1 LoRA é‡ã¿ã®ãƒ­ãƒ¼ãƒ‰ãƒ»æ¨è«–

**ãƒ•ã‚¡ã‚¤ãƒ«: `character_generator.py` ã® modify ç®‡æ‰€**

```python
import torch
from diffusers import StableDiffusionPipeline
from peft import PeftModel

class AnimeCharacterGenerator:
    def __init__(self, model_name="runwayml/stable-diffusion-v1-5"):
        self.model_name = model_name
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            safety_checker=None
        )
        self.lora_loaded = False
    
    def load_lora(self, lora_path: str = "./lora_weights/anime-lora-final"):
        """LoRA é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
        try:
            self.pipe.unet.load_adapter(lora_path, adapter_name="anime_lora")
            self.lora_loaded = True
            print(f"âœ… LoRA loaded from {lora_path}")
        except Exception as e:
            print(f"âŒ Failed to load LoRA: {e}")
            self.lora_loaded = False
    
    def unload_lora(self):
        """LoRA é‡ã¿ã‚’ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        if self.lora_loaded:
            self.pipe.unet.delete_adapter("anime_lora")
            self.lora_loaded = False
            print("âœ… LoRA unloaded")
    
    def generate_image(
        self,
        prompt: str,
        use_lora: bool = False,
        num_inference_steps: int = 20,
        guidance_scale: float = 7.5,
        seed: int = None
    ) -> Image:
        """
        ç”»åƒç”Ÿæˆï¼ˆLoRA å¯¾å¿œï¼‰
        
        Args:
            prompt: ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            use_lora: LoRA ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            num_inference_steps: æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—
            guidance_scale: ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚¹ã‚±ãƒ¼ãƒ«
            seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼ˆå†ç¾æ€§ç”¨ï¼‰
        
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸ PIL Image
        """
        
        # ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if seed is not None:
            torch.manual_seed(seed)
        
        # LoRA é©ç”¨
        if use_lora and not self.lora_loaded:
            self.load_lora()
        elif not use_lora and self.lora_loaded:
            self.unload_lora()
        
        # æ¨è«–
        with torch.no_grad():
            result = self.pipe(
                prompt=prompt,
                negative_prompt="low quality, worst quality",
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale
            )
        
        return result.images[0]
    
    def generate_batch(
        self,
        prompts: list,
        use_lora: bool = False,
        **kwargs
    ) -> list:
        """ãƒãƒƒãƒæ¨è«–"""
        images = []
        for prompt in prompts:
            img = self.generate_image(prompt, use_lora=use_lora, **kwargs)
            images.append(img)
        return images
```

### 4.2 ä½¿ç”¨ä¾‹

```python
# åˆæœŸåŒ–
generator = AnimeCharacterGenerator()

# ä¾‹ 1: v1.5 ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ç”Ÿæˆ
prompt1 = "1girl, anime, beautiful, masterpiece, high quality"
img1 = generator.generate_image(prompt1, use_lora=False)
img1.save("output_v1.5.png")

# ä¾‹ 2: LoRA é©ç”¨ç‰ˆã§ç”Ÿæˆï¼ˆåŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
img2 = generator.generate_image(prompt1, use_lora=True)
img2.save("output_lora.png")

# ä¾‹ 3: ãƒãƒƒãƒæ¨è«–
prompts = [
    "1girl, watercolor style, soft colors",
    "1girl, impressionist, oil painting aesthetic",
    "1girl, sketch aesthetic, soft focus"
]
images_lora = generator.generate_batch(prompts, use_lora=True)

for i, img in enumerate(images_lora):
    img.save(f"batch_{i:02d}_lora.png")

# LoRA ã‚’ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¡ãƒ¢ãƒªè§£æ”¾ï¼‰
generator.unload_lora()
```

---

## ğŸ“Š å“è³ªè©•ä¾¡ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

### æå¤±æ›²ç·šã®èª­ã¿æ–¹

```python
import json
import matplotlib.pyplot as plt

# training_log.json ã‚’ãƒ­ãƒ¼ãƒ‰
with open("lora_weights/training_log.json") as f:
    logs = json.load(f)

# æå¤±æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆ
epochs = [log["epoch"] for log in logs]
losses = [log["loss"] for log in logs]

plt.figure(figsize=(10, 6))
plt.plot(epochs, losses, marker='o', linestyle='-', linewidth=2)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("LoRA Training Loss Curve")
plt.grid(True)
plt.yscale("log")  # ãƒ­ã‚°ã‚¹ã‚±ãƒ¼ãƒ«
plt.savefig("training_curve.png", dpi=150, bbox_inches='tight')
plt.show()

# çµ±è¨ˆæƒ…å ±
print(f"Initial Loss: {losses[0]:.6f}")
print(f"Final Loss: {losses[-1]:.6f}")
print(f"Reduction: {(1 - losses[-1]/losses[0]) * 100:.1f}%")
print(f"Average Loss: {sum(losses) / len(losses):.6f}")
```

### æˆåŠŸã®ç›®å®‰

```
âœ… è‰¯å¥½ãªå­¦ç¿’:
   - Epoch 1 â†’ 20 ã§ æå¤±ãŒ 30-50% ä½ä¸‹
   - æœ€çµ‚æå¤± < 0.05
   - æå¤±ãŒå˜èª¿æ¸›å°‘ï¼ˆãƒã‚¤ã‚ºã¯è¨±å®¹ï¼‰

âš ï¸  ä¸é©åˆ‡ãªå­¦ç¿’:
   - æå¤±ãŒå¢—åŠ å‚¾å‘ â†’ å­¦ç¿’ç‡ãŒé«˜ã„
   - æœ€çµ‚æå¤±ãŒåæŸã—ãªã„ â†’ ã‚¨ãƒãƒƒã‚¯æ•°ä¸è¶³
   - Epoch 5 ã§æ—¢ã« plateau â†’ å­¦ç¿’ç‡ãŒä½ã„

âŒ å¤±æ•—ã®å…†å€™:
   - æå¤±ãŒ NaN ã«ãªã‚‹ â†’ VRAM ä¸è¶³ã¾ãŸã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºéå¤§
   - æå¤±ãŒç™ºæ•£ â†’ å­¦ç¿’ç‡ãŒé«˜ã™ãã‚‹
   - checkpoint ãŒä¿å­˜ã•ã‚Œãªã„ â†’ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä¸è¶³
```

---

## ğŸš€ æ¨è«–ã®æœ€é©åŒ–

### æ¨è«–é€Ÿåº¦å‘ä¸Šï¼ˆé«˜åº¦ãªè¨­å®šï¼‰

```python
from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    safety_checker=None
)

# LoRA ãƒ­ãƒ¼ãƒ‰
pipe.unet.load_adapter("./lora_weights/anime-lora-final")

# æœ€é©åŒ– 1: xFormers ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
try:
    pipe.enable_xformers_memory_efficient_attention()
    print("âœ… xFormers enabled")
except ImportError:
    print("âš ï¸  xFormers not available (pip install xformers)")

# æœ€é©åŒ– 2: ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ« (Torch 2.0+)
try:
    pipe.unet = torch.compile(pipe.unet, mode="reduced-overhead")
    print("âœ… Model compiled with torch.compile")
except Exception as e:
    print(f"âš ï¸  torch.compile not available: {e}")

# æ¨è«–ãƒ†ã‚¹ãƒˆ
import time
prompt = "1girl, masterpiece, high quality"

start = time.time()
image = pipe(prompt, num_inference_steps=20).images[0]
elapsed = time.time() - start

print(f"ğŸš€ Generated in {elapsed:.2f} seconds")
```

### æ¨è«–æ™‚é–“ã®ç›®å®‰

```
ç’°å¢ƒ: Colab T4 GPU, fp16, LoRA é©ç”¨

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ (20 steps):
  - æœ€é©åŒ–ãªã—: 5-7 ç§’
  - xFormers + compile: 3-4 ç§’

é«˜é€ŸåŒ– (LCM ä½¿ç”¨æ™‚):
  - 4 steps: 1-2 ç§’
```

---

## ğŸ“¤ HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 1: Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ¨å¥¨ï¼‰

```bash
# æ—¢ã«ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ upload_to_huggingface.py ã‚’ä½¿ç”¨
export HF_TOKEN="your_huggingface_token_here"

python upload_to_huggingface.py \
    --model-path ./lora_weights/anime-lora-final \
    --repo-name anime-character-lora \
    --hf-token $HF_TOKEN \
    --private false
```

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ 2: CLI ã‚³ãƒãƒ³ãƒ‰

```bash
# HuggingFace CLI ãƒ„ãƒ¼ãƒ«
pip install huggingface-hub

# ãƒ­ã‚°ã‚¤ãƒ³
huggingface-cli login
# â†’ ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›

# ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ & ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
huggingface-cli repo create anime-character-lora --type model
cd lora_weights/anime-lora-final
git clone https://huggingface.co/YOUR_USERNAME/anime-character-lora
cd anime-character-lora
cp ../adapter_config.json .
cp ../adapter_model.bin .
git add .
git commit -m "Add anime LoRA model"
git push origin main
```

### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®åˆ©ç”¨æ–¹æ³•

```python
from diffusers import StableDiffusionPipeline

# ãƒªãƒ¢ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ­ãƒ¼ãƒ‰
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    safety_checker=None
)

# HuggingFace Hub ã‹ã‚‰LoRA ãƒ­ãƒ¼ãƒ‰
pipe.unet.load_adapter("YOUR_USERNAME/anime-character-lora")

# æ¨è«–
image = pipe(prompt="1girl, masterpiece").images[0]
```

---

## ğŸ“‹ å®Œæˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 2A å®Œäº†æ™‚ã®ç¢ºèªé …ç›®

```
âœ… å­¦ç¿’å®Œäº†
   â–¡ 20 ã‚¨ãƒãƒƒã‚¯å­¦ç¿’å®Œäº†
   â–¡ training_log.json ã« 20 å€‹ã®ã‚¨ãƒ³ãƒˆãƒª
   â–¡ anime-lora-final/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨
   â–¡ adapter_model.bin ã‚µã‚¤ã‚º 3-4 MB

âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
   â–¡ checkpoint-epoch-5/ å­˜åœ¨
   â–¡ checkpoint-epoch-10/ å­˜åœ¨
   â–¡ checkpoint-epoch-15/ å­˜åœ¨
   â–¡ checkpoint-epoch-20/ å­˜åœ¨
   â–¡ å„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã« training_metadata.json

âœ… æ¨è«–ãƒ†ã‚¹ãƒˆ
   â–¡ v1.5 vs LoRA ã§ç”»åƒæ¯”è¼ƒå¯èƒ½
   â–¡ LoRA é©ç”¨ç‰ˆã§å°è±¡æ´¾é¢¨ã‚¹ã‚¿ã‚¤ãƒ«ç¢ºèª
   â–¡ æ¨è«–æ™‚é–“ 3-5 ç§’ / ç”»åƒ

âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
   â–¡ character_generator.py ã‚’ LoRA å¯¾å¿œã«æ›´æ–°
   â–¡ README.md ã« LoRA ä½¿ç”¨æ–¹æ³•ã‚’è¨˜è¼‰
   â–¡ dev_peft.mdï¼ˆæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰å®Œæˆ

âœ… ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
   â–¡ HuggingFace Hub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
   â–¡ ãƒªãƒ¢ãƒ¼ãƒˆã‹ã‚‰ã®ãƒ­ãƒ¼ãƒ‰ç¢ºèª
```

---

## ğŸ“š å‚è€ƒãƒ»è¿½åŠ è³‡æ–™

### å­¦è¡“è«–æ–‡
- **PEFT (Parameter-Efficient Fine-Tuning)**: https://arxiv.org/abs/2305.18356
- **LoRA (Low-Rank Adaptation)**: https://arxiv.org/abs/2106.09685
- **Stable Diffusion**: https://arxiv.org/abs/2112.10752

### å®Ÿè£…ãƒªã‚½ãƒ¼ã‚¹
- **HuggingFace PEFT**: https://github.com/huggingface/peft
- **Diffusers LoRA Tutorial**: https://huggingface.co/docs/diffusers/training/lora
- **LoRA ã®è©³ç´°è§£èª¬**: https://huggingface.co/blog/lora

### é–¢é€£ãƒ–ãƒ­ã‚°è¨˜äº‹ï¼ˆæ›¸äºˆå®šï¼‰
- ã€ŒPEFT ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã£ãŸåŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€
- ã€ŒLoRA ãƒ©ãƒ³ã‚¯ã®é¸æŠ: å“è³ªã¨åŠ¹ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã€
- ã€ŒColab T4 ã§ã® LoRA å­¦ç¿’ãƒã‚¹ã‚¿ãƒ¼ã‚¬ã‚¤ãƒ‰ã€
- ã€Œcheckpoints ã‹ã‚‰å†é–‹ã™ã‚‹ä»•çµ„ã¿ã®è§£èª¬ã€

---

## ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### Phase 2A å®Œäº†å¾Œ

1. **å“è³ªè©•ä¾¡ãƒ–ãƒ­ã‚°è¨˜äº‹åŸ·ç­†** (1-2æ—¥)
   - å­¦ç¿’æ›²ç·šã®è§£èª¬
   - v1.5 vs LoRA æ¯”è¼ƒ
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯

2. **Phase 2B: LCM è’¸ç•™** (3-5æ—¥)
   - æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—å‰Šæ¸› (20 â†’ 4)
   - æ¨è«–æ™‚é–“ 5ç§’ â†’ 1ç§’ã«é«˜é€ŸåŒ–

3. **Phase 3: Image-to-Image çµ±åˆ** (3æ—¥)
   - æ—¢å­˜ç”»åƒ â†’ LoRA ã‚¹ã‚¿ã‚¤ãƒ«å¤‰æ›
   - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ„Ÿæƒ…å¤‰åŒ–ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³

4. **æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤** (1æ—¥)
   - HuggingFace Hub å…¬é–‹
   - Streamlit Web UI

---

## ğŸ“ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ˜ãƒ«ãƒ—

**Colab å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆ:**

1. **GPU ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ç¢ºèª**
   ```bash
   !nvidia-smi  # GPU ä½¿ç”¨çŠ¶æ³ã‚’ç¢ºèª
   ```

2. **ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
   ```bash
   !pip install --upgrade pip
   !pip install --upgrade -r requirements.txt
   ```

3. **ãƒ¡ãƒ¢ãƒªã‚’ã‚¯ãƒªã‚¢**
   ```bash
   import gc
   gc.collect()
   torch.cuda.empty_cache()
   ```

4. **Colab ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ãƒªã‚»ãƒƒãƒˆ**
   - ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  â†’ ã™ã¹ã¦ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œè§£é™¤
   - ãƒ©ãƒ³ã‚¿ã‚¤ãƒ  â†’ ãƒªã‚»ãƒƒãƒˆï¼ˆå…¨ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢ï¼‰

5. **ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã§ç›¸è«‡**
   - https://github.com/huggingface/diffusers/discussions
   - https://forums.fast.ai/

---

**æœ€çµ‚æ›´æ–°**: 2026å¹´2æœˆ19æ—¥  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.1 - Checkpoint å¯¾å¿œãƒ»å®Ÿè£…å®Œäº†ç‰ˆ  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ğŸš€ Colab ã§ã®å®Ÿè¡Œã«å‘ã‘ã¦æº–å‚™å®Œäº†
