# ğŸ¨ Anime Character Generator - LoRA Models

**ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«:** Stable Diffusion v1.5  
**ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•:** LoRA (Low-Rank Adaptation)  
**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:** ~2-3 MB (è»½é‡ãƒ»é«˜é€Ÿæ¨è«–å¯¾å¿œ)  
**æ¨è«–é€Ÿåº¦:** 4-20 ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆLCMå¯¾å¿œï¼‰

> ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ Latent Diffusion (Rombach et al., 2022) ã¨ LoRA (Hu et al., 2021) ã‚’çµ„ã¿åˆã‚ã›ãŸè»½é‡ãªã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

---

## ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±

| é …ç›® | è©³ç´° |
|------|------|
| **ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«** | `runwayml/stable-diffusion-v1-5` |
| **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡åŒ–æ‰‹æ³•** | LoRA (PEFT) + Latent Space Adaptation |
| **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿** | Danbooru ã‚¢ãƒ‹ãƒ¡ç”»åƒï¼ˆã‚¹ã‚¿ã‚¤ãƒ«åˆ¥åˆ†é¡ï¼‰ |
| **LoRA ãƒ©ãƒ³ã‚¯** | **32** (è«–æ–‡æ¨å¥¨å€¤ã®1.5å€) |
| **LoRA ã‚¢ãƒ«ãƒ•ã‚¡å€¤** | **32** (rank = alpha ç›¸å½“) |
| **å¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«** | `to_k, to_v, to_q` (Attentionå±¤) |
| **å­¦ç¿’ç‡** | 1e-4 (Latent Diffusionæœ€é©åŒ–) |
| **ãƒãƒƒãƒã‚µã‚¤ã‚º** | 2-4 (Colab T4æœ€é©åŒ–: 16GB VRAM) |
| **æœ€é©åŒ–æ‰‹æ³•** | AdamW (weight_decay=0.01) |
| **ç²¾åº¦** | fp16/mixed precision |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1: diffusers + PEFTï¼ˆæ¨å¥¨ã€æœ€ã‚‚ç°¡å˜ï¼‰

```python
import torch
from diffusers import StableDiffusionPipeline
from peft import PeftModel

# ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)

# LoRA é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆHuggingFace Hubï¼‰
pipe.unet = PeftModel.from_pretrained(
    pipe.unet,
    "YOUR_USERNAME/anime-character-lora",  # ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®ID
    adapter_name="anime_lora"
)

pipe = pipe.to("cuda")

# ç”»åƒç”Ÿæˆ
prompt = "1girl, anime character, masterpiece, high quality"
negative_prompt = "low quality, nsfw, blurry, distorted, worst quality"

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=20,
    guidance_scale=7.5,
    height=512,
    width=512,
    generator=torch.Generator(device="cuda").manual_seed(42)
).images[0]

image.save("output.png")
```

### æ–¹æ³• 2: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰

```python
# ã™ã§ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã® SAFETENSORS ãƒ•ã‚¡ã‚¤ãƒ«
pipe.unet = PeftModel.from_pretrained(
    pipe.unet,
    "./downloaded_lora/",  # or "./anime-lora.safetensors"
    adapter_name="anime_lora"
)
```

### æ–¹æ³• 3: é«˜é€Ÿæ¨è«– (LCMå¯¾å¿œ)

```python
from diffusers import LCMScheduler

# LCM ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã§ 4 ã‚¹ãƒ†ãƒƒãƒ—ã«çŸ­ç¸®
pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)

# åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§é«˜é€Ÿç”Ÿæˆï¼ˆ35ms vs 500msï¼‰
image = pipe(
    prompt=prompt,
    num_inference_steps=4,  # LCM: 2-8ã‚¹ãƒ†ãƒƒãƒ—ã§ååˆ†
    guidance_scale=1.0,  # LCMã§ã¯guidanceã‚’ä½ã‚ã«
    height=512,
    width=512
).images[0]
```

### æ–¹æ³• 4: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ CLI ã§ä½¿ç”¨

```bash
# anime-character-generator ãƒªãƒã‚¸ãƒˆãƒªã§ã®ä½¿ç”¨
python character_generator.py \
  --use-lora \
  --emotion happy \
  --style casual

# LoRA é©ç”¨å¾Œã®ç”»åƒç”Ÿæˆ
```

---

## ğŸ¨ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ & æ¨å¥¨è¨­å®š

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ï¼ˆ3å±¤ãƒãƒ«ãƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆï¼‰

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ­ãƒã‚¹ãƒˆãƒã‚¹å‘ä¸Šã‚’ç›®æ¨™ã«ã€3å±¤æ§‹é€ ã‚’æ¨å¥¨ï¼š

```
ãƒ¬ã‚¤ãƒ¤ãƒ¼1ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼‰: 1girl, anime character, detailed face, beautiful eyes
ãƒ¬ã‚¤ãƒ¤ãƒ¼2ï¼ˆã‚¹ã‚¿ã‚¤ãƒ«ï¼‰: watercolor painting style, soft colors, bokeh background  
ãƒ¬ã‚¤ãƒ¤ãƒ¼3ï¼ˆå“è³ªä¿®é£¾ï¼‰: masterpiece, best quality, high quality, intricate details
```

**å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ï¼š**
```
1girl, anime character, detailed beautiful face, long hair, 
watercolor painting style, soft colors, bokeh background, 
masterpiece, best quality, high quality, intricate details
```

### æ¨å¥¨ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

```
low quality, worst quality, blurry, distorted, watermark, 
error, nsfw, extra limbs, missing limbs, ugly, bad anatomy, 
bad proportions, text, username, signature, bad hand
```

### æ¨å¥¨ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | LCMé«˜é€Ÿ | é«˜å“è³ª |
|-----------|-----------|--------|--------|
| `num_inference_steps` | **20** | **4-6** | **30-50** |
| `guidance_scale` | **7.5** | **1.0-2.0** | **7.5-10.0** |
| `height / width` | **512Ã—512** | **512Ã—512** | **768Ã—768** |
| `generator seed` | -1 (ãƒ©ãƒ³ãƒ€ãƒ ) | -1 | ä»»æ„ (å†ç¾æ€§) |

**æ¨å¥¨ã‚³ãƒ³ãƒœ:**
- ğŸš€ **é«˜é€Ÿ:** 4ã‚¹ãƒ†ãƒƒãƒ— + LCMã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ© + guidance_scale=1.5
- âš–ï¸ **ãƒãƒ©ãƒ³ã‚¹:** 20ã‚¹ãƒ†ãƒƒãƒ— + DPMã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ© + guidance_scale=7.5  
- ğŸ¨ **é«˜å“è³ª:** 50ã‚¹ãƒ†ãƒƒãƒ— + DPMã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ© + guidance_scale=8.5

---

## ğŸ“ˆ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è©³ç´°

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

Danbooru ã‚ˆã‚Šè‡ªå‹•åé›†ãƒ»åˆ†é¡ã•ã‚ŒãŸã‚¢ãƒ‹ãƒ¡ç”»åƒï¼š

| ã‚¹ã‚¿ã‚¤ãƒ« | æšæ•° | ç‰¹å¾´ | ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º |
|---------|------|------|------------|
| **impressionist_style** | ~60æš | å°è±¡æ´¾é¢¨ã€ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ | ~120 MB |
| **soft_focus_landscape** | ~60æš | ã‚½ãƒ•ãƒˆãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã€é¢¨æ™¯ | ~120 MB |
| **oil_painting_aesthetic** | ~60æš | æ²¹çµµèª¿ã€é¢¨æ™¯ | ~120 MB |
| **sketch_aesthetic** | ~60æš | ã‚¹ã‚±ãƒƒãƒã€ç·šç”» | ~120 MB |
| **pastel_softness** | ~60æš | ãƒ‘ã‚¹ãƒ†ãƒ«ã‚«ãƒ©ãƒ¼ã€ã‚„ã•ã—ã„è‰²åˆã„ | ~120 MB |

**åˆè¨ˆ:** ~300 æšã€~600 MB

### å­¦ç¿’è¨­å®šï¼ˆImprovement_Plan.md æº–æ‹ ï¼‰

```python
# Phase 2A ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
model_config = {
    "model_id": "runwayml/stable-diffusion-v1-5",
    "lora_rank": 32,
    "lora_alpha": 32,
    "lora_dropout": 0.1,
    "target_modules": ["to_k", "to_v", "to_q"],  # Attentionå±¤
}

training_config = {
    "learning_rate": 1e-4,
    "batch_size": 2,  # Colab T4 æœ€é©åŒ–
    "num_epochs": 50-100,
    "gradient_accumulation_steps": 1,
    "mixed_precision": "fp16",
    "optimizer": "AdamW",
    "weight_decay": 0.01,
    "max_grad_norm": 1.0,
    "warmup_steps": 100,
    "scheduler": "linear"
}

inference_config = {
    "seed": 42,
    "guidance_scale": 7.5,
    "num_inference_steps": 20,
    "height": 512,
    "width": 512,
    "dtype": "float16"  # fp16æ¨è«–
}
```

### å­¦ç¿’æ›²ç·šï¼ˆå…¸å‹çš„ï¼‰

```
Epoch   Loss        Validation
1       0.32        -
10      0.15        0.14
25      0.09        0.08
50      0.05        0.05
100     0.04        0.04
```

**ç‰¹æ€§:**
- åˆæœŸæ®µéšã§æ€¥é€Ÿã«æ”¹å–„
- 10-15ã‚¨ãƒãƒƒã‚¯å¾Œã«å®‰å®š
- éå­¦ç¿’ãªã—ã§50-100ã‚¨ãƒãƒƒã‚¯æ¨å¥¨
- ç·å­¦ç¿’æ™‚é–“: 1-3æ™‚é–“ (Colab T4)

### ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–

```
ãƒ™ãƒ¼ã‚¹ Stable Diffusion: 7.7 GB VRAM
+ LoRA ã‚¢ãƒ€ãƒ—ã‚¿: +0.5 GB
åˆè¨ˆ: ~8.2 GB VRAM ä½¿ç”¨ (Colab T4 16GB ã«åã¾ã‚‹)

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šæ¸›:
- ãƒ•ãƒ«å¾®èª¿æ•´: 865M ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- LoRAé©å¿œ: 32K ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (0.0037%)
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ~2-3 MB (ãƒ•ãƒ«æ™‚: 4GB)
```

---

## ğŸ¯ ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã®ç†è«–çš„åŸºç›¤

ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ä»¥ä¸‹ã®å­¦è¡“è«–æ–‡ã«åŸºã¥ã„ã¦è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ï¼š

### 1. **DDPM** (Ho et al., 2020)
- **è«–æ–‡:** Denoising Diffusion Probabilistic Models
- **é©ç”¨:** å‰å‘ã/é€†å‘ãæ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã®æ•°å­¦åŸºç›¤
- **åŠ¹æœ:** å®‰å®šã—ãŸç”»åƒç”Ÿæˆã¨ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«å¯èƒ½æ€§

### 2. **Latent Diffusion** (Rombach et al., 2022)
- **è«–æ–‡:** High-Resolution Image Synthesis with Latent Diffusion Models
- **é©ç”¨:** VAEåœ§ç¸®ã«ã‚ˆã‚‹512å€ãƒ¡ãƒ¢ãƒªå‰Šæ¸›
- **åŠ¹æœ:** Colab T4 (16GB VRAM) ã§ã®å®Ÿè¡Œå¯èƒ½

### 3. **LoRA** (Hu et al., 2021)
- **è«–æ–‡:** LoRA: Low-Rank Adaptation of Large Language Models
- **é©ç”¨:** åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¾®èª¿æ•´ (0.0037% ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
- **åŠ¹æœ:** 2-3MB ã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªå­¦ç¿’å¯èƒ½é‡ã¿

### 4. **LCM** (Luo et al., 2023)
- **è«–æ–‡:** Latent Consistency Models: Synthesizing High-Resolution Images with Minimal Inference Steps
- **é©ç”¨:** 4ã‚¹ãƒ†ãƒƒãƒ—æ¨è«–ã§12å€é«˜é€ŸåŒ–
- **åŠ¹æœ:** 500ms â†’ 35ms ã®æ¨è«–æ™‚é–“å®Ÿç¾

---

## âœ¨ ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´

### âœ… å¾—æ„ãªç”Ÿæˆå¯¾è±¡

- ğŸ¨ **ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”Ÿæˆ**: é¡”ãƒ»é«ªãƒ»è¡¨æƒ…ã®è©³ç´°è¡¨ç¾
- ğŸ–Œï¸ **ã‚¢ãƒ¼ãƒˆæ§˜å¼**: æ°´å½©ã€æ²¹çµµã€ã‚¹ã‚±ãƒƒãƒã€ãƒ‘ã‚¹ãƒ†ãƒ«
- ğŸŒ… **èƒŒæ™¯ãƒ»é¢¨æ™¯**: ãƒœã‚±åŠ¹æœã€å…‰æºè¡¨ç¾ã€ã‚½ãƒ•ãƒˆãƒ•ã‚©ãƒ¼ã‚«ã‚¹
- âœ¨ **è£…é£¾åŠ¹æœ**: ã‚°ãƒ­ãƒ¼ã€æ•£ä¹±å…‰ã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
- ğŸ“ **ç·šç”»ãƒ»ã‚¹ã‚±ãƒƒãƒ**: ãƒšãƒ³ç”»ã€è¼ªéƒ­è¡¨ç¾

### âš ï¸ æ—¢çŸ¥ã®é™ç•Œ

- **ãƒªã‚¢ãƒ«3Dç”»åƒ**: Stable Diffusion v1.5 ã¯2D ã‚¢ãƒ‹ãƒ¡æœ€é©åŒ–
- **è¤‡é›‘ãªæ§‹å›³**: 3äººä»¥ä¸Šã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åŒæ™‚ç”Ÿæˆã¯ä¸å®‰å®š
- **æ‰‹ãƒ»æŒ‡**: å…ƒã€…ã®SD v1.5 ã®é™ç•Œï¼ˆè©³ç´°ã«ã¯ controlnet æ¨å¥¨ï¼‰
- **ãƒ†ã‚­ã‚¹ãƒˆ**: ç”»åƒå†…ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¯ä½ç²¾åº¦
- **æ¥µç«¯ãªã‚¹ã‚¿ã‚¤ãƒ«**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãªã„æ§˜å¼ã¸ã®é©å¿œã¯é™å®šçš„

---

## ï¿½ å®Œå…¨ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰

è©³ç´°ãªå®Ÿè£…ã¯ [anime-character-generator](https://github.com/Shion1124/anime-character-generator) ãƒªãƒã‚¸ãƒˆãƒªã® `train_lora.py` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### æœ€å°é™ã®å®Ÿè£…ä¾‹

```python
import torch
from diffusers import StableDiffusionPipeline, DDPMScheduler
from transformers import CLIPTextModel, CLIPTokenizer
from peft import LoraConfig, get_peft_model

# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
model_id = "runwayml/stable-diffusion-v1-5"
tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer")
text_encoder = CLIPTextModel.from_pretrained(model_id, subfolder="text_encoder")
unet = UNet2DConditionModel.from_pretrained(model_id, subfolder="unet")

# LoRA è¨­å®š
peft_config = LoraConfig(
    r=32,
    lora_alpha=32,
    target_modules=["to_k", "to_v", "to_q"],
    lora_dropout=0.1,
    bias="none"
)

# LoRA ã‚’ UNet ã«é©ç”¨
unet = get_peft_model(unet, peft_config)

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š
optimizer = torch.optim.AdamW(
    unet.parameters(),
    lr=1e-4,
    weight_decay=0.01
)

# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
for epoch in range(100):
    for batch in dataloader:
        # ... ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ ...
        loss.backward()
        optimizer.step()

# é‡ã¿ã®ä¿å­˜
unet.save_pretrained("./anime-lora-weights")
```

### HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

```bash
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
python upload_to_huggingface.py \
  --model-path ./anime-lora-weights \
  --repo-name anime-character-lora \
  --private False

# ã¾ãŸã¯æ‰‹å‹•
huggingface-cli upload YOUR_USERNAME/anime-character-lora \
  ./anime-lora-weights/ \
  --repo-type model \
  --private=False
```

---

## ğŸ“‹ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯è¤‡æ•°ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ï¼š

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ | èª¬æ˜ |
|-------------|---------|------|
| **Stable Diffusion v1.5** | OpenRAIL-M | CompVis/Stability AI |
| **LoRA å®Ÿè£…** | Apache 2.0 | æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ |
| **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿** | CC0 | Danbooru |

### OpenRAIL-M ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æº–æ‹ 

OpenRAIL-M ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«åŸºã¥ãã€ä»¥ä¸‹ã®åˆ©ç”¨ãŒèªã‚ã‚‰ã‚Œã¦ã„ã¾ã™ï¼š

**âœ… è¨±å¯ã•ã‚Œã‚‹åˆ©ç”¨:**
- å­¦è¡“ç ”ç©¶ãƒ»æ•™è‚²
- å‰µä½œæ”¯æ´ãƒ»å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
- éå–¶åˆ©ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆ
- å•†ç”¨åˆ©ç”¨ï¼ˆè²¬ä»»ã‚ã‚‹åˆ©ç”¨ãŒå‰æï¼‰

**âŒ ç¦æ­¢ã•ã‚Œã‚‹åˆ©ç”¨:**
- é•æ³•ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
- å€‹äººã‚’ç›´æ¥å®³ã™ã‚‹ç›®çš„ã§ã®åˆ©ç”¨
- è©æ¬ºãƒ»ãªã‚Šã™ã¾ã—

è©³ç´°ã¯ [OpenRAIL License](https://huggingface.co/spaces/CompVis/stable-diffusion-license) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

## ğŸ“š å­¦è¡“å‚è€ƒè³‡æ–™

ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã™ã‚‹éš›ã«å‚è€ƒã«ã—ãŸå­¦è¡“è«–æ–‡ï¼š

1. **Ho et al. (2020)**
   - *Denoising Diffusion Probabilistic Models*
   - NEURIPS 2020
   - arXiv: [2006.11239](https://arxiv.org/abs/2006.11239)

2. **Rombach et al. (2022)**
   - *High-Resolution Image Synthesis with Latent Diffusion Models*
   - CVPR 2022
   - arXiv: [2112.10752](https://arxiv.org/abs/2112.10752)

3. **Hu et al. (2021)**
   - *LoRA: Low-Rank Adaptation of Large Language Models*
   - ICLR 2022
   - arXiv: [2106.09685](https://arxiv.org/abs/2106.09685)

4. **Luo et al. (2023)**
   - *Latent Consistency Models: Synthesizing High-Resolution Images with Minimal Inference Steps*
   - ICCV 2023
   - arXiv: [2310.04378](https://arxiv.org/abs/2310.04378)

### é–¢é€£ãƒªã‚½ãƒ¼ã‚¹

- ğŸ“– [Diffusers Library](https://huggingface.co/docs/diffusers/)
- ğŸ“– [PEFT Library](https://github.com/huggingface/peft)
- ğŸ  [Stable Diffusion v1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5)
- ğŸ¨ [Danbooru Tag Recommendation](https://danbooru.donmai.us/)
- ğŸ’¾ [Latent Consistency Models](https://github.com/luosiallen/latent-consistency-model)

---

## ğŸ‘¤ ä½œè€…

**Shion Shinzaki**
- GitHub: [@Shion1124](https://github.com/Shion1124)
- HuggingFace: [@Shion1124](https://huggingface.co/Shion1124)

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹æ—¥:** 2026å¹´2æœˆ18æ—¥  
**LoRA ãƒªãƒªãƒ¼ã‚¹æ—¥:** 2026å¹´2æœˆ18æ—¥  
**æœ€çµ‚æ›´æ–°:** 2026å¹´2æœˆ18æ—¥

---

**ğŸ‰ ã“ã®ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ï¼**

ã”è³ªå•ã‚„ææ¡ˆã¯ [GitHub Issues](https://github.com/Shion1124/anime-character-generator/issues) ã¾ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
