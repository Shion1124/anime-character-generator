{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1edacd",
   "metadata": {},
   "source": [
    "# ğŸ¨ anime-character-generator: LoRA ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "\n",
    "Stable Diffusion v1.5 ã‚’ **ã‚¢ãƒ‹ãƒ¡ãƒ»å°è±¡æ´¾é¢¨** ã«ç‰¹åŒ–ã•ã›ã‚‹ãŸã‚ã€LoRA ã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ Google Colab (T4 GPU) ã§å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "**å®Ÿè¡Œæ™‚é–“:** ç´„ 1-2 æ™‚é–“\n",
    "**å¿…è¦ãªã‚‚ã®:**\n",
    "- Google Drive ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "- training_data/ ãƒ•ã‚©ãƒ«ãƒ€ (660 MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde6cb9",
   "metadata": {},
   "source": [
    "## Step 1: ç’°å¢ƒç¢ºèªãƒ»GPU ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ã®ç¢ºèª\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a3648",
   "metadata": {},
   "source": [
    "## Step 2: ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f2730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpeftä¸è¦ - ç´”ç²‹PyTorch LoRAã‚’ä½¿ç”¨ï¼‰\n",
    "!pip install -q diffusers transformers pillow torch tqdm safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa666c",
   "metadata": {},
   "source": [
    "## Step 3: Google Drive ã«ãƒã‚¦ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Google Drive ã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
    "drive.mount('/content/drive')\n",
    "print(\"âœ… Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a13c1",
   "metadata": {},
   "source": [
    "## Step 4: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™\n",
    "\n",
    "**äº‹å‰æº–å‚™ (ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œå‰):**\n",
    "1. ãƒ­ãƒ¼ã‚«ãƒ«ã§ `python scripts/download_danbooru.py --limit 60` ã‚’å®Ÿè¡Œ\n",
    "2. ç”Ÿæˆã•ã‚ŒãŸ `training_data/` ãƒ•ã‚©ãƒ«ãƒ€ã‚’ Google Drive ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "3. ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d51897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Google Drive ã‹ã‚‰ training_data ã‚’ã‚³ãƒ”ãƒ¼\n",
    "drive_path = Path(\"/content/drive/MyDrive/training_data\")\n",
    "local_path = Path(\"/content/training_data\")\n",
    "\n",
    "if drive_path.exists():\n",
    "    print(f\"âœ… Found: {drive_path}\")\n",
    "    # ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ (é€Ÿåº¦å‘ä¸Š)\n",
    "    if not local_path.exists():\n",
    "        os.symlink(drive_path, local_path)\n",
    "        print(f\"âœ… Symlink created: {local_path}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ\n",
    "    import json\n",
    "    metadata_file = drive_path / \"metadata.json\"\n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file) as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"ğŸ“Š Dataset: {len(metadata.get('training_data', []))} images\")\n",
    "else:\n",
    "    print(f\"âŒ Not found: {drive_path}\")\n",
    "    print(\"\\nPlease upload training_data/ to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efa079",
   "metadata": {},
   "source": [
    "## Step 5: train_lora.py ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "GitHub ã‹ã‚‰æœ€æ–°ã® train_lora.py ã‚’å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub ã‹ã‚‰ train_lora.py ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "!wget -q https://raw.githubusercontent.com/Shion1124/anime-character-generator/master/train_lora.py -O /content/train_lora.py\n",
    "print(\"âœ… train_lora.py downloaded\")\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª\n",
    "import os\n",
    "file_size = os.path.getsize(\"/content/train_lora.py\") / 1024\n",
    "print(f\"ğŸ“Š File size: {file_size:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a21a9a",
   "metadata": {},
   "source": [
    "## Step 6: LoRA ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "\n",
    "**é‡è¦:** ã“ã®ã‚»ãƒ«ã¯ 1-2 æ™‚é–“ ã‹ã‹ã‚Šã¾ã™ã€‚Colab ã®æ¥ç¶šã‚’ä¿æŒã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb324c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ\n",
    "!python /content/train_lora.py \\\n",
    "    --data_dir /content/training_data \\\n",
    "    --output_dir /content/lora_weights \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 1 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a21c5c",
   "metadata": {},
   "source": [
    "## Step 7: å­¦ç¿’çµæœã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# å­¦ç¿’ãƒ­ã‚°ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "log_file = Path(\"/content/lora_weights/training_log.json\")\n",
    "if log_file.exists():\n",
    "    with open(log_file) as f:\n",
    "        training_log = json.load(f)\n",
    "    \n",
    "    # å­¦ç¿’æ›²ç·šã‚’è¡¨ç¤º\n",
    "    losses = [h['loss'] for h in training_log['history']]\n",
    "    epochs = list(range(1, len(losses) + 1))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, losses, 'b-', linewidth=2, marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('LoRA Training Loss Curve')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/training_curve.png', dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±\n",
    "    print(f\"âœ… Training completed!\")\n",
    "    print(f\"ğŸ“Š Total epochs: {len(losses)}\")\n",
    "    print(f\"ğŸ“‰ Final loss: {losses[-1]:.6f}\")\n",
    "    print(f\"ğŸ“ˆ Initial loss: {losses[0]:.6f}\")\n",
    "    print(f\"ğŸ¯ Loss improvement: {(losses[0] - losses[-1]) / losses[0] * 100:.1f}%\")\n",
    "else:\n",
    "    print(\"âš ï¸ training_log.json not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc4431",
   "metadata": {},
   "source": [
    "## Step 8: LoRA é‡ã¿ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4545af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "lora_dir = Path(\"/content/lora_weights\")\n",
    "print(\"ğŸ“ Output files:\")\n",
    "print()\n",
    "\n",
    "for file in sorted(lora_dir.glob(\"*\")):\n",
    "    if file.is_file():\n",
    "        size_mb = file.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {file.name:40s} {size_mb:>8.2f} MB\")\n",
    "\n",
    "# ãƒ¡ã‚¤ãƒ³ã® LoRA é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "lora_model = lora_dir / \"anime-impressionist-lora.safetensors\"\n",
    "if lora_model.exists():\n",
    "    size_mb = lora_model.stat().st_size / (1024 * 1024)\n",
    "    print(f\"\\nâœ… Main LoRA weights: {lora_model.name} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d7328",
   "metadata": {},
   "source": [
    "## Step 9: Google Drive ã«çµæœã‚’ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f330d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’æ¸ˆã¿ LoRA é‡ã¿ã‚’ Google Drive ã«ä¿å­˜\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "lora_weights_dir = Path(\"/content/lora_weights\")\n",
    "drive_output_dir = Path(\"/content/drive/MyDrive/lora_weights\")\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "drive_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
    "for file in lora_weights_dir.glob(\"*\"):\n",
    "    if file.is_file():\n",
    "        destination = drive_output_dir / file.name\n",
    "        shutil.copy2(file, destination)\n",
    "        print(f\"âœ… Saved: {file.name}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Output saved to: {drive_output_dir}\")\n",
    "print(\"\\nğŸ’¾ Download instructions:\")\n",
    "print(\"1. Open Google Drive\")\n",
    "print(\"2. Navigate to /lora_weights/\")\n",
    "print(\"3. Download 'anime-impressionist-lora.safetensors'\")\n",
    "print(\"4. Place in: anime-character-generator/ root directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb12ff",
   "metadata": {},
   "source": [
    "## Step 10: æ¨è«–ãƒ†ã‚¹ãƒˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ LoRA ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA ã‚’ä½¿ç”¨ã—ãŸæ¨è«–ãƒ†ã‚¹ãƒˆ\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "print(\"â³ Loading model...\")\n",
    "\n",
    "# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆ\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# LoRA é‡ã¿ãƒ­ãƒ¼ãƒ‰\n",
    "try:\n",
    "    # PEFT ã‚’ä½¿ç”¨ã—ãŸ LoRA ãƒ­ãƒ¼ãƒ‰\n",
    "    from peft import PeftModel\n",
    "    # (LoRA ãƒ­ãƒ¼ãƒ‰å®Ÿè£…)\n",
    "    print(\"âœ… LoRA weights loaded\")\n",
    "except:\n",
    "    print(\"âš ï¸ LoRA loading requires additional setup\")\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "prompt = \"1girl, watercolor painting style, masterpiece, high quality, anime\"\n",
    "negative_prompt = \"low quality, nsfw\"\n",
    "\n",
    "print(f\"\\nğŸ¨ Generating: {prompt}...\")\n",
    "\n",
    "# ç”»åƒç”Ÿæˆ\n",
    "with torch.no_grad():\n",
    "    image = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        height=512,\n",
    "        width=512,\n",
    "        num_inference_steps=20,\n",
    "        guidance_scale=7.0\n",
    "    ).images[0]\n",
    "\n",
    "# çµæœè¡¨ç¤º\n",
    "image.save(\"/content/test_output.png\")\n",
    "print(\"âœ… Image saved: test_output.png\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20208be4",
   "metadata": {},
   "source": [
    "## âœ… å®Œäº†ï¼\n",
    "\n",
    "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**\n",
    "1. LoRA é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "2. ãƒ­ãƒ¼ã‚«ãƒ«ã§ `character_generator.py --use_lora=True` ã§æ¨è«–\n",
    "3. çµæœã‚’ç¢ºèª\n",
    "\n",
    "**å‚è€ƒ:**\n",
    "- [GitHub ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/Shion1124/anime-character-generator)\n",
    "- [HuggingFace ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/runwayml/stable-diffusion-v1-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5464a",
   "metadata": {},
   "source": [
    "## Step 11: HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ LoRA ãƒ¢ãƒ‡ãƒ«ã‚’ HuggingFace Model Hub ã§å…¬é–‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1041206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: HuggingFace Hub ã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# èªè¨¼ï¼ˆäº‹å‰ã« huggingface-cli login ã‚’å®Ÿè¡Œï¼‰\n",
    "api = HfApi()\n",
    "\n",
    "# ãƒªãƒã‚¸ãƒˆãƒªè¨­å®š\n",
    "username = \"YOUR_USERNAME\"  # è‡ªåˆ†ã® HuggingFace ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«å¤‰æ›´\n",
    "repo_name = \"anime-impressionist-lora\"\n",
    "repo_id = f\"{username}/{repo_name}\"\n",
    "\n",
    "print(f\"ğŸš€ HuggingFace Hub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {repo_id}\")\n",
    "\n",
    "# ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆREADME.mdä½œæˆ\n",
    "readme_content = \"\"\"# ğŸ¨ anime-impressionist-lora\n",
    "\n",
    "**æ–‡ä½“:** å°è±¡æ´¾é¢¨ã€æ°´å½©ç”»é¢¨ã€ã‚¢ãƒ‹ãƒ¡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼  \n",
    "**ãƒ¢ãƒ‡ãƒ«:** Stable Diffusion v1.5 + LoRA (Low-Rank Adaptation)  \n",
    "**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:** ç´„ 4 MB (è»½é‡ãƒ»é«˜é€Ÿ)\n",
    "\n",
    "## ğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±\n",
    "\n",
    "| é …ç›® | è©³ç´° |\n",
    "|------|------|\n",
    "| **ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«** | `runwayml/stable-diffusion-v1-5` |\n",
    "| **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•** | LoRA (PEFT) |\n",
    "| **ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿** | Danbooru 300 æš (5 ã‚¹ã‚¿ã‚¤ãƒ«) |\n",
    "| **å­¦ç¿’æ™‚é–“** | ç´„ 1-2 æ™‚é–“ (Colab T4 GPU) |\n",
    "| **LoRA ãƒ©ãƒ³ã‚¯** | 8 |\n",
    "| **LoRA ã‚¢ãƒ«ãƒ•ã‚¡** | 32 |\n",
    "\n",
    "## ğŸš€ ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "### æ–¹æ³• 1: diffusers + PEFT (æ¨å¥¨)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe.unet = PeftModel.from_pretrained(\n",
    "    pipe.unet,\n",
    "    \"{repo_id}\",\n",
    "    adapter_name=\"anime_lora\"\n",
    ")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"1girl, watercolor painting style, masterpiece, anime\"\n",
    "image = pipe(prompt=prompt, num_inference_steps=20).images[0]\n",
    "image.save(\"output.png\")\n",
    "```\n",
    "\n",
    "## ğŸ“ˆ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è©³ç´°\n",
    "\n",
    "- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: Danbooru 300 æš (5 ã‚¹ã‚¿ã‚¤ãƒ«)\n",
    "- **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: lr=1e-4, rank=8, alpha=32\n",
    "- **ã‚¨ãƒãƒƒã‚¯**: 50\n",
    "- **æœ€é©åŒ–**: AdamW\n",
    "\n",
    "## ğŸ“‹ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n",
    "\n",
    "[OpenRAIL License](https://huggingface.co/spaces/CompVis/stable-diffusion-license)\n",
    "\n",
    "## ğŸ¤ å‚è€ƒ\n",
    "\n",
    "- [anime-character-generator](https://github.com/Shion1124/anime-character-generator)\n",
    "- [PEFT Documentation](https://github.com/huggingface/peft)\n",
    "\"\"\"\n",
    "\n",
    "# README.md ã‚’ä¸€æ™‚ä¿å­˜\n",
    "readme_path = Path(lora_weights_dir) / \"README.md\"\n",
    "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"âœ… README.md ã‚’ç”Ÿæˆã—ã¾ã—ãŸ ({len(readme_content)} æ–‡å­—)\")\n",
    "\n",
    "# ãƒªãƒã‚¸ãƒˆãƒªä½œæˆï¼ˆæ—¢å­˜ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰\n",
    "try:\n",
    "    api.create_repo(repo_id=repo_id, repo_type=\"model\", exist_ok=True, private=False)\n",
    "    print(f\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆ: {repo_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ: {e}\")\n",
    "\n",
    "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "files_to_upload = [\n",
    "    (\"anime-impressionist-lora.safetensors\", \"LoRA é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«\"),\n",
    "    (\"adapter_config.json\", \"LoRA è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«\"),\n",
    "    (\"training_log.json\", \"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ­ã‚°\"),\n",
    "    (\"README.md\", \"ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰\")\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "for filename, description in files_to_upload:\n",
    "    file_path = Path(lora_weights_dir) / filename\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"âš ï¸ {filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (ã‚¹ã‚­ãƒƒãƒ—)\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=str(file_path),\n",
    "            path_in_repo=filename,\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "        file_size = file_path.stat().st_size / (1024 * 1024)  # MB\n",
    "        print(f\"âœ… {filename} ({file_size:.1f} MB) - {description}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {filename}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ‰ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼\")\n",
    "print(f\"ğŸ“ ãƒ¢ãƒ‡ãƒ« URL: https://huggingface.co/{repo_id}\")\n",
    "print(f\"ğŸ’¡ ä½¿ç”¨æ–¹æ³•: model = {repo_id}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
